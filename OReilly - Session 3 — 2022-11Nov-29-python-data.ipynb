{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd4bf3b",
   "metadata": {},
   "source": [
    "# Agenda, week 3: Real-world data\n",
    "\n",
    "1. Recap and Q&A\n",
    "2. (More about) CSV file\n",
    "    - Selecting columns\n",
    "    - Selecting the index\n",
    "    - Header lines\n",
    "3. Reading online data\n",
    "    - CSV\n",
    "    - Scraping sites with Pandas\n",
    "4. Sorting data\n",
    "    - Sorting by value\n",
    "    - Sorting by index\n",
    "    - Sorting by multiple values\n",
    "5. Grouping\n",
    "    - What is grouping?\n",
    "    - Aggregate functions\n",
    "    - Grouping by multiple columns\n",
    "6. Pivot tables\n",
    "7. Joining\n",
    "    - What is joining?\n",
    "    - Simple joins across data frames\n",
    "8. Cleaning data    \n",
    "\n",
    "Please download the data file mentioned in the course page.  Warning: It's a big file! And it contains some very large CSV files!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce0653c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a6aec53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1    10\n",
       "2    20\n",
       "3    50\n",
       "4    89\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Series('1 10 20 50 89'.split())\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "521132d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/numpy/core/numeric.py:2463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "values cannot be losslessly cast to int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1 10 20 50 89\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# this forces the dtype to be int64, and turns items into ints\u001b[39;00m\n\u001b[1;32m      2\u001b[0m s\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/series.py:470\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    468\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 470\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/construction.py:622\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_try_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_cast_failure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    624\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_integer_dtype(dtype):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/construction.py:835\u001b[0m, in \u001b[0;36m_try_cast\u001b[0;34m(arr, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;66;03m# GH#15832: Check if we are requesting a numeric dtype and\u001b[39;00m\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;66;03m# that we can convert the data to the requested dtype.\u001b[39;00m\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_integer_dtype(dtype):\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;66;03m# this will raise if we have e.g. floats\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_cast_to_integer_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    837\u001b[0m         \u001b[38;5;66;03m# 4 tests fail if we move this to a try/except/else; see\u001b[39;00m\n\u001b[1;32m    838\u001b[0m         \u001b[38;5;66;03m#  test_constructor_compound_dtypes, test_constructor_cast_failure\u001b[39;00m\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;66;03m#  test_constructor_dict_cast2, test_loc_setitem_dtype\u001b[39;00m\n\u001b[1;32m    840\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(arr, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/dtypes/cast.py:1888\u001b[0m, in \u001b[0;36mmaybe_cast_to_integer_array\u001b[0;34m(arr, dtype, copy)\u001b[0m\n\u001b[1;32m   1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m casted\n\u001b[1;32m   1887\u001b[0m \u001b[38;5;66;03m# No known cases that get here, but raising explicitly to cover our bases.\u001b[39;00m\n\u001b[0;32m-> 1888\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues cannot be losslessly cast to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: values cannot be losslessly cast to int64"
     ]
    }
   ],
   "source": [
    "s = Series('1 10 20 50 89'.split(), dtype=np.int64)   # this forces the dtype to be int64, and turns items into ints\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb074488",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Series('1 10 20 50 89'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbbd367f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1    10\n",
       "2    20\n",
       "3    50\n",
       "4    89\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b510a3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1    10\n",
       "2    20\n",
       "3    50\n",
       "4    89\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b1d7b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1    10\n",
       "2    20\n",
       "3    50\n",
       "4    89\n",
       "dtype: string"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.astype(pd.StringDtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4992449d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is Python's None equal to itself?\n",
    "None == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7dd289c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what type is Python's None?\n",
    "type(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d439eed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is NumPy's NaN equal to itself?\n",
    "np.nan == np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b254603e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what type is it?\n",
    "type(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3950d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Series([10, 20, 30, np.nan, 50, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "653f692f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10.0\n",
       "1    20.0\n",
       "2    30.0\n",
       "3     NaN\n",
       "4    50.0\n",
       "5    60.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24c31ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10.0\n",
       "1    20.0\n",
       "2    30.0\n",
       "3     NaN\n",
       "4    50.0\n",
       "5    60.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Series([10, 20, 30, None, 50, 60])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "852c8604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is a growing interest in using a special Pandas version of NaN, called pd.NA\n",
    "\n",
    "s = Series([10, 20, 30, pd.NA, 50, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35e9bc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      10\n",
       "1      20\n",
       "2      30\n",
       "3    <NA>\n",
       "4      50\n",
       "5      60\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "939b1457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b180e98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>28</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>66</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>87</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    v   w   x   y   z\n",
       "a  28  66   9  33  99\n",
       "b  66  92  99  87  39\n",
       "c   3  92  37  34  84\n",
       "d  38   8  44   3  87"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame(np.random.randint(0, 100, [4, 5]),\n",
    "              index=list('abcd'),\n",
    "              columns=list('vwxyz'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb1c3082",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wx'] = df['w'] + df['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc29145a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>wx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>28</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>99</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>66</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>87</td>\n",
       "      <td>39</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>84</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    v   w   x   y   z   wx\n",
       "a  28  66   9  33  99   75\n",
       "b  66  92  99  87  39  191\n",
       "c   3  92  37  34  84  129\n",
       "d  38   8  44   3  87   52"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c31126",
   "metadata": {},
   "source": [
    "# More about CSV\n",
    "\n",
    "CSV is a standard, but with a *lot* of leeway in its interpretation. So when you have a CSV file, it might (or might not) have a line at the top naming the columns. It might (or might not) use commas to separate the values. It might or might not contains special types of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cf712cc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_csv in module pandas.io.parsers.readers:\n",
      "\n",
      "read_csv(filepath_or_buffer: 'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]', *, sep: 'str | None | lib.NoDefault' = <no_default>, delimiter: 'str | None | lib.NoDefault' = None, header: \"int | Sequence[int] | None | Literal['infer']\" = 'infer', names: 'Sequence[Hashable] | None | lib.NoDefault' = <no_default>, index_col: 'IndexLabel | Literal[False] | None' = None, usecols=None, squeeze: 'bool | None' = None, prefix: 'str | lib.NoDefault' = <no_default>, mangle_dupe_cols: 'bool' = True, dtype: 'DtypeArg | None' = None, engine: 'CSVEngine | None' = None, converters=None, true_values=None, false_values=None, skipinitialspace: 'bool' = False, skiprows=None, skipfooter: 'int' = 0, nrows: 'int | None' = None, na_values=None, keep_default_na: 'bool' = True, na_filter: 'bool' = True, verbose: 'bool' = False, skip_blank_lines: 'bool' = True, parse_dates=None, infer_datetime_format: 'bool' = False, keep_date_col: 'bool' = False, date_parser=None, dayfirst: 'bool' = False, cache_dates: 'bool' = True, iterator: 'bool' = False, chunksize: 'int | None' = None, compression: 'CompressionOptions' = 'infer', thousands: 'str | None' = None, decimal: 'str' = '.', lineterminator: 'str | None' = None, quotechar: 'str' = '\"', quoting: 'int' = 0, doublequote: 'bool' = True, escapechar: 'str | None' = None, comment: 'str | None' = None, encoding: 'str | None' = None, encoding_errors: 'str | None' = 'strict', dialect: 'str | csv.Dialect | None' = None, error_bad_lines: 'bool | None' = None, warn_bad_lines: 'bool | None' = None, on_bad_lines=None, delim_whitespace: 'bool' = False, low_memory=True, memory_map: 'bool' = False, float_precision: \"Literal['high', 'legacy'] | None\" = None, storage_options: 'StorageOptions' = None) -> 'DataFrame | TextFileReader'\n",
      "    Read a comma-separated values (csv) file into DataFrame.\n",
      "    \n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "    \n",
      "    Additional help can be found in the online docs for\n",
      "    `IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : str, path object or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
      "        expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "    \n",
      "        If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "    \n",
      "        By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "        a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "    sep : str, default ','\n",
      "        Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
      "        the separator, but the Python parsing engine can, meaning the latter will\n",
      "        be used and automatically detect the separator by Python's builtin sniffer\n",
      "        tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
      "        different from ``'\\s+'`` will be interpreted as regular expressions and\n",
      "        will also force the use of the Python parsing engine. Note that regex\n",
      "        delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "    delimiter : str, default ``None``\n",
      "        Alias for sep.\n",
      "    header : int, list of int, None, default 'infer'\n",
      "        Row number(s) to use as the column names, and the start of the\n",
      "        data.  Default behavior is to infer the column names: if no names\n",
      "        are passed the behavior is identical to ``header=0`` and column\n",
      "        names are inferred from the first line of the file, if column\n",
      "        names are passed explicitly then the behavior is identical to\n",
      "        ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "        replace existing names. The header can be a list of integers that\n",
      "        specify row locations for a multi-index on the columns\n",
      "        e.g. [0,1,3]. Intervening rows that are not specified will be\n",
      "        skipped (e.g. 2 in this example is skipped). Note that this\n",
      "        parameter ignores commented lines and empty lines if\n",
      "        ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "        data rather than the first line of the file.\n",
      "    names : array-like, optional\n",
      "        List of column names to use. If the file contains a header row,\n",
      "        then you should explicitly pass ``header=0`` to override the column names.\n",
      "        Duplicates in this list are not allowed.\n",
      "    index_col : int, str, sequence of int / str, or False, optional, default ``None``\n",
      "      Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
      "      string name or column index. If a sequence of int / str is given, a\n",
      "      MultiIndex is used.\n",
      "    \n",
      "      Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "      column as the index, e.g. when you have a malformed file with delimiters at\n",
      "      the end of each line.\n",
      "    usecols : list-like or callable, optional\n",
      "        Return a subset of the columns. If list-like, all elements must either\n",
      "        be positional (i.e. integer indices into the document columns) or strings\n",
      "        that correspond to column names provided either by the user in `names` or\n",
      "        inferred from the document header row(s). If ``names`` are given, the document\n",
      "        header row(s) are not taken into account. For example, a valid list-like\n",
      "        `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "        Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "        To instantiate a DataFrame from ``data`` with element order preserved use\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
      "        in ``['foo', 'bar']`` order or\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "        for ``['bar', 'foo']`` order.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the column\n",
      "        names, returning names where the callable function evaluates to True. An\n",
      "        example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "        ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "        parsing time and lower memory usage.\n",
      "    squeeze : bool, default False\n",
      "        If the parsed data only contains one column then return a Series.\n",
      "    \n",
      "        .. deprecated:: 1.4.0\n",
      "            Append ``.squeeze(\"columns\")`` to the call to ``read_csv`` to squeeze\n",
      "            the data.\n",
      "    prefix : str, optional\n",
      "        Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
      "    \n",
      "        .. deprecated:: 1.4.0\n",
      "           Use a list comprehension on the DataFrame's columns after calling ``read_csv``.\n",
      "    mangle_dupe_cols : bool, default True\n",
      "        Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
      "        'X'...'X'. Passing in False will cause data to be overwritten if there\n",
      "        are duplicate names in the columns.\n",
      "    \n",
      "        .. deprecated:: 1.5.0\n",
      "            Not implemented, and a new argument to specify the pattern for the\n",
      "            names of duplicated columns will be added instead\n",
      "    dtype : Type name or dict of column -> type, optional\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
      "        'c': 'Int64'}\n",
      "        Use `str` or `object` together with suitable `na_values` settings\n",
      "        to preserve and not interpret dtype.\n",
      "        If converters are specified, they will be applied INSTEAD\n",
      "        of dtype conversion.\n",
      "    \n",
      "        .. versionadded:: 1.5.0\n",
      "    \n",
      "            Support for defaultdict was added. Specify a defaultdict as input where\n",
      "            the default determines the dtype of the columns which are not explicitly\n",
      "            listed.\n",
      "    engine : {'c', 'python', 'pyarrow'}, optional\n",
      "        Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
      "        is currently more feature-complete. Multithreading is currently only supported by\n",
      "        the pyarrow engine.\n",
      "    \n",
      "        .. versionadded:: 1.4.0\n",
      "    \n",
      "            The \"pyarrow\" engine was added as an *experimental* engine, and some features\n",
      "            are unsupported, or may not work correctly, with this engine.\n",
      "    converters : dict, optional\n",
      "        Dict of functions for converting values in certain columns. Keys can either\n",
      "        be integers or column labels.\n",
      "    true_values : list, optional\n",
      "        Values to consider as True.\n",
      "    false_values : list, optional\n",
      "        Values to consider as False.\n",
      "    skipinitialspace : bool, default False\n",
      "        Skip spaces after delimiter.\n",
      "    skiprows : list-like, int or callable, optional\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
      "        at the start of the file.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the row\n",
      "        indices, returning True if the row should be skipped and False otherwise.\n",
      "        An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
      "    nrows : int, optional\n",
      "        Number of rows of file to read. Useful for reading pieces of large files.\n",
      "    na_values : scalar, str, list-like, or dict, optional\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values.  By default the following values are interpreted as\n",
      "        NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "        '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
      "        'nan', 'null'.\n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default NaN values when parsing the data.\n",
      "        Depending on whether `na_values` is passed in, the behavior is as follows:\n",
      "    \n",
      "        * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
      "          is appended to the default NaN values used for parsing.\n",
      "        * If `keep_default_na` is True, and `na_values` are not specified, only\n",
      "          the default NaN values are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are specified, only\n",
      "          the NaN values specified `na_values` are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are not specified, no\n",
      "          strings will be parsed as NaN.\n",
      "    \n",
      "        Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
      "        `na_values` parameters will be ignored.\n",
      "    na_filter : bool, default True\n",
      "        Detect missing value markers (empty strings and the value of na_values). In\n",
      "        data without any NAs, passing na_filter=False can improve the performance\n",
      "        of reading a large file.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of NA values placed in non-numeric columns.\n",
      "    skip_blank_lines : bool, default True\n",
      "        If True, skip over blank lines rather than interpreting as NaN values.\n",
      "    parse_dates : bool or list of int or names or list of lists or dict, default False\n",
      "        The behavior is as follows:\n",
      "    \n",
      "        * boolean. If True -> try parsing the index.\n",
      "        * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "          a single date column.\n",
      "        * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
      "          result 'foo'\n",
      "    \n",
      "        If a column or index cannot be represented as an array of datetimes,\n",
      "        say because of an unparsable value or a mixture of timezones, the column\n",
      "        or index will be returned unaltered as an object data type. For\n",
      "        non-standard datetime parsing, use ``pd.to_datetime`` after\n",
      "        ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
      "        specify ``date_parser`` to be a partially-applied\n",
      "        :func:`pandas.to_datetime` with ``utc=True``. See\n",
      "        :ref:`io.csv.mixed_timezones` for more.\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    infer_datetime_format : bool, default False\n",
      "        If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
      "        format of the datetime strings in the columns, and if it can be inferred,\n",
      "        switch to a faster method of parsing them. In some cases this can increase\n",
      "        the parsing speed by 5-10x.\n",
      "    keep_date_col : bool, default False\n",
      "        If True and `parse_dates` specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : function, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by `parse_dates` into a single array\n",
      "        and pass that; and 3) call `date_parser` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "        arguments.\n",
      "    dayfirst : bool, default False\n",
      "        DD/MM format dates, international and European format.\n",
      "    cache_dates : bool, default True\n",
      "        If True, use a cache of unique, converted dates to apply the datetime\n",
      "        conversion. May produce significant speed-up when parsing duplicate\n",
      "        date strings, especially ones with timezone offsets.\n",
      "    \n",
      "        .. versionadded:: 0.25.0\n",
      "    iterator : bool, default False\n",
      "        Return TextFileReader object for iteration or getting chunks with\n",
      "        ``get_chunk()``.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           ``TextFileReader`` is a context manager.\n",
      "    chunksize : int, optional\n",
      "        Return TextFileReader object for iteration.\n",
      "        See the `IO Tools docs\n",
      "        <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "        for more information on ``iterator`` and ``chunksize``.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           ``TextFileReader`` is a context manager.\n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer' and 'filepath_or_buffer' is\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "        (otherwise no compression).\n",
      "        If using 'zip' or 'tar', the ZIP file must contain only one data file to be read in.\n",
      "        Set to ``None`` for no decompression.\n",
      "        Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      "        key-value pairs are forwarded to\n",
      "        ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, ``zstandard.ZstdDecompressor`` or\n",
      "        ``tarfile.TarFile``, respectively.\n",
      "        As an example, the following could be passed for Zstandard decompression using a\n",
      "        custom compression dictionary:\n",
      "        ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
      "    \n",
      "            .. versionadded:: 1.5.0\n",
      "                Added support for `.tar` files.\n",
      "    \n",
      "        .. versionchanged:: 1.4.0 Zstandard support.\n",
      "    \n",
      "    thousands : str, optional\n",
      "        Thousands separator.\n",
      "    decimal : str, default '.'\n",
      "        Character to recognize as decimal point (e.g. use ',' for European data).\n",
      "    lineterminator : str (length 1), optional\n",
      "        Character to break file into lines. Only valid with C parser.\n",
      "    quotechar : str (length 1), optional\n",
      "        The character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the delimiter and it will be ignored.\n",
      "    quoting : int or csv.QUOTE_* instance, default 0\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
      "        QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
      "    doublequote : bool, default ``True``\n",
      "       When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
      "       whether or not to interpret two consecutive quotechar elements INSIDE a\n",
      "       field as a single ``quotechar`` element.\n",
      "    escapechar : str (length 1), optional\n",
      "        One-character string used to escape other characters.\n",
      "    comment : str, optional\n",
      "        Indicates remainder of line should not be parsed. If found at the beginning\n",
      "        of a line, the line will be ignored altogether. This parameter must be a\n",
      "        single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter `header` but not by\n",
      "        `skiprows`. For example, if ``comment='#'``, parsing\n",
      "        ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
      "        treated as the header.\n",
      "    encoding : str, optional\n",
      "        Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           When ``encoding`` is ``None``, ``errors=\"replace\"`` is passed to\n",
      "           ``open()``. Otherwise, ``errors=\"strict\"`` is passed to ``open()``.\n",
      "           This behavior was previously only the case for ``engine=\"python\"``.\n",
      "    \n",
      "        .. versionchanged:: 1.3.0\n",
      "    \n",
      "           ``encoding_errors`` is a new argument. ``encoding`` has no longer an\n",
      "           influence on how encoding errors are handled.\n",
      "    \n",
      "    encoding_errors : str, optional, default \"strict\"\n",
      "        How encoding errors are treated. `List of possible values\n",
      "        <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "    dialect : str or csv.Dialect, optional\n",
      "        If provided, this parameter will override values (default or not) for the\n",
      "        following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
      "        `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
      "        override values, a ParserWarning will be issued. See csv.Dialect\n",
      "        documentation for more details.\n",
      "    error_bad_lines : bool, optional, default ``None``\n",
      "        Lines with too many fields (e.g. a csv line with too many commas) will by\n",
      "        default cause an exception to be raised, and no DataFrame will be returned.\n",
      "        If False, then these \"bad lines\" will be dropped from the DataFrame that is\n",
      "        returned.\n",
      "    \n",
      "        .. deprecated:: 1.3.0\n",
      "           The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
      "           encountering a bad line instead.\n",
      "    warn_bad_lines : bool, optional, default ``None``\n",
      "        If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
      "        \"bad line\" will be output.\n",
      "    \n",
      "        .. deprecated:: 1.3.0\n",
      "           The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
      "           encountering a bad line instead.\n",
      "    on_bad_lines : {'error', 'warn', 'skip'} or callable, default 'error'\n",
      "        Specifies what to do upon encountering a bad line (a line with too many fields).\n",
      "        Allowed values are :\n",
      "    \n",
      "            - 'error', raise an Exception when a bad line is encountered.\n",
      "            - 'warn', raise a warning when a bad line is encountered and skip that line.\n",
      "            - 'skip', skip bad lines without raising or warning when they are encountered.\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "        .. versionadded:: 1.4.0\n",
      "    \n",
      "            - callable, function with signature\n",
      "              ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
      "              bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
      "              If the function returns ``None``, the bad line will be ignored.\n",
      "              If the function returns a new list of strings with more elements than\n",
      "              expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
      "              Only supported when ``engine=\"python\"``\n",
      "    \n",
      "    delim_whitespace : bool, default False\n",
      "        Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
      "        used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "        is set to True, nothing should be passed in for the ``delimiter``\n",
      "        parameter.\n",
      "    low_memory : bool, default True\n",
      "        Internally process the file in chunks, resulting in lower memory use\n",
      "        while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "        types either set False, or specify the type with the `dtype` parameter.\n",
      "        Note that the entire file is read into a single DataFrame regardless,\n",
      "        use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
      "        (Only valid with C parser).\n",
      "    memory_map : bool, default False\n",
      "        If a filepath is provided for `filepath_or_buffer`, map the file object\n",
      "        directly onto memory and access the data directly from there. Using this\n",
      "        option can improve performance because there is no longer any I/O overhead.\n",
      "    float_precision : str, optional\n",
      "        Specifies which converter the C engine should use for floating-point\n",
      "        values. The options are ``None`` or 'high' for the ordinary converter,\n",
      "        'legacy' for the original lower precision pandas converter, and\n",
      "        'round_trip' for the round-trip converter.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "    \n",
      "        .. versionadded:: 1.2\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or TextParser\n",
      "        A comma-separated values (csv) file is returned as two-dimensional\n",
      "        data structure with labeled axes.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_csv)   # show me the documentation for read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "baf76397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wine mag 150k reviews \n",
    "\n",
    "filename = '/Users/reuven/Courses/Current/data/winemag-150k-reviews.csv'\n",
    "\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5aa5ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>Martha's Vineyard</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Heitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>Carodorum Selección Especial Reserva</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>Bodega Carmen Rodríguez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>Special Selected Late Harvest</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Macauley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Ponzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>La Brûlade</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Bandol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provence red blend</td>\n",
       "      <td>Domaine de la Bégude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 country                                        description  \\\n",
       "0           0      US  This tremendous 100% varietal wine hails from ...   \n",
       "1           1   Spain  Ripe aromas of fig, blackberry and cassis are ...   \n",
       "2           2      US  Mac Watson honors the memory of a wine once ma...   \n",
       "3           3      US  This spent 20 months in 30% new French oak, an...   \n",
       "4           4  France  This is the top wine from La Bégude, named aft...   \n",
       "\n",
       "                            designation  points  price        province  \\\n",
       "0                     Martha's Vineyard      96  235.0      California   \n",
       "1  Carodorum Selección Especial Reserva      96  110.0  Northern Spain   \n",
       "2         Special Selected Late Harvest      96   90.0      California   \n",
       "3                               Reserve      96   65.0          Oregon   \n",
       "4                            La Brûlade      95   66.0        Provence   \n",
       "\n",
       "            region_1           region_2             variety  \\\n",
       "0        Napa Valley               Napa  Cabernet Sauvignon   \n",
       "1               Toro                NaN       Tinta de Toro   \n",
       "2     Knights Valley             Sonoma     Sauvignon Blanc   \n",
       "3  Willamette Valley  Willamette Valley          Pinot Noir   \n",
       "4             Bandol                NaN  Provence red blend   \n",
       "\n",
       "                    winery  \n",
       "0                    Heitz  \n",
       "1  Bodega Carmen Rodríguez  \n",
       "2                 Macauley  \n",
       "3                    Ponzi  \n",
       "4     Domaine de la Bégude  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first thing that I normally do when reading a CSV file is df.head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fc7cdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150930, 11)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I also want to know: How big is this data frame?\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "546d23a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Bandol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provence red blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                                        description  price  \\\n",
       "0      US  This tremendous 100% varietal wine hails from ...  235.0   \n",
       "1   Spain  Ripe aromas of fig, blackberry and cassis are ...  110.0   \n",
       "2      US  Mac Watson honors the memory of a wine once ma...   90.0   \n",
       "3      US  This spent 20 months in 30% new French oak, an...   65.0   \n",
       "4  France  This is the top wine from La Bégude, named aft...   66.0   \n",
       "\n",
       "         province           region_1           region_2             variety  \n",
       "0      California        Napa Valley               Napa  Cabernet Sauvignon  \n",
       "1  Northern Spain               Toro                NaN       Tinta de Toro  \n",
       "2      California     Knights Valley             Sonoma     Sauvignon Blanc  \n",
       "3          Oregon  Willamette Valley  Willamette Valley          Pinot Noir  \n",
       "4        Provence             Bandol                NaN  Provence red blend  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How can I be more selective with my CSV file?\n",
    "\n",
    "# What columns can I ignore from this file?\n",
    "# - Unnamed: 0\n",
    "# - winery\n",
    "# - points\n",
    "# - price\n",
    "\n",
    "# I can specify \"usecols\", and a list of either column names *or* column numbers, starting with 0\n",
    "\n",
    "filename = '/Users/reuven/Courses/Current/data/winemag-150k-reviews.csv'\n",
    "\n",
    "df = pd.read_csv(filename,\n",
    "                usecols=['country', 'description', 'price', 'province', 'region_1', 'region_2', 'variety'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "491c3b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if every row is 10 kb\n",
    "# if we have 150k rows\n",
    "\n",
    "150_000 * 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "317df32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cut down each row to be 8kb\n",
    "150_000 * 8_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f184623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spain</th>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Bandol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provence red blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               description  price  \\\n",
       "country                                                             \n",
       "US       This tremendous 100% varietal wine hails from ...  235.0   \n",
       "Spain    Ripe aromas of fig, blackberry and cassis are ...  110.0   \n",
       "US       Mac Watson honors the memory of a wine once ma...   90.0   \n",
       "US       This spent 20 months in 30% new French oak, an...   65.0   \n",
       "France   This is the top wine from La Bégude, named aft...   66.0   \n",
       "\n",
       "               province           region_1           region_2  \\\n",
       "country                                                         \n",
       "US           California        Napa Valley               Napa   \n",
       "Spain    Northern Spain               Toro                NaN   \n",
       "US           California     Knights Valley             Sonoma   \n",
       "US               Oregon  Willamette Valley  Willamette Valley   \n",
       "France         Provence             Bandol                NaN   \n",
       "\n",
       "                    variety  \n",
       "country                      \n",
       "US       Cabernet Sauvignon  \n",
       "Spain         Tinta de Toro  \n",
       "US          Sauvignon Blanc  \n",
       "US               Pinot Noir  \n",
       "France   Provence red blend  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make the index the country column\n",
    "\n",
    "df = pd.read_csv(filename,\n",
    "                usecols=['country', 'description', 'price', 'province', 'region_1', 'region_2', 'variety'])\n",
    "df = df.set_index('country')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "556dcc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spain</th>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Bandol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provence red blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               description  price  \\\n",
       "country                                                             \n",
       "US       This tremendous 100% varietal wine hails from ...  235.0   \n",
       "Spain    Ripe aromas of fig, blackberry and cassis are ...  110.0   \n",
       "US       Mac Watson honors the memory of a wine once ma...   90.0   \n",
       "US       This spent 20 months in 30% new French oak, an...   65.0   \n",
       "France   This is the top wine from La Bégude, named aft...   66.0   \n",
       "\n",
       "               province           region_1           region_2  \\\n",
       "country                                                         \n",
       "US           California        Napa Valley               Napa   \n",
       "Spain    Northern Spain               Toro                NaN   \n",
       "US           California     Knights Valley             Sonoma   \n",
       "US               Oregon  Willamette Valley  Willamette Valley   \n",
       "France         Provence             Bandol                NaN   \n",
       "\n",
       "                    variety  \n",
       "country                      \n",
       "US       Cabernet Sauvignon  \n",
       "Spain         Tinta de Toro  \n",
       "US          Sauvignon Blanc  \n",
       "US               Pinot Noir  \n",
       "France   Provence red blend  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can do this in one step, when reading the CSV file in from disk\n",
    "\n",
    "df = pd.read_csv(filename,\n",
    "                usecols=['country', 'description', 'price', 'province', 'region_1', 'region_2', 'variety'],\n",
    "                index_col='country')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "886da167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>This garnet-colored wine made from 100% Kallme...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Mirditë</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kallmet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>This garnet-colored wine made from 100% Kallme...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Mirditë</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kallmet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               description  price province  \\\n",
       "country                                                                      \n",
       "Albania  This garnet-colored wine made from 100% Kallme...   20.0  Mirditë   \n",
       "Albania  This garnet-colored wine made from 100% Kallme...   20.0  Mirditë   \n",
       "\n",
       "        region_1 region_2  variety  \n",
       "country                             \n",
       "Albania      NaN      NaN  Kallmet  \n",
       "Albania      NaN      NaN  Kallmet  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['Albania']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c9dee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I sync to GitHub with \"gitautopush\"\n",
    "# Just search for it on PyPI, and install it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9b679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cef134a",
   "metadata": {},
   "source": [
    "# Exercise: Wine reviews\n",
    "\n",
    "1. Read the wine-150k-reviews data set into a data frame. We only care about country, price, and variety.\n",
    "2. Which wine in this data set has the highest price?\n",
    "3. Which country has the most wines in this data set?\n",
    "4. What is the average price of Cabernet Sauvignon? How about Malbec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1dab0bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence red blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  price             variety\n",
       "0      US  235.0  Cabernet Sauvignon\n",
       "1   Spain  110.0       Tinta de Toro\n",
       "2      US   90.0     Sauvignon Blanc\n",
       "3      US   65.0          Pinot Noir\n",
       "4  France   66.0  Provence red blend"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/reuven/Courses/Current/data/winemag-150k-reviews.csv'\n",
    "\n",
    "df = pd.read_csv(filename, \n",
    "                usecols=['country', 'price', 'variety'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7d2c697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country     object\n",
       "price      float64\n",
       "variety     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6eeb628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34920</th>\n",
       "      <td>France</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      country   price                   variety\n",
       "34920  France  2300.0  Bordeaux-style Red Blend"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which wine has the highest price?\n",
    "df.loc[df['price'] == df['price'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45e477f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    62397\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which country has the most wines in this data set?\n",
    "df['country'].value_counts().head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4908e783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.146634046247335"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the average price of Cabernet Sauvignon? \n",
    "\n",
    "# row selector: variety has to be CS\n",
    "# column selector: price\n",
    "\n",
    "df.loc[\n",
    "    df['variety'] == 'Cabernet Sauvignon'   # row selector\n",
    "    ,\n",
    "    'price'  # column selector\n",
    "].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d350a96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.631118314424636"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How about Malbec?\n",
    "\n",
    "\n",
    "df.loc[\n",
    "    df['variety'] == 'Malbec'   # row selector\n",
    "    ,\n",
    "    'price'  # column selector\n",
    "].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28722be4",
   "metadata": {},
   "source": [
    "Data files are here: https://files.lerner.co.il/pandas-workout-data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df80778d",
   "metadata": {},
   "source": [
    "# Let's look again at `pd.read_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5c9c863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_csv in module pandas.io.parsers.readers:\n",
      "\n",
      "read_csv(filepath_or_buffer: 'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]', *, sep: 'str | None | lib.NoDefault' = <no_default>, delimiter: 'str | None | lib.NoDefault' = None, header: \"int | Sequence[int] | None | Literal['infer']\" = 'infer', names: 'Sequence[Hashable] | None | lib.NoDefault' = <no_default>, index_col: 'IndexLabel | Literal[False] | None' = None, usecols=None, squeeze: 'bool | None' = None, prefix: 'str | lib.NoDefault' = <no_default>, mangle_dupe_cols: 'bool' = True, dtype: 'DtypeArg | None' = None, engine: 'CSVEngine | None' = None, converters=None, true_values=None, false_values=None, skipinitialspace: 'bool' = False, skiprows=None, skipfooter: 'int' = 0, nrows: 'int | None' = None, na_values=None, keep_default_na: 'bool' = True, na_filter: 'bool' = True, verbose: 'bool' = False, skip_blank_lines: 'bool' = True, parse_dates=None, infer_datetime_format: 'bool' = False, keep_date_col: 'bool' = False, date_parser=None, dayfirst: 'bool' = False, cache_dates: 'bool' = True, iterator: 'bool' = False, chunksize: 'int | None' = None, compression: 'CompressionOptions' = 'infer', thousands: 'str | None' = None, decimal: 'str' = '.', lineterminator: 'str | None' = None, quotechar: 'str' = '\"', quoting: 'int' = 0, doublequote: 'bool' = True, escapechar: 'str | None' = None, comment: 'str | None' = None, encoding: 'str | None' = None, encoding_errors: 'str | None' = 'strict', dialect: 'str | csv.Dialect | None' = None, error_bad_lines: 'bool | None' = None, warn_bad_lines: 'bool | None' = None, on_bad_lines=None, delim_whitespace: 'bool' = False, low_memory=True, memory_map: 'bool' = False, float_precision: \"Literal['high', 'legacy'] | None\" = None, storage_options: 'StorageOptions' = None) -> 'DataFrame | TextFileReader'\n",
      "    Read a comma-separated values (csv) file into DataFrame.\n",
      "    \n",
      "    Also supports optionally iterating or breaking of the file\n",
      "    into chunks.\n",
      "    \n",
      "    Additional help can be found in the online docs for\n",
      "    `IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filepath_or_buffer : str, path object or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
      "        expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "    \n",
      "        If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "    \n",
      "        By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "        a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "    sep : str, default ','\n",
      "        Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
      "        the separator, but the Python parsing engine can, meaning the latter will\n",
      "        be used and automatically detect the separator by Python's builtin sniffer\n",
      "        tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
      "        different from ``'\\s+'`` will be interpreted as regular expressions and\n",
      "        will also force the use of the Python parsing engine. Note that regex\n",
      "        delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "    delimiter : str, default ``None``\n",
      "        Alias for sep.\n",
      "    header : int, list of int, None, default 'infer'\n",
      "        Row number(s) to use as the column names, and the start of the\n",
      "        data.  Default behavior is to infer the column names: if no names\n",
      "        are passed the behavior is identical to ``header=0`` and column\n",
      "        names are inferred from the first line of the file, if column\n",
      "        names are passed explicitly then the behavior is identical to\n",
      "        ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "        replace existing names. The header can be a list of integers that\n",
      "        specify row locations for a multi-index on the columns\n",
      "        e.g. [0,1,3]. Intervening rows that are not specified will be\n",
      "        skipped (e.g. 2 in this example is skipped). Note that this\n",
      "        parameter ignores commented lines and empty lines if\n",
      "        ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "        data rather than the first line of the file.\n",
      "    names : array-like, optional\n",
      "        List of column names to use. If the file contains a header row,\n",
      "        then you should explicitly pass ``header=0`` to override the column names.\n",
      "        Duplicates in this list are not allowed.\n",
      "    index_col : int, str, sequence of int / str, or False, optional, default ``None``\n",
      "      Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
      "      string name or column index. If a sequence of int / str is given, a\n",
      "      MultiIndex is used.\n",
      "    \n",
      "      Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "      column as the index, e.g. when you have a malformed file with delimiters at\n",
      "      the end of each line.\n",
      "    usecols : list-like or callable, optional\n",
      "        Return a subset of the columns. If list-like, all elements must either\n",
      "        be positional (i.e. integer indices into the document columns) or strings\n",
      "        that correspond to column names provided either by the user in `names` or\n",
      "        inferred from the document header row(s). If ``names`` are given, the document\n",
      "        header row(s) are not taken into account. For example, a valid list-like\n",
      "        `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "        Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "        To instantiate a DataFrame from ``data`` with element order preserved use\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
      "        in ``['foo', 'bar']`` order or\n",
      "        ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "        for ``['bar', 'foo']`` order.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the column\n",
      "        names, returning names where the callable function evaluates to True. An\n",
      "        example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "        ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "        parsing time and lower memory usage.\n",
      "    squeeze : bool, default False\n",
      "        If the parsed data only contains one column then return a Series.\n",
      "    \n",
      "        .. deprecated:: 1.4.0\n",
      "            Append ``.squeeze(\"columns\")`` to the call to ``read_csv`` to squeeze\n",
      "            the data.\n",
      "    prefix : str, optional\n",
      "        Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
      "    \n",
      "        .. deprecated:: 1.4.0\n",
      "           Use a list comprehension on the DataFrame's columns after calling ``read_csv``.\n",
      "    mangle_dupe_cols : bool, default True\n",
      "        Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
      "        'X'...'X'. Passing in False will cause data to be overwritten if there\n",
      "        are duplicate names in the columns.\n",
      "    \n",
      "        .. deprecated:: 1.5.0\n",
      "            Not implemented, and a new argument to specify the pattern for the\n",
      "            names of duplicated columns will be added instead\n",
      "    dtype : Type name or dict of column -> type, optional\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
      "        'c': 'Int64'}\n",
      "        Use `str` or `object` together with suitable `na_values` settings\n",
      "        to preserve and not interpret dtype.\n",
      "        If converters are specified, they will be applied INSTEAD\n",
      "        of dtype conversion.\n",
      "    \n",
      "        .. versionadded:: 1.5.0\n",
      "    \n",
      "            Support for defaultdict was added. Specify a defaultdict as input where\n",
      "            the default determines the dtype of the columns which are not explicitly\n",
      "            listed.\n",
      "    engine : {'c', 'python', 'pyarrow'}, optional\n",
      "        Parser engine to use. The C and pyarrow engines are faster, while the python engine\n",
      "        is currently more feature-complete. Multithreading is currently only supported by\n",
      "        the pyarrow engine.\n",
      "    \n",
      "        .. versionadded:: 1.4.0\n",
      "    \n",
      "            The \"pyarrow\" engine was added as an *experimental* engine, and some features\n",
      "            are unsupported, or may not work correctly, with this engine.\n",
      "    converters : dict, optional\n",
      "        Dict of functions for converting values in certain columns. Keys can either\n",
      "        be integers or column labels.\n",
      "    true_values : list, optional\n",
      "        Values to consider as True.\n",
      "    false_values : list, optional\n",
      "        Values to consider as False.\n",
      "    skipinitialspace : bool, default False\n",
      "        Skip spaces after delimiter.\n",
      "    skiprows : list-like, int or callable, optional\n",
      "        Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
      "        at the start of the file.\n",
      "    \n",
      "        If callable, the callable function will be evaluated against the row\n",
      "        indices, returning True if the row should be skipped and False otherwise.\n",
      "        An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "    skipfooter : int, default 0\n",
      "        Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
      "    nrows : int, optional\n",
      "        Number of rows of file to read. Useful for reading pieces of large files.\n",
      "    na_values : scalar, str, list-like, or dict, optional\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values.  By default the following values are interpreted as\n",
      "        NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "        '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
      "        'nan', 'null'.\n",
      "    keep_default_na : bool, default True\n",
      "        Whether or not to include the default NaN values when parsing the data.\n",
      "        Depending on whether `na_values` is passed in, the behavior is as follows:\n",
      "    \n",
      "        * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
      "          is appended to the default NaN values used for parsing.\n",
      "        * If `keep_default_na` is True, and `na_values` are not specified, only\n",
      "          the default NaN values are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are specified, only\n",
      "          the NaN values specified `na_values` are used for parsing.\n",
      "        * If `keep_default_na` is False, and `na_values` are not specified, no\n",
      "          strings will be parsed as NaN.\n",
      "    \n",
      "        Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
      "        `na_values` parameters will be ignored.\n",
      "    na_filter : bool, default True\n",
      "        Detect missing value markers (empty strings and the value of na_values). In\n",
      "        data without any NAs, passing na_filter=False can improve the performance\n",
      "        of reading a large file.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of NA values placed in non-numeric columns.\n",
      "    skip_blank_lines : bool, default True\n",
      "        If True, skip over blank lines rather than interpreting as NaN values.\n",
      "    parse_dates : bool or list of int or names or list of lists or dict, default False\n",
      "        The behavior is as follows:\n",
      "    \n",
      "        * boolean. If True -> try parsing the index.\n",
      "        * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "          a single date column.\n",
      "        * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
      "          result 'foo'\n",
      "    \n",
      "        If a column or index cannot be represented as an array of datetimes,\n",
      "        say because of an unparsable value or a mixture of timezones, the column\n",
      "        or index will be returned unaltered as an object data type. For\n",
      "        non-standard datetime parsing, use ``pd.to_datetime`` after\n",
      "        ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
      "        specify ``date_parser`` to be a partially-applied\n",
      "        :func:`pandas.to_datetime` with ``utc=True``. See\n",
      "        :ref:`io.csv.mixed_timezones` for more.\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    infer_datetime_format : bool, default False\n",
      "        If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
      "        format of the datetime strings in the columns, and if it can be inferred,\n",
      "        switch to a faster method of parsing them. In some cases this can increase\n",
      "        the parsing speed by 5-10x.\n",
      "    keep_date_col : bool, default False\n",
      "        If True and `parse_dates` specifies combining multiple columns then\n",
      "        keep the original columns.\n",
      "    date_parser : function, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by `parse_dates` into a single array\n",
      "        and pass that; and 3) call `date_parser` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "        arguments.\n",
      "    dayfirst : bool, default False\n",
      "        DD/MM format dates, international and European format.\n",
      "    cache_dates : bool, default True\n",
      "        If True, use a cache of unique, converted dates to apply the datetime\n",
      "        conversion. May produce significant speed-up when parsing duplicate\n",
      "        date strings, especially ones with timezone offsets.\n",
      "    \n",
      "        .. versionadded:: 0.25.0\n",
      "    iterator : bool, default False\n",
      "        Return TextFileReader object for iteration or getting chunks with\n",
      "        ``get_chunk()``.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           ``TextFileReader`` is a context manager.\n",
      "    chunksize : int, optional\n",
      "        Return TextFileReader object for iteration.\n",
      "        See the `IO Tools docs\n",
      "        <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "        for more information on ``iterator`` and ``chunksize``.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           ``TextFileReader`` is a context manager.\n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer' and 'filepath_or_buffer' is\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "        (otherwise no compression).\n",
      "        If using 'zip' or 'tar', the ZIP file must contain only one data file to be read in.\n",
      "        Set to ``None`` for no decompression.\n",
      "        Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      "        key-value pairs are forwarded to\n",
      "        ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, ``zstandard.ZstdDecompressor`` or\n",
      "        ``tarfile.TarFile``, respectively.\n",
      "        As an example, the following could be passed for Zstandard decompression using a\n",
      "        custom compression dictionary:\n",
      "        ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
      "    \n",
      "            .. versionadded:: 1.5.0\n",
      "                Added support for `.tar` files.\n",
      "    \n",
      "        .. versionchanged:: 1.4.0 Zstandard support.\n",
      "    \n",
      "    thousands : str, optional\n",
      "        Thousands separator.\n",
      "    decimal : str, default '.'\n",
      "        Character to recognize as decimal point (e.g. use ',' for European data).\n",
      "    lineterminator : str (length 1), optional\n",
      "        Character to break file into lines. Only valid with C parser.\n",
      "    quotechar : str (length 1), optional\n",
      "        The character used to denote the start and end of a quoted item. Quoted\n",
      "        items can include the delimiter and it will be ignored.\n",
      "    quoting : int or csv.QUOTE_* instance, default 0\n",
      "        Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
      "        QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
      "    doublequote : bool, default ``True``\n",
      "       When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
      "       whether or not to interpret two consecutive quotechar elements INSIDE a\n",
      "       field as a single ``quotechar`` element.\n",
      "    escapechar : str (length 1), optional\n",
      "        One-character string used to escape other characters.\n",
      "    comment : str, optional\n",
      "        Indicates remainder of line should not be parsed. If found at the beginning\n",
      "        of a line, the line will be ignored altogether. This parameter must be a\n",
      "        single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "        fully commented lines are ignored by the parameter `header` but not by\n",
      "        `skiprows`. For example, if ``comment='#'``, parsing\n",
      "        ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
      "        treated as the header.\n",
      "    encoding : str, optional\n",
      "        Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
      "        standard encodings\n",
      "        <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           When ``encoding`` is ``None``, ``errors=\"replace\"`` is passed to\n",
      "           ``open()``. Otherwise, ``errors=\"strict\"`` is passed to ``open()``.\n",
      "           This behavior was previously only the case for ``engine=\"python\"``.\n",
      "    \n",
      "        .. versionchanged:: 1.3.0\n",
      "    \n",
      "           ``encoding_errors`` is a new argument. ``encoding`` has no longer an\n",
      "           influence on how encoding errors are handled.\n",
      "    \n",
      "    encoding_errors : str, optional, default \"strict\"\n",
      "        How encoding errors are treated. `List of possible values\n",
      "        <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "    dialect : str or csv.Dialect, optional\n",
      "        If provided, this parameter will override values (default or not) for the\n",
      "        following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
      "        `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
      "        override values, a ParserWarning will be issued. See csv.Dialect\n",
      "        documentation for more details.\n",
      "    error_bad_lines : bool, optional, default ``None``\n",
      "        Lines with too many fields (e.g. a csv line with too many commas) will by\n",
      "        default cause an exception to be raised, and no DataFrame will be returned.\n",
      "        If False, then these \"bad lines\" will be dropped from the DataFrame that is\n",
      "        returned.\n",
      "    \n",
      "        .. deprecated:: 1.3.0\n",
      "           The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
      "           encountering a bad line instead.\n",
      "    warn_bad_lines : bool, optional, default ``None``\n",
      "        If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
      "        \"bad line\" will be output.\n",
      "    \n",
      "        .. deprecated:: 1.3.0\n",
      "           The ``on_bad_lines`` parameter should be used instead to specify behavior upon\n",
      "           encountering a bad line instead.\n",
      "    on_bad_lines : {'error', 'warn', 'skip'} or callable, default 'error'\n",
      "        Specifies what to do upon encountering a bad line (a line with too many fields).\n",
      "        Allowed values are :\n",
      "    \n",
      "            - 'error', raise an Exception when a bad line is encountered.\n",
      "            - 'warn', raise a warning when a bad line is encountered and skip that line.\n",
      "            - 'skip', skip bad lines without raising or warning when they are encountered.\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "        .. versionadded:: 1.4.0\n",
      "    \n",
      "            - callable, function with signature\n",
      "              ``(bad_line: list[str]) -> list[str] | None`` that will process a single\n",
      "              bad line. ``bad_line`` is a list of strings split by the ``sep``.\n",
      "              If the function returns ``None``, the bad line will be ignored.\n",
      "              If the function returns a new list of strings with more elements than\n",
      "              expected, a ``ParserWarning`` will be emitted while dropping extra elements.\n",
      "              Only supported when ``engine=\"python\"``\n",
      "    \n",
      "    delim_whitespace : bool, default False\n",
      "        Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
      "        used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
      "        is set to True, nothing should be passed in for the ``delimiter``\n",
      "        parameter.\n",
      "    low_memory : bool, default True\n",
      "        Internally process the file in chunks, resulting in lower memory use\n",
      "        while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "        types either set False, or specify the type with the `dtype` parameter.\n",
      "        Note that the entire file is read into a single DataFrame regardless,\n",
      "        use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
      "        (Only valid with C parser).\n",
      "    memory_map : bool, default False\n",
      "        If a filepath is provided for `filepath_or_buffer`, map the file object\n",
      "        directly onto memory and access the data directly from there. Using this\n",
      "        option can improve performance because there is no longer any I/O overhead.\n",
      "    float_precision : str, optional\n",
      "        Specifies which converter the C engine should use for floating-point\n",
      "        values. The options are ``None`` or 'high' for the ordinary converter,\n",
      "        'legacy' for the original lower precision pandas converter, and\n",
      "        'round_trip' for the round-trip converter.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "    \n",
      "        .. versionadded:: 1.2\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or TextParser\n",
      "        A comma-separated values (csv) file is returned as two-dimensional\n",
      "        data structure with labeled axes.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95c19e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://gist.githubusercontent.com/reuven/bb116ba2034bb10bb7e4e2caa5d8a000/raw/3660c4af808684dbf17af48b3d2f25b6a218535f/CSCO.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b7563a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>38.520000</td>\n",
       "      <td>38.740002</td>\n",
       "      <td>38.470001</td>\n",
       "      <td>38.549999</td>\n",
       "      <td>38.264591</td>\n",
       "      <td>11441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>38.549999</td>\n",
       "      <td>38.680000</td>\n",
       "      <td>38.360001</td>\n",
       "      <td>38.480000</td>\n",
       "      <td>38.195110</td>\n",
       "      <td>8186100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>38.540001</td>\n",
       "      <td>38.650002</td>\n",
       "      <td>38.450001</td>\n",
       "      <td>38.560001</td>\n",
       "      <td>38.274517</td>\n",
       "      <td>10543000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>38.730000</td>\n",
       "      <td>38.730000</td>\n",
       "      <td>38.450001</td>\n",
       "      <td>38.590000</td>\n",
       "      <td>38.304295</td>\n",
       "      <td>8807700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>38.410000</td>\n",
       "      <td>38.619999</td>\n",
       "      <td>38.299999</td>\n",
       "      <td>38.299999</td>\n",
       "      <td>38.016441</td>\n",
       "      <td>12583600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>38.669998</td>\n",
       "      <td>38.950001</td>\n",
       "      <td>38.430000</td>\n",
       "      <td>38.860001</td>\n",
       "      <td>38.572296</td>\n",
       "      <td>20135700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>38.720001</td>\n",
       "      <td>39.279999</td>\n",
       "      <td>38.529999</td>\n",
       "      <td>39.169998</td>\n",
       "      <td>38.879997</td>\n",
       "      <td>29536000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>39.049999</td>\n",
       "      <td>39.540001</td>\n",
       "      <td>38.930000</td>\n",
       "      <td>38.990002</td>\n",
       "      <td>38.990002</td>\n",
       "      <td>20731400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>39.549999</td>\n",
       "      <td>39.880001</td>\n",
       "      <td>39.369999</td>\n",
       "      <td>39.529999</td>\n",
       "      <td>39.529999</td>\n",
       "      <td>24588200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>39.520000</td>\n",
       "      <td>39.959999</td>\n",
       "      <td>39.349998</td>\n",
       "      <td>39.939999</td>\n",
       "      <td>39.939999</td>\n",
       "      <td>16582000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>39.790001</td>\n",
       "      <td>39.959999</td>\n",
       "      <td>39.540001</td>\n",
       "      <td>39.689999</td>\n",
       "      <td>39.689999</td>\n",
       "      <td>21449800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>39.650002</td>\n",
       "      <td>40.240002</td>\n",
       "      <td>39.630001</td>\n",
       "      <td>39.910000</td>\n",
       "      <td>39.910000</td>\n",
       "      <td>19473000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>40.139999</td>\n",
       "      <td>40.209999</td>\n",
       "      <td>39.750000</td>\n",
       "      <td>40.099998</td>\n",
       "      <td>40.099998</td>\n",
       "      <td>21685600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>40.220001</td>\n",
       "      <td>40.930000</td>\n",
       "      <td>40.049999</td>\n",
       "      <td>40.869999</td>\n",
       "      <td>40.869999</td>\n",
       "      <td>23770500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>40.900002</td>\n",
       "      <td>41.160000</td>\n",
       "      <td>40.320000</td>\n",
       "      <td>40.540001</td>\n",
       "      <td>40.540001</td>\n",
       "      <td>32845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-17</td>\n",
       "      <td>40.840000</td>\n",
       "      <td>41.320000</td>\n",
       "      <td>40.709999</td>\n",
       "      <td>41.200001</td>\n",
       "      <td>41.200001</td>\n",
       "      <td>24427100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>41.240002</td>\n",
       "      <td>41.480000</td>\n",
       "      <td>41.029999</td>\n",
       "      <td>41.299999</td>\n",
       "      <td>41.299999</td>\n",
       "      <td>19610200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>41.279999</td>\n",
       "      <td>41.520000</td>\n",
       "      <td>41.099998</td>\n",
       "      <td>41.290001</td>\n",
       "      <td>41.290001</td>\n",
       "      <td>24207800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>41.200001</td>\n",
       "      <td>41.520000</td>\n",
       "      <td>41.020000</td>\n",
       "      <td>41.340000</td>\n",
       "      <td>41.340000</td>\n",
       "      <td>6792482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date       Open       High        Low      Close  Adj Close  \\\n",
       "0   2017-12-22  38.520000  38.740002  38.470001  38.549999  38.264591   \n",
       "1   2017-12-26  38.549999  38.680000  38.360001  38.480000  38.195110   \n",
       "2   2017-12-27  38.540001  38.650002  38.450001  38.560001  38.274517   \n",
       "3   2017-12-28  38.730000  38.730000  38.450001  38.590000  38.304295   \n",
       "4   2017-12-29  38.410000  38.619999  38.299999  38.299999  38.016441   \n",
       "5   2018-01-02  38.669998  38.950001  38.430000  38.860001  38.572296   \n",
       "6   2018-01-03  38.720001  39.279999  38.529999  39.169998  38.879997   \n",
       "7   2018-01-04  39.049999  39.540001  38.930000  38.990002  38.990002   \n",
       "8   2018-01-05  39.549999  39.880001  39.369999  39.529999  39.529999   \n",
       "9   2018-01-08  39.520000  39.959999  39.349998  39.939999  39.939999   \n",
       "10  2018-01-09  39.790001  39.959999  39.540001  39.689999  39.689999   \n",
       "11  2018-01-10  39.650002  40.240002  39.630001  39.910000  39.910000   \n",
       "12  2018-01-11  40.139999  40.209999  39.750000  40.099998  40.099998   \n",
       "13  2018-01-12  40.220001  40.930000  40.049999  40.869999  40.869999   \n",
       "14  2018-01-16  40.900002  41.160000  40.320000  40.540001  40.540001   \n",
       "15  2018-01-17  40.840000  41.320000  40.709999  41.200001  41.200001   \n",
       "16  2018-01-18  41.240002  41.480000  41.029999  41.299999  41.299999   \n",
       "17  2018-01-19  41.279999  41.520000  41.099998  41.290001  41.290001   \n",
       "18  2018-01-22  41.200001  41.520000  41.020000  41.340000  41.340000   \n",
       "\n",
       "      Volume  \n",
       "0   11441600  \n",
       "1    8186100  \n",
       "2   10543000  \n",
       "3    8807700  \n",
       "4   12583600  \n",
       "5   20135700  \n",
       "6   29536000  \n",
       "7   20731400  \n",
       "8   24588200  \n",
       "9   16582000  \n",
       "10  21449800  \n",
       "11  19473000  \n",
       "12  21685600  \n",
       "13  23770500  \n",
       "14  32845000  \n",
       "15  24427100  \n",
       "16  19610200  \n",
       "17  24207800  \n",
       "18   6792482  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05ce5d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest Bitcoin prices are at https://api.blockchain.info/charts/market-price?format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8da3186e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2021-11-29 00:00:00</th>\n",
       "      <th>57292.28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-30 00:00:00</td>\n",
       "      <td>57828.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-01 00:00:00</td>\n",
       "      <td>57025.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-02 00:00:00</td>\n",
       "      <td>57229.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-03 00:00:00</td>\n",
       "      <td>56508.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-04 00:00:00</td>\n",
       "      <td>53713.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2021-11-29 00:00:00  57292.28\n",
       "0  2021-11-30 00:00:00  57828.45\n",
       "1  2021-12-01 00:00:00  57025.79\n",
       "2  2021-12-02 00:00:00  57229.76\n",
       "3  2021-12-03 00:00:00  56508.48\n",
       "4  2021-12-04 00:00:00  53713.84"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://api.blockchain.info/charts/market-price?format=csv'\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7daeda5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2021-11-29 00:00:00</th>\n",
       "      <th>57292.28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2022-11-25 00:00:00</td>\n",
       "      <td>16592.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2022-11-26 00:00:00</td>\n",
       "      <td>16507.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2022-11-27 00:00:00</td>\n",
       "      <td>16453.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2022-11-28 00:00:00</td>\n",
       "      <td>16420.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2022-11-29 00:00:00</td>\n",
       "      <td>16208.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     2021-11-29 00:00:00  57292.28\n",
       "360  2022-11-25 00:00:00  16592.67\n",
       "361  2022-11-26 00:00:00  16507.44\n",
       "362  2022-11-27 00:00:00  16453.47\n",
       "363  2022-11-28 00:00:00  16420.20\n",
       "364  2022-11-29 00:00:00  16208.96"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "969a3dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bitcoin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-11-29 00:00:00</th>\n",
       "      <td>57292.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 00:00:00</th>\n",
       "      <td>57828.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-01 00:00:00</th>\n",
       "      <td>57025.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-02 00:00:00</th>\n",
       "      <td>57229.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-03 00:00:00</th>\n",
       "      <td>56508.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      bitcoin\n",
       "date                         \n",
       "2021-11-29 00:00:00  57292.28\n",
       "2021-11-30 00:00:00  57828.45\n",
       "2021-12-01 00:00:00  57025.79\n",
       "2021-12-02 00:00:00  57229.76\n",
       "2021-12-03 00:00:00  56508.48"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(url,\n",
    "                 header=None,\n",
    "                 names=['date', 'bitcoin'],\n",
    "                 index_col='date')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5355050c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bitcoin    20223.69\n",
       "Name: 2022-07-14 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['2022-07-14 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f5c0a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's say that I like the GDP data in Wikipedia\n",
    "# I'd like to read it into Pandas, into a data frame\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)'\n",
    "\n",
    "# read_html retrieves every HTML table on that web page into a data frame\n",
    "# you get back a list of data frames, one per HTML table\n",
    "all_dfs = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01feeb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Country/Territory</th>\n",
       "      <th>UN Region</th>\n",
       "      <th colspan=\"2\" halign=\"left\">IMF[1][13]</th>\n",
       "      <th colspan=\"2\" halign=\"left\">World Bank[14]</th>\n",
       "      <th colspan=\"2\" halign=\"left\">United Nations[15]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Country/Territory</th>\n",
       "      <th>UN Region</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World</td>\n",
       "      <td>—</td>\n",
       "      <td>101560901</td>\n",
       "      <td>2022</td>\n",
       "      <td>96100091</td>\n",
       "      <td>2021</td>\n",
       "      <td>85328323</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>Americas</td>\n",
       "      <td>25035164</td>\n",
       "      <td>2022</td>\n",
       "      <td>22996100</td>\n",
       "      <td>2021</td>\n",
       "      <td>20893746</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "      <td>18321197</td>\n",
       "      <td>[n 1]2022</td>\n",
       "      <td>17734063</td>\n",
       "      <td>[n 3]2021</td>\n",
       "      <td>14722801</td>\n",
       "      <td>[n 1]2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>European Union[n 4]</td>\n",
       "      <td>Europe</td>\n",
       "      <td>16613060</td>\n",
       "      <td>2022</td>\n",
       "      <td>17088621</td>\n",
       "      <td>2021</td>\n",
       "      <td>15292201</td>\n",
       "      <td>[16]2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>4300621</td>\n",
       "      <td>2022</td>\n",
       "      <td>4937422</td>\n",
       "      <td>2021</td>\n",
       "      <td>5057759</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Palau</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>226</td>\n",
       "      <td>2022</td>\n",
       "      <td>258</td>\n",
       "      <td>2020</td>\n",
       "      <td>264</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Kiribati</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>207</td>\n",
       "      <td>2022</td>\n",
       "      <td>181</td>\n",
       "      <td>2020</td>\n",
       "      <td>181</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Nauru</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>134</td>\n",
       "      <td>2022</td>\n",
       "      <td>133</td>\n",
       "      <td>2021</td>\n",
       "      <td>135</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Montserrat</td>\n",
       "      <td>Americas</td>\n",
       "      <td>—</td>\n",
       "      <td>—</td>\n",
       "      <td>—</td>\n",
       "      <td>—</td>\n",
       "      <td>68</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>64</td>\n",
       "      <td>2022</td>\n",
       "      <td>63</td>\n",
       "      <td>2021</td>\n",
       "      <td>55</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country/Territory UN Region IMF[1][13]            World Bank[14]  \\\n",
       "       Country/Territory UN Region   Estimate       Year       Estimate   \n",
       "0                  World         —  101560901       2022       96100091   \n",
       "1          United States  Americas   25035164       2022       22996100   \n",
       "2                  China      Asia   18321197  [n 1]2022       17734063   \n",
       "3    European Union[n 4]    Europe   16613060       2022       17088621   \n",
       "4                  Japan      Asia    4300621       2022        4937422   \n",
       "..                   ...       ...        ...        ...            ...   \n",
       "213                Palau   Oceania        226       2022            258   \n",
       "214             Kiribati   Oceania        207       2022            181   \n",
       "215                Nauru   Oceania        134       2022            133   \n",
       "216           Montserrat  Americas          —          —              —   \n",
       "217               Tuvalu   Oceania         64       2022             63   \n",
       "\n",
       "               United Nations[15]             \n",
       "          Year           Estimate       Year  \n",
       "0         2021           85328323       2020  \n",
       "1         2021           20893746       2020  \n",
       "2    [n 3]2021           14722801  [n 1]2020  \n",
       "3         2021           15292201   [16]2020  \n",
       "4         2021            5057759       2020  \n",
       "..         ...                ...        ...  \n",
       "213       2020                264       2020  \n",
       "214       2020                181       2020  \n",
       "215       2021                135       2020  \n",
       "216          —                 68       2020  \n",
       "217       2021                 55       2020  \n",
       "\n",
       "[218 rows x 8 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dfs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "47fd3c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_dfs[3]\n",
    "df.columns=['country', 'un_region', 'imf_estimate', 'imf_year', 'wb_estimate', 'wb_year', 'un_estimate', 'un_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d32b6c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>un_region</th>\n",
       "      <th>imf_estimate</th>\n",
       "      <th>imf_year</th>\n",
       "      <th>wb_estimate</th>\n",
       "      <th>wb_year</th>\n",
       "      <th>un_estimate</th>\n",
       "      <th>un_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World</td>\n",
       "      <td>—</td>\n",
       "      <td>101560901</td>\n",
       "      <td>2022</td>\n",
       "      <td>96100091</td>\n",
       "      <td>2021</td>\n",
       "      <td>85328323</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>Americas</td>\n",
       "      <td>25035164</td>\n",
       "      <td>2022</td>\n",
       "      <td>22996100</td>\n",
       "      <td>2021</td>\n",
       "      <td>20893746</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "      <td>18321197</td>\n",
       "      <td>[n 1]2022</td>\n",
       "      <td>17734063</td>\n",
       "      <td>[n 3]2021</td>\n",
       "      <td>14722801</td>\n",
       "      <td>[n 1]2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>European Union[n 4]</td>\n",
       "      <td>Europe</td>\n",
       "      <td>16613060</td>\n",
       "      <td>2022</td>\n",
       "      <td>17088621</td>\n",
       "      <td>2021</td>\n",
       "      <td>15292201</td>\n",
       "      <td>[16]2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>4300621</td>\n",
       "      <td>2022</td>\n",
       "      <td>4937422</td>\n",
       "      <td>2021</td>\n",
       "      <td>5057759</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Palau</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>226</td>\n",
       "      <td>2022</td>\n",
       "      <td>258</td>\n",
       "      <td>2020</td>\n",
       "      <td>264</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Kiribati</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>207</td>\n",
       "      <td>2022</td>\n",
       "      <td>181</td>\n",
       "      <td>2020</td>\n",
       "      <td>181</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Nauru</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>134</td>\n",
       "      <td>2022</td>\n",
       "      <td>133</td>\n",
       "      <td>2021</td>\n",
       "      <td>135</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Montserrat</td>\n",
       "      <td>Americas</td>\n",
       "      <td>—</td>\n",
       "      <td>—</td>\n",
       "      <td>—</td>\n",
       "      <td>—</td>\n",
       "      <td>68</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>64</td>\n",
       "      <td>2022</td>\n",
       "      <td>63</td>\n",
       "      <td>2021</td>\n",
       "      <td>55</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 country un_region imf_estimate   imf_year wb_estimate  \\\n",
       "0                  World         —    101560901       2022    96100091   \n",
       "1          United States  Americas     25035164       2022    22996100   \n",
       "2                  China      Asia     18321197  [n 1]2022    17734063   \n",
       "3    European Union[n 4]    Europe     16613060       2022    17088621   \n",
       "4                  Japan      Asia      4300621       2022     4937422   \n",
       "..                   ...       ...          ...        ...         ...   \n",
       "213                Palau   Oceania          226       2022         258   \n",
       "214             Kiribati   Oceania          207       2022         181   \n",
       "215                Nauru   Oceania          134       2022         133   \n",
       "216           Montserrat  Americas            —          —           —   \n",
       "217               Tuvalu   Oceania           64       2022          63   \n",
       "\n",
       "       wb_year un_estimate    un_year  \n",
       "0         2021    85328323       2020  \n",
       "1         2021    20893746       2020  \n",
       "2    [n 3]2021    14722801  [n 1]2020  \n",
       "3         2021    15292201   [16]2020  \n",
       "4         2021     5057759       2020  \n",
       "..         ...         ...        ...  \n",
       "213       2020         264       2020  \n",
       "214       2020         181       2020  \n",
       "215       2021         135       2020  \n",
       "216          —          68       2020  \n",
       "217       2021          55       2020  \n",
       "\n",
       "[218 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe49fff",
   "metadata": {},
   "source": [
    "# Exercise: Blockchain downloads\n",
    "\n",
    "Bitcoin info: 'https://api.blockchain.info/charts/market-price?format=csv'\n",
    "\n",
    "1. Create a data frame from the Bitcoin info, in which the date is the index.\n",
    "2. On which date was Bitcoin at its highest value?\n",
    "3. On which date was it at its lowest value? (The info only goes back one year, I believe.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2a875934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>btc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-11-29 00:00:00</th>\n",
       "      <td>57292.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 00:00:00</th>\n",
       "      <td>57828.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-01 00:00:00</th>\n",
       "      <td>57025.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-02 00:00:00</th>\n",
       "      <td>57229.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-03 00:00:00</th>\n",
       "      <td>56508.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          btc\n",
       "date                         \n",
       "2021-11-29 00:00:00  57292.28\n",
       "2021-11-30 00:00:00  57828.45\n",
       "2021-12-01 00:00:00  57025.79\n",
       "2021-12-02 00:00:00  57229.76\n",
       "2021-12-03 00:00:00  56508.48"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://api.blockchain.info/charts/market-price?format=csv'\n",
    "\n",
    "df = pd.read_csv(url,\n",
    "                 header=None,\n",
    "                names=['date', 'btc'],\n",
    "                index_col='date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "803a5892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>btc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-11-30 00:00:00</th>\n",
       "      <td>57828.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          btc\n",
       "date                         \n",
       "2021-11-30 00:00:00  57828.45"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on which date was bitcoin at its highest value?\n",
    "df.loc[df['btc'] == df['btc'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "93c2d24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>btc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-22 00:00:00</th>\n",
       "      <td>15759.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          btc\n",
       "date                         \n",
       "2022-11-22 00:00:00  15759.61"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On which date was it at its lowest value?\n",
    "\n",
    "df.loc[df['btc'] == df['btc'].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe61e74",
   "metadata": {},
   "source": [
    "# Good sources for interesting datasets\n",
    "\n",
    "1. https://www.kaggle.com/datasets\n",
    "2. https://github.com/awesomedata/awesome-public-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9267c5a",
   "metadata": {},
   "source": [
    "# Next up\n",
    "\n",
    "1. Sorting\n",
    "2. Basic grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cd06a0",
   "metadata": {},
   "source": [
    "# Sorting\n",
    "\n",
    "It's common for us to want to sort our data.  If I just want to pick out the highest value, or the lowest value, I can do that with a boolean index and grabbing the first or last value.  But if I'm going to want the 10 largest values, then sorting is going to be more useful.  Also, if I'm going to *look* at the data, then sorting can be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cb8e3f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/reuven/Courses/Current/data/winemag-150k-reviews.csv'\n",
    "\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2c5210c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>Martha's Vineyard</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Heitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>Carodorum Selección Especial Reserva</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>Bodega Carmen Rodríguez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>Special Selected Late Harvest</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Macauley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Ponzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>La Brûlade</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Bandol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provence red blend</td>\n",
       "      <td>Domaine de la Bégude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 country                                        description  \\\n",
       "0           0      US  This tremendous 100% varietal wine hails from ...   \n",
       "1           1   Spain  Ripe aromas of fig, blackberry and cassis are ...   \n",
       "2           2      US  Mac Watson honors the memory of a wine once ma...   \n",
       "3           3      US  This spent 20 months in 30% new French oak, an...   \n",
       "4           4  France  This is the top wine from La Bégude, named aft...   \n",
       "\n",
       "                            designation  points  price        province  \\\n",
       "0                     Martha's Vineyard      96  235.0      California   \n",
       "1  Carodorum Selección Especial Reserva      96  110.0  Northern Spain   \n",
       "2         Special Selected Late Harvest      96   90.0      California   \n",
       "3                               Reserve      96   65.0          Oregon   \n",
       "4                            La Brûlade      95   66.0        Provence   \n",
       "\n",
       "            region_1           region_2             variety  \\\n",
       "0        Napa Valley               Napa  Cabernet Sauvignon   \n",
       "1               Toro                NaN       Tinta de Toro   \n",
       "2     Knights Valley             Sonoma     Sauvignon Blanc   \n",
       "3  Willamette Valley  Willamette Valley          Pinot Noir   \n",
       "4             Bandol                NaN  Provence red blend   \n",
       "\n",
       "                    winery  \n",
       "0                    Heitz  \n",
       "1  Bodega Carmen Rodríguez  \n",
       "2                 Macauley  \n",
       "3                    Ponzi  \n",
       "4     Domaine de la Bégude  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the 10 most expensive wines in this database?\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "29d06e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90546</th>\n",
       "      <td>90546</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Clean as anyone should reasonably expect given...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mendoza Province</td>\n",
       "      <td>Mendoza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Malbec</td>\n",
       "      <td>Toca Diamonte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25645</th>\n",
       "      <td>25645</td>\n",
       "      <td>US</td>\n",
       "      <td>There's a lot going on in this Merlot, which i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "      <td>4.0</td>\n",
       "      <td>California</td>\n",
       "      <td>California</td>\n",
       "      <td>California Other</td>\n",
       "      <td>Merlot</td>\n",
       "      <td>Bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118347</th>\n",
       "      <td>118347</td>\n",
       "      <td>US</td>\n",
       "      <td>Light and earthy, this wine-in-a-box is clean ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>4.0</td>\n",
       "      <td>California</td>\n",
       "      <td>California</td>\n",
       "      <td>California Other</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Bandit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>1858</td>\n",
       "      <td>US</td>\n",
       "      <td>Sweet and fruity, this canned wine feels soft ...</td>\n",
       "      <td>Unoaked</td>\n",
       "      <td>83</td>\n",
       "      <td>4.0</td>\n",
       "      <td>California</td>\n",
       "      <td>California</td>\n",
       "      <td>California Other</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>Pam's Cuties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91766</th>\n",
       "      <td>91766</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Crimson in color but also translucent, with a ...</td>\n",
       "      <td>Red</td>\n",
       "      <td>84</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mendoza Province</td>\n",
       "      <td>Mendoza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Malbec-Syrah</td>\n",
       "      <td>Broke Ass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150377</th>\n",
       "      <td>150377</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Light and a bit herbal, like a pleasant St.-Jo...</td>\n",
       "      <td>Matheson</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hawke's Bay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Syrah</td>\n",
       "      <td>Matua Valley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150378</th>\n",
       "      <td>150378</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Impressive purple color, but less intense on t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Martinborough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Syrah</td>\n",
       "      <td>Kusuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150587</th>\n",
       "      <td>150587</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Shows pronounced oily, earthy, almost tobacco-...</td>\n",
       "      <td>Icewine</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Lake Erie North Shore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>Colio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150673</th>\n",
       "      <td>150673</td>\n",
       "      <td>US</td>\n",
       "      <td>Cherry-scented, clean and fruity. Good concent...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California</td>\n",
       "      <td>Dry Creek Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Zinfandel</td>\n",
       "      <td>Taft Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150922</th>\n",
       "      <td>150922</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Made by 30-ish Roberta Borghese high above Man...</td>\n",
       "      <td>Superiore</td>\n",
       "      <td>91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northeastern Italy</td>\n",
       "      <td>Colli Orientali del Friuli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tocai</td>\n",
       "      <td>Ronchi di Manzano</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150930 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      country  \\\n",
       "90546        90546    Argentina   \n",
       "25645        25645           US   \n",
       "118347      118347           US   \n",
       "1858          1858           US   \n",
       "91766        91766    Argentina   \n",
       "...            ...          ...   \n",
       "150377      150377  New Zealand   \n",
       "150378      150378  New Zealand   \n",
       "150587      150587       Canada   \n",
       "150673      150673           US   \n",
       "150922      150922        Italy   \n",
       "\n",
       "                                              description designation  points  \\\n",
       "90546   Clean as anyone should reasonably expect given...         NaN      85   \n",
       "25645   There's a lot going on in this Merlot, which i...         NaN      86   \n",
       "118347  Light and earthy, this wine-in-a-box is clean ...         NaN      84   \n",
       "1858    Sweet and fruity, this canned wine feels soft ...     Unoaked      83   \n",
       "91766   Crimson in color but also translucent, with a ...         Red      84   \n",
       "...                                                   ...         ...     ...   \n",
       "150377  Light and a bit herbal, like a pleasant St.-Jo...    Matheson      84   \n",
       "150378  Impressive purple color, but less intense on t...         NaN      84   \n",
       "150587  Shows pronounced oily, earthy, almost tobacco-...     Icewine      90   \n",
       "150673  Cherry-scented, clean and fruity. Good concent...         NaN      87   \n",
       "150922  Made by 30-ish Roberta Borghese high above Man...   Superiore      91   \n",
       "\n",
       "        price            province                    region_1  \\\n",
       "90546     4.0    Mendoza Province                     Mendoza   \n",
       "25645     4.0          California                  California   \n",
       "118347    4.0          California                  California   \n",
       "1858      4.0          California                  California   \n",
       "91766     4.0    Mendoza Province                     Mendoza   \n",
       "...       ...                 ...                         ...   \n",
       "150377    NaN         Hawke's Bay                         NaN   \n",
       "150378    NaN       Martinborough                         NaN   \n",
       "150587    NaN             Ontario       Lake Erie North Shore   \n",
       "150673    NaN          California            Dry Creek Valley   \n",
       "150922    NaN  Northeastern Italy  Colli Orientali del Friuli   \n",
       "\n",
       "                region_2             variety             winery  \n",
       "90546                NaN              Malbec      Toca Diamonte  \n",
       "25645   California Other              Merlot             Bandit  \n",
       "118347  California Other  Cabernet Sauvignon             Bandit  \n",
       "1858    California Other          Chardonnay       Pam's Cuties  \n",
       "91766                NaN        Malbec-Syrah          Broke Ass  \n",
       "...                  ...                 ...                ...  \n",
       "150377               NaN               Syrah       Matua Valley  \n",
       "150378               NaN               Syrah             Kusuda  \n",
       "150587               NaN            Riesling              Colio  \n",
       "150673            Sonoma           Zinfandel        Taft Street  \n",
       "150922               NaN               Tocai  Ronchi di Manzano  \n",
       "\n",
       "[150930 rows x 11 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to sort the rows of df by the \"price\" column\n",
    "\n",
    "df.sort_values('price')  \n",
    "\n",
    "# (1) The rows are sorted in ascending order (from lowest to highest)\n",
    "# (2) We haven't modified df -- rather, we got a new data frame back from .sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6fc9d618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150255</th>\n",
       "      <td>150255</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Starts with scents of anise and blackberry, th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hawke's Bay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Syrah</td>\n",
       "      <td>Vidal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150260</th>\n",
       "      <td>150260</td>\n",
       "      <td>France</td>\n",
       "      <td>Always reliable, Hanteillan has reflected the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>Haut-Médoc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>Château Hanteillan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150261</th>\n",
       "      <td>150261</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>A bit heavy for Riesling, with pretty pear and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waipara</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>Daniel Schuster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150319</th>\n",
       "      <td>150319</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>A bit jammy, with aromas and flavors of slight...</td>\n",
       "      <td>Innovator Bullrush</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hawke's Bay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Syrah</td>\n",
       "      <td>Matua Valley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150322</th>\n",
       "      <td>150322</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Impressively dark in color, but shows more woo...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hawke's Bay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Syrah</td>\n",
       "      <td>CJ Pask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150377</th>\n",
       "      <td>150377</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Light and a bit herbal, like a pleasant St.-Jo...</td>\n",
       "      <td>Matheson</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hawke's Bay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Syrah</td>\n",
       "      <td>Matua Valley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150378</th>\n",
       "      <td>150378</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Impressive purple color, but less intense on t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Martinborough</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Syrah</td>\n",
       "      <td>Kusuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150587</th>\n",
       "      <td>150587</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Shows pronounced oily, earthy, almost tobacco-...</td>\n",
       "      <td>Icewine</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Lake Erie North Shore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>Colio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150673</th>\n",
       "      <td>150673</td>\n",
       "      <td>US</td>\n",
       "      <td>Cherry-scented, clean and fruity. Good concent...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California</td>\n",
       "      <td>Dry Creek Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Zinfandel</td>\n",
       "      <td>Taft Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150922</th>\n",
       "      <td>150922</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Made by 30-ish Roberta Borghese high above Man...</td>\n",
       "      <td>Superiore</td>\n",
       "      <td>91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northeastern Italy</td>\n",
       "      <td>Colli Orientali del Friuli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tocai</td>\n",
       "      <td>Ronchi di Manzano</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      country  \\\n",
       "150255      150255  New Zealand   \n",
       "150260      150260       France   \n",
       "150261      150261  New Zealand   \n",
       "150319      150319  New Zealand   \n",
       "150322      150322  New Zealand   \n",
       "150377      150377  New Zealand   \n",
       "150378      150378  New Zealand   \n",
       "150587      150587       Canada   \n",
       "150673      150673           US   \n",
       "150922      150922        Italy   \n",
       "\n",
       "                                              description         designation  \\\n",
       "150255  Starts with scents of anise and blackberry, th...                 NaN   \n",
       "150260  Always reliable, Hanteillan has reflected the ...                 NaN   \n",
       "150261  A bit heavy for Riesling, with pretty pear and...                 NaN   \n",
       "150319  A bit jammy, with aromas and flavors of slight...  Innovator Bullrush   \n",
       "150322  Impressively dark in color, but shows more woo...             Reserve   \n",
       "150377  Light and a bit herbal, like a pleasant St.-Jo...            Matheson   \n",
       "150378  Impressive purple color, but less intense on t...                 NaN   \n",
       "150587  Shows pronounced oily, earthy, almost tobacco-...             Icewine   \n",
       "150673  Cherry-scented, clean and fruity. Good concent...                 NaN   \n",
       "150922  Made by 30-ish Roberta Borghese high above Man...           Superiore   \n",
       "\n",
       "        points  price            province                    region_1  \\\n",
       "150255      85    NaN         Hawke's Bay                         NaN   \n",
       "150260      85    NaN            Bordeaux                  Haut-Médoc   \n",
       "150261      85    NaN             Waipara                         NaN   \n",
       "150319      85    NaN         Hawke's Bay                         NaN   \n",
       "150322      84    NaN         Hawke's Bay                         NaN   \n",
       "150377      84    NaN         Hawke's Bay                         NaN   \n",
       "150378      84    NaN       Martinborough                         NaN   \n",
       "150587      90    NaN             Ontario       Lake Erie North Shore   \n",
       "150673      87    NaN          California            Dry Creek Valley   \n",
       "150922      91    NaN  Northeastern Italy  Colli Orientali del Friuli   \n",
       "\n",
       "       region_2                   variety              winery  \n",
       "150255      NaN                     Syrah               Vidal  \n",
       "150260      NaN  Bordeaux-style Red Blend  Château Hanteillan  \n",
       "150261      NaN                  Riesling     Daniel Schuster  \n",
       "150319      NaN                     Syrah        Matua Valley  \n",
       "150322      NaN                     Syrah             CJ Pask  \n",
       "150377      NaN                     Syrah        Matua Valley  \n",
       "150378      NaN                     Syrah              Kusuda  \n",
       "150587      NaN                  Riesling               Colio  \n",
       "150673   Sonoma                 Zinfandel         Taft Street  \n",
       "150922      NaN                     Tocai   Ronchi di Manzano  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since we're sorting by price, in ascending order, the 10 most expensive wines will be\n",
    "# the 10 final rows\n",
    "\n",
    "df.sort_values('price').tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "20913b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/reuven/Courses/Current/data/winemag-150k-reviews.csv'\n",
    "\n",
    "df = pd.read_csv(filename,\n",
    "                usecols=['country', 'variety', 'price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed577f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34927</th>\n",
       "      <td>France</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10651</th>\n",
       "      <td>Austria</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>Grüner Veltliner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34942</th>\n",
       "      <td>France</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34939</th>\n",
       "      <td>France</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83536</th>\n",
       "      <td>France</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>Chardonnay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26296</th>\n",
       "      <td>France</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>Chardonnay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51886</th>\n",
       "      <td>France</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>Chardonnay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34922</th>\n",
       "      <td>France</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13318</th>\n",
       "      <td>US</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Chardonnay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34920</th>\n",
       "      <td>France</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country   price                   variety\n",
       "34927   France  1100.0  Bordeaux-style Red Blend\n",
       "10651  Austria  1100.0          Grüner Veltliner\n",
       "34942   France  1200.0  Bordeaux-style Red Blend\n",
       "34939   France  1300.0  Bordeaux-style Red Blend\n",
       "83536   France  1400.0                Chardonnay\n",
       "26296   France  1400.0                Chardonnay\n",
       "51886   France  1400.0                Chardonnay\n",
       "34922   France  1900.0  Bordeaux-style Red Blend\n",
       "13318       US  2013.0                Chardonnay\n",
       "34920   France  2300.0  Bordeaux-style Red Blend"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, I:\n",
    "\n",
    "# (1) removed rows containing NaN\n",
    "# (2) sorted the remaining rows by price, in ascending order\n",
    "# (3) look at the final 10 rows of what remains\n",
    "\n",
    "df.dropna().sort_values('price').tail(10)  # remove all rows containing NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f031b90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method sort_values in module pandas.core.frame:\n",
      "\n",
      "sort_values(by: 'IndexLabel', *, axis: 'Axis' = 0, ascending: 'bool | list[bool] | tuple[bool, ...]' = True, inplace: 'bool' = False, kind: 'str' = 'quicksort', na_position: 'str' = 'last', ignore_index: 'bool' = False, key: 'ValueKeyFunc' = None) -> 'DataFrame | None' method of pandas.core.frame.DataFrame instance\n",
      "    Sort by the values along either axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "            by : str or list of str\n",
      "                Name or list of names to sort by.\n",
      "    \n",
      "                - if `axis` is 0 or `'index'` then `by` may contain index\n",
      "                  levels and/or column labels.\n",
      "                - if `axis` is 1 or `'columns'` then `by` may contain column\n",
      "                  levels and/or index labels.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "         Axis to be sorted.\n",
      "    ascending : bool or list of bool, default True\n",
      "         Sort ascending vs. descending. Specify list for multiple sort\n",
      "         orders.  If this is a list of bools, must match the length of\n",
      "         the by.\n",
      "    inplace : bool, default False\n",
      "         If True, perform operation in-place.\n",
      "    kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\n",
      "         Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      "         information. `mergesort` and `stable` are the only stable algorithms. For\n",
      "         DataFrames, this option is only applied when sorting on a single\n",
      "         column or label.\n",
      "    na_position : {'first', 'last'}, default 'last'\n",
      "         Puts NaNs at the beginning if `first`; `last` puts NaNs at the\n",
      "         end.\n",
      "    ignore_index : bool, default False\n",
      "         If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      "    \n",
      "         .. versionadded:: 1.0.0\n",
      "    \n",
      "    key : callable, optional\n",
      "        Apply the key function to the values\n",
      "        before sorting. This is similar to the `key` argument in the\n",
      "        builtin :meth:`sorted` function, with the notable difference that\n",
      "        this `key` function should be *vectorized*. It should expect a\n",
      "        ``Series`` and return a Series with the same shape as the input.\n",
      "        It will be applied to each column in `by` independently.\n",
      "    \n",
      "        .. versionadded:: 1.1.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or None\n",
      "        DataFrame with sorted values or None if ``inplace=True``.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.sort_index : Sort a DataFrame by the index.\n",
      "    Series.sort_values : Similar method for a Series.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({\n",
      "    ...     'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
      "    ...     'col2': [2, 1, 9, 8, 7, 4],\n",
      "    ...     'col3': [0, 1, 9, 4, 2, 3],\n",
      "    ...     'col4': ['a', 'B', 'c', 'D', 'e', 'F']\n",
      "    ... })\n",
      "    >>> df\n",
      "      col1  col2  col3 col4\n",
      "    0    A     2     0    a\n",
      "    1    A     1     1    B\n",
      "    2    B     9     9    c\n",
      "    3  NaN     8     4    D\n",
      "    4    D     7     2    e\n",
      "    5    C     4     3    F\n",
      "    \n",
      "    Sort by col1\n",
      "    \n",
      "    >>> df.sort_values(by=['col1'])\n",
      "      col1  col2  col3 col4\n",
      "    0    A     2     0    a\n",
      "    1    A     1     1    B\n",
      "    2    B     9     9    c\n",
      "    5    C     4     3    F\n",
      "    4    D     7     2    e\n",
      "    3  NaN     8     4    D\n",
      "    \n",
      "    Sort by multiple columns\n",
      "    \n",
      "    >>> df.sort_values(by=['col1', 'col2'])\n",
      "      col1  col2  col3 col4\n",
      "    1    A     1     1    B\n",
      "    0    A     2     0    a\n",
      "    2    B     9     9    c\n",
      "    5    C     4     3    F\n",
      "    4    D     7     2    e\n",
      "    3  NaN     8     4    D\n",
      "    \n",
      "    Sort Descending\n",
      "    \n",
      "    >>> df.sort_values(by='col1', ascending=False)\n",
      "      col1  col2  col3 col4\n",
      "    4    D     7     2    e\n",
      "    5    C     4     3    F\n",
      "    2    B     9     9    c\n",
      "    0    A     2     0    a\n",
      "    1    A     1     1    B\n",
      "    3  NaN     8     4    D\n",
      "    \n",
      "    Putting NAs first\n",
      "    \n",
      "    >>> df.sort_values(by='col1', ascending=False, na_position='first')\n",
      "      col1  col2  col3 col4\n",
      "    3  NaN     8     4    D\n",
      "    4    D     7     2    e\n",
      "    5    C     4     3    F\n",
      "    2    B     9     9    c\n",
      "    0    A     2     0    a\n",
      "    1    A     1     1    B\n",
      "    \n",
      "    Sorting with a key function\n",
      "    \n",
      "    >>> df.sort_values(by='col4', key=lambda col: col.str.lower())\n",
      "       col1  col2  col3 col4\n",
      "    0    A     2     0    a\n",
      "    1    A     1     1    B\n",
      "    2    B     9     9    c\n",
      "    3  NaN     8     4    D\n",
      "    4    D     7     2    e\n",
      "    5    C     4     3    F\n",
      "    \n",
      "    Natural sort with the key argument,\n",
      "    using the `natsort <https://github.com/SethMMorton/natsort>` package.\n",
      "    \n",
      "    >>> df = pd.DataFrame({\n",
      "    ...    \"time\": ['0hr', '128hr', '72hr', '48hr', '96hr'],\n",
      "    ...    \"value\": [10, 20, 30, 40, 50]\n",
      "    ... })\n",
      "    >>> df\n",
      "        time  value\n",
      "    0    0hr     10\n",
      "    1  128hr     20\n",
      "    2   72hr     30\n",
      "    3   48hr     40\n",
      "    4   96hr     50\n",
      "    >>> from natsort import index_natsorted\n",
      "    >>> df.sort_values(\n",
      "    ...    by=\"time\",\n",
      "    ...    key=lambda x: np.argsort(index_natsorted(df[\"time\"]))\n",
      "    ... )\n",
      "        time  value\n",
      "    0    0hr     10\n",
      "    3   48hr     40\n",
      "    2   72hr     30\n",
      "    4   96hr     50\n",
      "    1  128hr     20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's look at sort_values, and see what options it gives\n",
    "help(df.sort_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ef17004d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10651</th>\n",
       "      <td>Austria</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>Grüner Veltliner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34927</th>\n",
       "      <td>France</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34942</th>\n",
       "      <td>France</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34939</th>\n",
       "      <td>France</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26296</th>\n",
       "      <td>France</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>Chardonnay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83536</th>\n",
       "      <td>France</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>Chardonnay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51886</th>\n",
       "      <td>France</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>Chardonnay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34922</th>\n",
       "      <td>France</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13318</th>\n",
       "      <td>US</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Chardonnay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34920</th>\n",
       "      <td>France</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country   price                   variety\n",
       "10651  Austria  1100.0          Grüner Veltliner\n",
       "34927   France  1100.0  Bordeaux-style Red Blend\n",
       "34942   France  1200.0  Bordeaux-style Red Blend\n",
       "34939   France  1300.0  Bordeaux-style Red Blend\n",
       "26296   France  1400.0                Chardonnay\n",
       "83536   France  1400.0                Chardonnay\n",
       "51886   France  1400.0                Chardonnay\n",
       "34922   France  1900.0  Bordeaux-style Red Blend\n",
       "13318       US  2013.0                Chardonnay\n",
       "34920   France  2300.0  Bordeaux-style Red Blend"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('price', na_position='first').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfad1174",
   "metadata": {},
   "source": [
    "# `inplace`\n",
    "\n",
    "Pandas methods almost always return a new data frame, rather than modifying the data frame itself. This might seem wasteful (in terms of memory and performance), but the the Pandas core developers assure us that this is not the case.\n",
    "\n",
    "You can, if you want, pass `inplace=True` to a very large number of Pandas methods. If you do that, then the method will return `None`, and you'll modify the data frame itself, in place.\n",
    "\n",
    "However, the Pandas core developers are planning to remove `inplace` from most (or all) methods, and basically beg us not to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bfa636da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>235.0</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spain</th>\n",
       "      <td>110.0</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>90.0</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>65.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence red blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>20.0</td>\n",
       "      <td>White Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Champagne Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>20.0</td>\n",
       "      <td>White Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>52.0</td>\n",
       "      <td>Champagne Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Pinot Grigio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150930 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         price             variety\n",
       "country                           \n",
       "US       235.0  Cabernet Sauvignon\n",
       "Spain    110.0       Tinta de Toro\n",
       "US        90.0     Sauvignon Blanc\n",
       "US        65.0          Pinot Noir\n",
       "France    66.0  Provence red blend\n",
       "...        ...                 ...\n",
       "Italy     20.0         White Blend\n",
       "France    27.0     Champagne Blend\n",
       "Italy     20.0         White Blend\n",
       "France    52.0     Champagne Blend\n",
       "Italy     15.0        Pinot Grigio\n",
       "\n",
       "[150930 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sometimes, I want to sort by the index, rather than by the column\n",
    "\n",
    "df = df.set_index('country')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "32890124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Viognier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>30.0</td>\n",
       "      <td>Tannat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>52.0</td>\n",
       "      <td>Red Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>17.0</td>\n",
       "      <td>Tannat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Tannat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>17.0</td>\n",
       "      <td>Assyrtiko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>30.0</td>\n",
       "      <td>Red Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150930 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         price     variety\n",
       "country                   \n",
       "Uruguay   15.0    Viognier\n",
       "Uruguay   30.0      Tannat\n",
       "Uruguay   52.0   Red Blend\n",
       "Uruguay   17.0      Tannat\n",
       "Uruguay   10.0      Tannat\n",
       "...        ...         ...\n",
       "NaN       17.0   Assyrtiko\n",
       "NaN       30.0   Red Blend\n",
       "NaN       15.0  Pinot Noir\n",
       "NaN       15.0  Pinot Noir\n",
       "NaN       15.0  Pinot Noir\n",
       "\n",
       "[150930 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how can I sort my data frame, such that the index is ordered alphabetically?\n",
    "# I can use df.sort_index()\n",
    "\n",
    "df.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3287b69b",
   "metadata": {},
   "source": [
    "# Exercise: High and low temps\n",
    "\n",
    "1. Create a data frame from the file `new+york,ny.csv`. This contains weather information over a 4-month period (Decembee 2018 - March 2019) in New York City.\n",
    "2. You only need to load a few columns: `date_time`, `new+york,ny_maxtempC`, `new+york,ny_mintempC`.\n",
    "3. Rename the columns to be `date_time`, `max_temp`, and `min_temp`.\n",
    "4. Set the `date_time` column to be the index.\n",
    "5. Find the 5 lowest temperatures recorded in New York during this period.\n",
    "6. Find the 5 highest temperatures recorded in New York during this period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "665d434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/reuven/Courses/Current/data/new+york,ny.csv'\n",
    "\n",
    "df = pd.read_csv(filename,\n",
    "            usecols=[0, 1, 2],   # use the numbers when you're going to change the names\n",
    "            names=['date_time', 'max_temp', 'min_temp'],\n",
    "            header=0,\n",
    "            index_col='date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "53fb5817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-11 00:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-11 03:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-11 06:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-11 09:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-11 12:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     max_temp  min_temp\n",
       "date_time                              \n",
       "2018-12-11 00:00:00         4        -1\n",
       "2018-12-11 03:00:00         4        -1\n",
       "2018-12-11 06:00:00         4        -1\n",
       "2018-12-11 09:00:00         4        -1\n",
       "2018-12-11 12:00:00         4        -1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c3de1f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-31 09:00:00</th>\n",
       "      <td>-8</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31 00:00:00</th>\n",
       "      <td>-8</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31 12:00:00</th>\n",
       "      <td>-8</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-21 21:00:00</th>\n",
       "      <td>-12</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31 06:00:00</th>\n",
       "      <td>-8</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     max_temp  min_temp\n",
       "date_time                              \n",
       "2019-01-31 09:00:00        -8       -14\n",
       "2019-01-31 00:00:00        -8       -14\n",
       "2019-01-31 12:00:00        -8       -14\n",
       "2019-01-21 21:00:00       -12       -14\n",
       "2019-01-31 06:00:00        -8       -14"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('min_temp').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6ce56a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-21 12:00:00</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-21 09:00:00</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-21 06:00:00</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-21 03:00:00</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-21 00:00:00</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     max_temp  min_temp\n",
       "date_time                              \n",
       "2018-12-21 12:00:00        15        12\n",
       "2018-12-21 09:00:00        15        12\n",
       "2018-12-21 06:00:00        15        12\n",
       "2018-12-21 03:00:00        15        12\n",
       "2018-12-21 00:00:00        15        12"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('max_temp').tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "268338c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-21 00:00:00</th>\n",
       "      <td>-12</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-21 03:00:00</th>\n",
       "      <td>-12</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-21 06:00:00</th>\n",
       "      <td>-12</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-21 09:00:00</th>\n",
       "      <td>-12</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-21 12:00:00</th>\n",
       "      <td>-12</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-21 15:00:00</th>\n",
       "      <td>-12</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-21 18:00:00</th>\n",
       "      <td>-12</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-21 21:00:00</th>\n",
       "      <td>-12</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31 00:00:00</th>\n",
       "      <td>-8</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31 03:00:00</th>\n",
       "      <td>-8</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31 06:00:00</th>\n",
       "      <td>-8</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31 09:00:00</th>\n",
       "      <td>-8</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31 12:00:00</th>\n",
       "      <td>-8</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31 15:00:00</th>\n",
       "      <td>-8</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31 18:00:00</th>\n",
       "      <td>-8</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31 21:00:00</th>\n",
       "      <td>-8</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-22 00:00:00</th>\n",
       "      <td>-3</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-22 03:00:00</th>\n",
       "      <td>-3</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-22 06:00:00</th>\n",
       "      <td>-3</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-22 09:00:00</th>\n",
       "      <td>-3</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-22 12:00:00</th>\n",
       "      <td>-3</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-22 15:00:00</th>\n",
       "      <td>-3</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-22 18:00:00</th>\n",
       "      <td>-3</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-22 21:00:00</th>\n",
       "      <td>-3</td>\n",
       "      <td>-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01 00:00:00</th>\n",
       "      <td>-5</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01 03:00:00</th>\n",
       "      <td>-5</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01 06:00:00</th>\n",
       "      <td>-5</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01 09:00:00</th>\n",
       "      <td>-5</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01 12:00:00</th>\n",
       "      <td>-5</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01 15:00:00</th>\n",
       "      <td>-5</td>\n",
       "      <td>-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     max_temp  min_temp\n",
       "date_time                              \n",
       "2019-01-21 00:00:00       -12       -14\n",
       "2019-01-21 03:00:00       -12       -14\n",
       "2019-01-21 06:00:00       -12       -14\n",
       "2019-01-21 09:00:00       -12       -14\n",
       "2019-01-21 12:00:00       -12       -14\n",
       "2019-01-21 15:00:00       -12       -14\n",
       "2019-01-21 18:00:00       -12       -14\n",
       "2019-01-21 21:00:00       -12       -14\n",
       "2019-01-31 00:00:00        -8       -14\n",
       "2019-01-31 03:00:00        -8       -14\n",
       "2019-01-31 06:00:00        -8       -14\n",
       "2019-01-31 09:00:00        -8       -14\n",
       "2019-01-31 12:00:00        -8       -14\n",
       "2019-01-31 15:00:00        -8       -14\n",
       "2019-01-31 18:00:00        -8       -14\n",
       "2019-01-31 21:00:00        -8       -14\n",
       "2019-01-22 00:00:00        -3       -13\n",
       "2019-01-22 03:00:00        -3       -13\n",
       "2019-01-22 06:00:00        -3       -13\n",
       "2019-01-22 09:00:00        -3       -13\n",
       "2019-01-22 12:00:00        -3       -13\n",
       "2019-01-22 15:00:00        -3       -13\n",
       "2019-01-22 18:00:00        -3       -13\n",
       "2019-01-22 21:00:00        -3       -13\n",
       "2019-02-01 00:00:00        -5       -12\n",
       "2019-02-01 03:00:00        -5       -12\n",
       "2019-02-01 06:00:00        -5       -12\n",
       "2019-02-01 09:00:00        -5       -12\n",
       "2019-02-01 12:00:00        -5       -12\n",
       "2019-02-01 15:00:00        -5       -12"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting by more than one column\n",
    "# sort by min_temp, and then (if there's a tie) by max_temp\n",
    "\n",
    "# just provide a list of column names, rather than a single column name\n",
    "\n",
    "df.sort_values(['min_temp', 'max_temp']).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970619dd",
   "metadata": {},
   "source": [
    "# Grouping\n",
    "\n",
    "If I read the wine data into Pandas, I can find out:\n",
    "\n",
    "- What's the average price of wines from France?\n",
    "- What's the average price of wines from the US?\n",
    "- What's the average price of wines from Chile?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bfe74f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  price\n",
       "0      US  235.0\n",
       "1   Spain  110.0\n",
       "2      US   90.0\n",
       "3      US   65.0\n",
       "4  France   66.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/reuven/Courses/Current/data/winemag-150k-reviews.csv'\n",
    "\n",
    "df = pd.read_csv(filename,\n",
    "                usecols=['country', 'price'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7aae0f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.61988501859993"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average price of wines in France\n",
    "df.loc[df['country'] == 'France',  # row selector\n",
    "      'price'].mean()              # column selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "64dd58a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.65380839730282"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['country'] == 'US',      # row selector\n",
    "      'price'].mean()              # column selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "288cfd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.344779743322928"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['country'] == 'Chile',      # row selector\n",
    "      'price'].mean()              # column selector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b117616f",
   "metadata": {},
   "source": [
    "At a certain point, this becomes tedious.\n",
    "\n",
    "I'd rather ask Pandas to take every unique value in df['country'], and calculate the mean price of all wines in that country:\n",
    "\n",
    "- Take each country mentioned in df['country']\n",
    "- Create a mask index, to find only wines from that country\n",
    "- Retrieve the value from the `price` column\n",
    "- Take the mean of those values\n",
    "\n",
    "That is grouping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "69fb21f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Albania                   20.000000\n",
       "Argentina                 20.794881\n",
       "Australia                 31.258480\n",
       "Austria                   31.192106\n",
       "Bosnia and Herzegovina    12.750000\n",
       "Brazil                    19.920000\n",
       "Bulgaria                  11.545455\n",
       "Canada                    34.628866\n",
       "Chile                     19.344780\n",
       "China                     20.333333\n",
       "Croatia                   23.108434\n",
       "Cyprus                    15.483871\n",
       "Czech Republic            18.000000\n",
       "Egypt                           NaN\n",
       "England                   47.500000\n",
       "France                    45.619885\n",
       "Georgia                   18.581395\n",
       "Germany                   39.011078\n",
       "Greece                    21.747706\n",
       "Hungary                   44.204348\n",
       "India                     13.875000\n",
       "Israel                    31.304918\n",
       "Italy                     37.547913\n",
       "Japan                     24.000000\n",
       "Lebanon                   25.432432\n",
       "Lithuania                 10.000000\n",
       "Luxembourg                40.666667\n",
       "Macedonia                 15.312500\n",
       "Mexico                    29.095238\n",
       "Moldova                   15.366197\n",
       "Montenegro                10.000000\n",
       "Morocco                   18.833333\n",
       "New Zealand               24.173290\n",
       "Portugal                  26.332615\n",
       "Romania                   16.395683\n",
       "Serbia                    24.285714\n",
       "Slovakia                  15.333333\n",
       "Slovenia                  28.061728\n",
       "South Africa              21.130532\n",
       "South Korea               13.500000\n",
       "Spain                     27.048529\n",
       "Switzerland               26.500000\n",
       "Tunisia                         NaN\n",
       "Turkey                    25.800000\n",
       "US                        33.653808\n",
       "US-France                 50.000000\n",
       "Ukraine                   13.000000\n",
       "Uruguay                   25.847059\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what unique values? (country)\n",
    "# on what column to calculate? (price)\n",
    "# what method do we want to run? (mean)\n",
    "\n",
    "# we get back a series in which the index contains the different values\n",
    "# for \"country\", the values in the series represent the mean prices for\n",
    "# each country.\n",
    "\n",
    "df.groupby('country')['price'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be03a34e",
   "metadata": {},
   "source": [
    "# Examples of grouping\n",
    "\n",
    "- Show total sales, grouped by region\n",
    "- Show mean infection rates, grouped by country\n",
    "- Show population, grouped by state\n",
    "- Show mean SAT score, grouped by university\n",
    "\n",
    "What methods can we use when grouping? Any aggregation method -- it takes many values, and returns a single value.\n",
    "\n",
    "- `mean`\n",
    "- `std`\n",
    "- `sum`\n",
    "- `count`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17a526",
   "metadata": {},
   "source": [
    "# Exercise: Grouping wines\n",
    "\n",
    "1. Read the wine data set into a data frame. Keep the country, price, province, and variety columns.\n",
    "2. What country has the most expensive wines, on average?\n",
    "3. What variety is most popular?\n",
    "4. What province produces the cheapest wines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8732caeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Provence red blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  price        province             variety\n",
       "0      US  235.0      California  Cabernet Sauvignon\n",
       "1   Spain  110.0  Northern Spain       Tinta de Toro\n",
       "2      US   90.0      California     Sauvignon Blanc\n",
       "3      US   65.0          Oregon          Pinot Noir\n",
       "4  France   66.0        Provence  Provence red blend"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/reuven/Courses/Current/data/winemag-150k-reviews.csv'\n",
    "\n",
    "df = pd.read_csv(filename,\n",
    "                usecols=['country', 'price', 'province', 'variety'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f1cf1505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Montenegro                10.000000\n",
       "Lithuania                 10.000000\n",
       "Bulgaria                  11.545455\n",
       "Bosnia and Herzegovina    12.750000\n",
       "Ukraine                   13.000000\n",
       "South Korea               13.500000\n",
       "India                     13.875000\n",
       "Macedonia                 15.312500\n",
       "Slovakia                  15.333333\n",
       "Moldova                   15.366197\n",
       "Cyprus                    15.483871\n",
       "Romania                   16.395683\n",
       "Czech Republic            18.000000\n",
       "Georgia                   18.581395\n",
       "Morocco                   18.833333\n",
       "Chile                     19.344780\n",
       "Brazil                    19.920000\n",
       "Albania                   20.000000\n",
       "China                     20.333333\n",
       "Argentina                 20.794881\n",
       "South Africa              21.130532\n",
       "Greece                    21.747706\n",
       "Croatia                   23.108434\n",
       "Japan                     24.000000\n",
       "New Zealand               24.173290\n",
       "Serbia                    24.285714\n",
       "Lebanon                   25.432432\n",
       "Turkey                    25.800000\n",
       "Uruguay                   25.847059\n",
       "Portugal                  26.332615\n",
       "Switzerland               26.500000\n",
       "Spain                     27.048529\n",
       "Slovenia                  28.061728\n",
       "Mexico                    29.095238\n",
       "Austria                   31.192106\n",
       "Australia                 31.258480\n",
       "Israel                    31.304918\n",
       "US                        33.653808\n",
       "Canada                    34.628866\n",
       "Italy                     37.547913\n",
       "Germany                   39.011078\n",
       "Luxembourg                40.666667\n",
       "Hungary                   44.204348\n",
       "France                    45.619885\n",
       "England                   47.500000\n",
       "US-France                 50.000000\n",
       "Egypt                           NaN\n",
       "Tunisia                         NaN\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what country has the most expensive wines, on average?\n",
    "\n",
    "# group on: country\n",
    "# calculate: mean\n",
    "# on the column: price\n",
    "\n",
    "df.groupby('country')['price'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3fe71afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variety\n",
       "Chardonnay                       13775\n",
       "Pinot Noir                       13628\n",
       "Cabernet Sauvignon               12671\n",
       "Red Blend                         9378\n",
       "Sauvignon Blanc                   6054\n",
       "Syrah                             5667\n",
       "Riesling                          5212\n",
       "Merlot                            4987\n",
       "Bordeaux-style Red Blend          4545\n",
       "Zinfandel                         3794\n",
       "Malbec                            3085\n",
       "Sangiovese                        2879\n",
       "White Blend                       2554\n",
       "Tempranillo                       2525\n",
       "Rosé                              2461\n",
       "Shiraz                            1945\n",
       "Sparkling Blend                   1820\n",
       "Portuguese Red                    1812\n",
       "Nebbiolo                          1529\n",
       "Rhône-style Red Blend             1455\n",
       "Cabernet Franc                    1310\n",
       "Corvina, Rondinella, Molinara     1292\n",
       "Pinot Gris                        1275\n",
       "Pinot Grigio                      1270\n",
       "Viognier                          1255\n",
       "Champagne Blend                   1003\n",
       "Barbera                            967\n",
       "Sangiovese Grosso                  938\n",
       "Petite Sirah                       897\n",
       "Gewürztraminer                     891\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What variety is most popular?\n",
    "\n",
    "# group on: variety\n",
    "# calculate: count()\n",
    "# on column: price (but we could use anything)\n",
    "\n",
    "df.groupby('variety')['price'].count().sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bfc1b505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "province\n",
       "Beni M'Tir            6.0\n",
       "Plaiurile Drancei     7.0\n",
       "Terras do Dão         7.0\n",
       "Felso-Magyarország    7.0\n",
       "Sliven                7.5\n",
       "Table wine            8.0\n",
       "Targovishte           8.0\n",
       "Rose Valley           8.0\n",
       "Retsina               8.0\n",
       "Viile Timis           8.0\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What province produces the cheapest wines?\n",
    "\n",
    "# group on: province\n",
    "# column: price\n",
    "# calculate: mean\n",
    "\n",
    "df.groupby('province')['price'].mean().sort_values().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001e10d0",
   "metadata": {},
   "source": [
    "# Next up\n",
    "\n",
    "1. Advanced grouping\n",
    "    - Multiple columns\n",
    "    - Multiple methods\n",
    "2. Pivot tables    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8ab9a5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                 province               \n",
       "Albania                 Mirditë                    20.000000\n",
       "Argentina               Mendoza Province           20.858266\n",
       "                        Other                      20.456300\n",
       "Australia               Australia Other            11.693285\n",
       "                        New South Wales            22.049180\n",
       "                        Queensland                 13.000000\n",
       "                        South Australia            35.489679\n",
       "                        Tasmania                   27.200000\n",
       "                        Victoria                   37.098522\n",
       "                        Western Australia          25.519507\n",
       "Austria                 Austria                    27.176471\n",
       "                        Burgenland                 31.202160\n",
       "                        Carnuntum                  26.872727\n",
       "                        Donauland                  26.000000\n",
       "                        Eisenberg                  24.666667\n",
       "                        Kamptal                    36.468504\n",
       "                        Kremstal                   26.777778\n",
       "                        Langenlois                 17.000000\n",
       "                        Leithaberg                 32.600000\n",
       "                        Mittelburgenland           30.650000\n",
       "                        Neusiedlersee              34.575758\n",
       "                        Neusiedlersee-Hügelland    30.000000\n",
       "                        Niederösterreich           21.942211\n",
       "                        South Styria               27.333333\n",
       "                        Steiermark                 20.000000\n",
       "                        Styria                     24.200000\n",
       "                        Südoststeiermark           27.309524\n",
       "                        Südsteiermark              32.787879\n",
       "                        Thermenregion              34.622449\n",
       "                        Traisental                 31.888889\n",
       "                        Vienna                     21.844444\n",
       "                        Wachau                     47.132308\n",
       "                        Wagram                     19.533333\n",
       "                        Wagram-Donauland           27.238095\n",
       "                        Weinland Österreich        13.285714\n",
       "                        Weinviertel                21.325581\n",
       "                        Wiener Gemischter Satz     26.500000\n",
       "                        Österreichischer Sekt      28.307692\n",
       "Bosnia and Herzegovina  Mostar                     12.750000\n",
       "Brazil                  Brazil                     20.833333\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we just saw that we can group by country *or* by province\n",
    "# but provinces are *in* countries\n",
    "# I'd like to group by country + province\n",
    "\n",
    "# we can give a list of categorical columns to group by, rather than just one\n",
    "df.groupby(['country', 'province'])['price'].mean().head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f5e1130f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Provence red blend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  points  price        province             variety\n",
       "0      US      96  235.0      California  Cabernet Sauvignon\n",
       "1   Spain      96  110.0  Northern Spain       Tinta de Toro\n",
       "2      US      96   90.0      California     Sauvignon Blanc\n",
       "3      US      96   65.0          Oregon          Pinot Noir\n",
       "4  France      95   66.0        Provence  Provence red blend"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what if I want to get results on more than one column?\n",
    "# for example: I want mean price *and* mean points for each country\n",
    "\n",
    "filename = '/Users/reuven/Courses/Current/data/winemag-150k-reviews.csv'\n",
    "\n",
    "df = pd.read_csv(filename,\n",
    "                usecols=['country', 'points','price', 'province', 'variety'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8a4dda86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>85.996093</td>\n",
       "      <td>20.794881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>87.892475</td>\n",
       "      <td>31.258480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria</th>\n",
       "      <td>89.276742</td>\n",
       "      <td>31.192106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosnia and Herzegovina</th>\n",
       "      <td>84.750000</td>\n",
       "      <td>12.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>83.240000</td>\n",
       "      <td>19.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bulgaria</th>\n",
       "      <td>85.467532</td>\n",
       "      <td>11.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <td>88.239796</td>\n",
       "      <td>34.628866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chile</th>\n",
       "      <td>86.296768</td>\n",
       "      <td>19.344780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>20.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Croatia</th>\n",
       "      <td>86.280899</td>\n",
       "      <td>23.108434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cyprus</th>\n",
       "      <td>85.870968</td>\n",
       "      <td>15.483871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Czech Republic</th>\n",
       "      <td>85.833333</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Egypt</th>\n",
       "      <td>83.666667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>England</th>\n",
       "      <td>92.888889</td>\n",
       "      <td>47.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>88.925870</td>\n",
       "      <td>45.619885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>85.511628</td>\n",
       "      <td>18.581395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>88.626427</td>\n",
       "      <td>39.011078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greece</th>\n",
       "      <td>86.117647</td>\n",
       "      <td>21.747706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hungary</th>\n",
       "      <td>87.329004</td>\n",
       "      <td>44.204348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>87.625000</td>\n",
       "      <td>13.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Israel</th>\n",
       "      <td>87.176190</td>\n",
       "      <td>31.304918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>88.413664</td>\n",
       "      <td>37.547913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lebanon</th>\n",
       "      <td>85.702703</td>\n",
       "      <td>25.432432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lithuania</th>\n",
       "      <td>84.250000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luxembourg</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>40.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macedonia</th>\n",
       "      <td>84.812500</td>\n",
       "      <td>15.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <td>84.761905</td>\n",
       "      <td>29.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moldova</th>\n",
       "      <td>84.718310</td>\n",
       "      <td>15.366197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montenegro</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morocco</th>\n",
       "      <td>88.166667</td>\n",
       "      <td>18.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Zealand</th>\n",
       "      <td>87.554217</td>\n",
       "      <td>24.173290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portugal</th>\n",
       "      <td>88.057685</td>\n",
       "      <td>26.332615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romania</th>\n",
       "      <td>84.920863</td>\n",
       "      <td>16.395683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serbia</th>\n",
       "      <td>87.714286</td>\n",
       "      <td>24.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slovakia</th>\n",
       "      <td>83.666667</td>\n",
       "      <td>15.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slovenia</th>\n",
       "      <td>88.234043</td>\n",
       "      <td>28.061728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Africa</th>\n",
       "      <td>87.225421</td>\n",
       "      <td>21.130532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Korea</th>\n",
       "      <td>81.500000</td>\n",
       "      <td>13.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spain</th>\n",
       "      <td>86.646589</td>\n",
       "      <td>27.048529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Switzerland</th>\n",
       "      <td>87.250000</td>\n",
       "      <td>26.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tunisia</th>\n",
       "      <td>86.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkey</th>\n",
       "      <td>88.096154</td>\n",
       "      <td>25.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>87.818789</td>\n",
       "      <td>33.653808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US-France</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ukraine</th>\n",
       "      <td>84.600000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>84.478261</td>\n",
       "      <td>25.847059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           points      price\n",
       "country                                     \n",
       "Albania                 88.000000  20.000000\n",
       "Argentina               85.996093  20.794881\n",
       "Australia               87.892475  31.258480\n",
       "Austria                 89.276742  31.192106\n",
       "Bosnia and Herzegovina  84.750000  12.750000\n",
       "Brazil                  83.240000  19.920000\n",
       "Bulgaria                85.467532  11.545455\n",
       "Canada                  88.239796  34.628866\n",
       "Chile                   86.296768  19.344780\n",
       "China                   82.000000  20.333333\n",
       "Croatia                 86.280899  23.108434\n",
       "Cyprus                  85.870968  15.483871\n",
       "Czech Republic          85.833333  18.000000\n",
       "Egypt                   83.666667        NaN\n",
       "England                 92.888889  47.500000\n",
       "France                  88.925870  45.619885\n",
       "Georgia                 85.511628  18.581395\n",
       "Germany                 88.626427  39.011078\n",
       "Greece                  86.117647  21.747706\n",
       "Hungary                 87.329004  44.204348\n",
       "India                   87.625000  13.875000\n",
       "Israel                  87.176190  31.304918\n",
       "Italy                   88.413664  37.547913\n",
       "Japan                   85.000000  24.000000\n",
       "Lebanon                 85.702703  25.432432\n",
       "Lithuania               84.250000  10.000000\n",
       "Luxembourg              87.000000  40.666667\n",
       "Macedonia               84.812500  15.312500\n",
       "Mexico                  84.761905  29.095238\n",
       "Moldova                 84.718310  15.366197\n",
       "Montenegro              82.000000  10.000000\n",
       "Morocco                 88.166667  18.833333\n",
       "New Zealand             87.554217  24.173290\n",
       "Portugal                88.057685  26.332615\n",
       "Romania                 84.920863  16.395683\n",
       "Serbia                  87.714286  24.285714\n",
       "Slovakia                83.666667  15.333333\n",
       "Slovenia                88.234043  28.061728\n",
       "South Africa            87.225421  21.130532\n",
       "South Korea             81.500000  13.500000\n",
       "Spain                   86.646589  27.048529\n",
       "Switzerland             87.250000  26.500000\n",
       "Tunisia                 86.000000        NaN\n",
       "Turkey                  88.096154  25.800000\n",
       "US                      87.818789  33.653808\n",
       "US-France               88.000000  50.000000\n",
       "Ukraine                 84.600000  13.000000\n",
       "Uruguay                 84.478261  25.847059"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each country\n",
    "# find the mean points + price\n",
    "\n",
    "df.groupby('country')[['points', 'price']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4321d5a9",
   "metadata": {},
   "source": [
    "We've now seen that we can, when grouping:\n",
    "\n",
    "- Group by 1 or more columns\n",
    "- Calculate our aggregation method on 1 or more columns\n",
    "\n",
    "Can we do both? YES!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7a9e1604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <th>Mirditë</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Argentina</th>\n",
       "      <th>Mendoza Province</th>\n",
       "      <td>86.108182</td>\n",
       "      <td>20.858266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>85.398200</td>\n",
       "      <td>20.456300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">Australia</th>\n",
       "      <th>Australia Other</th>\n",
       "      <td>84.813743</td>\n",
       "      <td>11.693285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New South Wales</th>\n",
       "      <td>87.048780</td>\n",
       "      <td>22.049180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Queensland</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Australia</th>\n",
       "      <td>88.544607</td>\n",
       "      <td>35.489679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tasmania</th>\n",
       "      <td>87.659574</td>\n",
       "      <td>27.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Victoria</th>\n",
       "      <td>88.045677</td>\n",
       "      <td>37.098522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western Australia</th>\n",
       "      <td>87.641548</td>\n",
       "      <td>25.519507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"28\" valign=\"top\">Austria</th>\n",
       "      <th>Austria</th>\n",
       "      <td>86.736842</td>\n",
       "      <td>27.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burgenland</th>\n",
       "      <td>88.985602</td>\n",
       "      <td>31.202160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carnuntum</th>\n",
       "      <td>89.342857</td>\n",
       "      <td>26.872727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donauland</th>\n",
       "      <td>88.409091</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eisenberg</th>\n",
       "      <td>91.333333</td>\n",
       "      <td>24.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamptal</th>\n",
       "      <td>90.406728</td>\n",
       "      <td>36.468504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kremstal</th>\n",
       "      <td>89.644654</td>\n",
       "      <td>26.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Langenlois</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leithaberg</th>\n",
       "      <td>90.833333</td>\n",
       "      <td>32.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mittelburgenland</th>\n",
       "      <td>89.375000</td>\n",
       "      <td>30.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neusiedlersee</th>\n",
       "      <td>88.111111</td>\n",
       "      <td>34.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neusiedlersee-Hügelland</th>\n",
       "      <td>88.511628</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Niederösterreich</th>\n",
       "      <td>88.301426</td>\n",
       "      <td>21.942211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Styria</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>27.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steiermark</th>\n",
       "      <td>88.571429</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Styria</th>\n",
       "      <td>86.533333</td>\n",
       "      <td>24.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Südoststeiermark</th>\n",
       "      <td>89.298246</td>\n",
       "      <td>27.309524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Südsteiermark</th>\n",
       "      <td>88.781250</td>\n",
       "      <td>32.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thermenregion</th>\n",
       "      <td>88.950820</td>\n",
       "      <td>34.622449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traisental</th>\n",
       "      <td>90.791667</td>\n",
       "      <td>31.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vienna</th>\n",
       "      <td>89.074074</td>\n",
       "      <td>21.844444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wachau</th>\n",
       "      <td>90.765013</td>\n",
       "      <td>47.132308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wagram</th>\n",
       "      <td>89.500000</td>\n",
       "      <td>19.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wagram-Donauland</th>\n",
       "      <td>88.973333</td>\n",
       "      <td>27.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weinland Österreich</th>\n",
       "      <td>87.900000</td>\n",
       "      <td>13.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weinviertel</th>\n",
       "      <td>88.351852</td>\n",
       "      <td>21.325581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wiener Gemischter Satz</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>26.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Österreichischer Sekt</th>\n",
       "      <td>86.450000</td>\n",
       "      <td>28.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosnia and Herzegovina</th>\n",
       "      <th>Mostar</th>\n",
       "      <td>84.750000</td>\n",
       "      <td>12.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <th>Brazil</th>\n",
       "      <td>83.333333</td>\n",
       "      <td>20.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   points      price\n",
       "country                province                                     \n",
       "Albania                Mirditë                  88.000000  20.000000\n",
       "Argentina              Mendoza Province         86.108182  20.858266\n",
       "                       Other                    85.398200  20.456300\n",
       "Australia              Australia Other          84.813743  11.693285\n",
       "                       New South Wales          87.048780  22.049180\n",
       "                       Queensland               85.000000  13.000000\n",
       "                       South Australia          88.544607  35.489679\n",
       "                       Tasmania                 87.659574  27.200000\n",
       "                       Victoria                 88.045677  37.098522\n",
       "                       Western Australia        87.641548  25.519507\n",
       "Austria                Austria                  86.736842  27.176471\n",
       "                       Burgenland               88.985602  31.202160\n",
       "                       Carnuntum                89.342857  26.872727\n",
       "                       Donauland                88.409091  26.000000\n",
       "                       Eisenberg                91.333333  24.666667\n",
       "                       Kamptal                  90.406728  36.468504\n",
       "                       Kremstal                 89.644654  26.777778\n",
       "                       Langenlois               84.000000  17.000000\n",
       "                       Leithaberg               90.833333  32.600000\n",
       "                       Mittelburgenland         89.375000  30.650000\n",
       "                       Neusiedlersee            88.111111  34.575758\n",
       "                       Neusiedlersee-Hügelland  88.511628  30.000000\n",
       "                       Niederösterreich         88.301426  21.942211\n",
       "                       South Styria             87.000000  27.333333\n",
       "                       Steiermark               88.571429  20.000000\n",
       "                       Styria                   86.533333  24.200000\n",
       "                       Südoststeiermark         89.298246  27.309524\n",
       "                       Südsteiermark            88.781250  32.787879\n",
       "                       Thermenregion            88.950820  34.622449\n",
       "                       Traisental               90.791667  31.888889\n",
       "                       Vienna                   89.074074  21.844444\n",
       "                       Wachau                   90.765013  47.132308\n",
       "                       Wagram                   89.500000  19.533333\n",
       "                       Wagram-Donauland         88.973333  27.238095\n",
       "                       Weinland Österreich      87.900000  13.285714\n",
       "                       Weinviertel              88.351852  21.325581\n",
       "                       Wiener Gemischter Satz   90.200000  26.500000\n",
       "                       Österreichischer Sekt    86.450000  28.307692\n",
       "Bosnia and Herzegovina Mostar                   84.750000  12.750000\n",
       "Brazil                 Brazil                   83.333333  20.833333"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by both country + province\n",
    "# calculate the mean\n",
    "# calculate on both points and price\n",
    "\n",
    "df.groupby(['country', 'province'])[['points', 'price']].mean().head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "eafcb0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>20.794881</td>\n",
       "      <td>20.186540</td>\n",
       "      <td>5587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>31.258480</td>\n",
       "      <td>39.008512</td>\n",
       "      <td>4894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria</th>\n",
       "      <td>31.192106</td>\n",
       "      <td>28.540861</td>\n",
       "      <td>2483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosnia and Herzegovina</th>\n",
       "      <td>12.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>19.920000</td>\n",
       "      <td>8.840814</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bulgaria</th>\n",
       "      <td>11.545455</td>\n",
       "      <td>4.959163</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <td>34.628866</td>\n",
       "      <td>24.267644</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chile</th>\n",
       "      <td>19.344780</td>\n",
       "      <td>19.618082</td>\n",
       "      <td>5766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>20.333333</td>\n",
       "      <td>11.547005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Croatia</th>\n",
       "      <td>23.108434</td>\n",
       "      <td>12.375243</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cyprus</th>\n",
       "      <td>15.483871</td>\n",
       "      <td>3.731586</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Czech Republic</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Egypt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>England</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>11.964232</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>45.619885</td>\n",
       "      <td>69.697060</td>\n",
       "      <td>14785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>18.581395</td>\n",
       "      <td>8.990028</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>39.011078</td>\n",
       "      <td>56.857128</td>\n",
       "      <td>2347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greece</th>\n",
       "      <td>21.747706</td>\n",
       "      <td>12.273692</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hungary</th>\n",
       "      <td>44.204348</td>\n",
       "      <td>66.264502</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>13.875000</td>\n",
       "      <td>3.870677</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Israel</th>\n",
       "      <td>31.304918</td>\n",
       "      <td>19.650363</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>37.547913</td>\n",
       "      <td>37.067869</td>\n",
       "      <td>18784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lebanon</th>\n",
       "      <td>25.432432</td>\n",
       "      <td>12.835585</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lithuania</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luxembourg</th>\n",
       "      <td>40.666667</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macedonia</th>\n",
       "      <td>15.312500</td>\n",
       "      <td>4.377499</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <td>29.095238</td>\n",
       "      <td>16.938898</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moldova</th>\n",
       "      <td>15.366197</td>\n",
       "      <td>7.679731</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montenegro</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morocco</th>\n",
       "      <td>18.833333</td>\n",
       "      <td>7.755741</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Zealand</th>\n",
       "      <td>24.173290</td>\n",
       "      <td>13.569317</td>\n",
       "      <td>3070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portugal</th>\n",
       "      <td>26.332615</td>\n",
       "      <td>35.242873</td>\n",
       "      <td>4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romania</th>\n",
       "      <td>16.395683</td>\n",
       "      <td>28.845571</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serbia</th>\n",
       "      <td>24.285714</td>\n",
       "      <td>9.335034</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slovakia</th>\n",
       "      <td>15.333333</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slovenia</th>\n",
       "      <td>28.061728</td>\n",
       "      <td>14.263017</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Africa</th>\n",
       "      <td>21.130532</td>\n",
       "      <td>14.248025</td>\n",
       "      <td>2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Korea</th>\n",
       "      <td>13.500000</td>\n",
       "      <td>2.886751</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spain</th>\n",
       "      <td>27.048529</td>\n",
       "      <td>33.861666</td>\n",
       "      <td>8160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Switzerland</th>\n",
       "      <td>26.500000</td>\n",
       "      <td>8.582929</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tunisia</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkey</th>\n",
       "      <td>25.800000</td>\n",
       "      <td>19.120456</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>33.653808</td>\n",
       "      <td>24.891343</td>\n",
       "      <td>62139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US-France</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ukraine</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>25.847059</td>\n",
       "      <td>15.066129</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             mean        std  count\n",
       "country                                            \n",
       "Albania                 20.000000   0.000000      2\n",
       "Argentina               20.794881  20.186540   5587\n",
       "Australia               31.258480  39.008512   4894\n",
       "Austria                 31.192106  28.540861   2483\n",
       "Bosnia and Herzegovina  12.750000   0.500000      4\n",
       "Brazil                  19.920000   8.840814     25\n",
       "Bulgaria                11.545455   4.959163     77\n",
       "Canada                  34.628866  24.267644    194\n",
       "Chile                   19.344780  19.618082   5766\n",
       "China                   20.333333  11.547005      3\n",
       "Croatia                 23.108434  12.375243     83\n",
       "Cyprus                  15.483871   3.731586     31\n",
       "Czech Republic          18.000000   4.000000      6\n",
       "Egypt                         NaN        NaN      0\n",
       "England                 47.500000  11.964232      8\n",
       "France                  45.619885  69.697060  14785\n",
       "Georgia                 18.581395   8.990028     43\n",
       "Germany                 39.011078  56.857128   2347\n",
       "Greece                  21.747706  12.273692    872\n",
       "Hungary                 44.204348  66.264502    230\n",
       "India                   13.875000   3.870677      8\n",
       "Israel                  31.304918  19.650363    610\n",
       "Italy                   37.547913  37.067869  18784\n",
       "Japan                   24.000000   0.000000      2\n",
       "Lebanon                 25.432432  12.835585     37\n",
       "Lithuania               10.000000   0.000000      8\n",
       "Luxembourg              40.666667   7.000000      9\n",
       "Macedonia               15.312500   4.377499     16\n",
       "Mexico                  29.095238  16.938898     63\n",
       "Moldova                 15.366197   7.679731     71\n",
       "Montenegro              10.000000   0.000000      2\n",
       "Morocco                 18.833333   7.755741     12\n",
       "New Zealand             24.173290  13.569317   3070\n",
       "Portugal                26.332615  35.242873   4176\n",
       "Romania                 16.395683  28.845571    139\n",
       "Serbia                  24.285714   9.335034     14\n",
       "Slovakia                15.333333   0.577350      3\n",
       "Slovenia                28.061728  14.263017     81\n",
       "South Africa            21.130532  14.248025   2237\n",
       "South Korea             13.500000   2.886751      4\n",
       "Spain                   27.048529  33.861666   8160\n",
       "Switzerland             26.500000   8.582929      4\n",
       "Tunisia                       NaN        NaN      0\n",
       "Turkey                  25.800000  19.120456     50\n",
       "US                      33.653808  24.891343  62139\n",
       "US-France               50.000000        NaN      1\n",
       "Ukraine                 13.000000   0.000000      5\n",
       "Uruguay                 25.847059  15.066129     85"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also calculate more than one aggregation method on our grouping\n",
    "\n",
    "# for each country\n",
    "# we'll find the mean, std, and count of price\n",
    "\n",
    "df.groupby('country')['price'].agg(['mean', 'std', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f625a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "583810b2",
   "metadata": {},
   "source": [
    "We've now seen that we can, when grouping:\n",
    "\n",
    "- Group by 1 or more columns\n",
    "- Calculate our aggregation method on 1 or more columns\n",
    "- Use 1 or more aggregation methods\n",
    "\n",
    "Can we do all three? YES! (But it's going to be big and a little ugly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8519f599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">points</th>\n",
       "      <th colspan=\"2\" halign=\"left\">price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <th>Mirditë</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Argentina</th>\n",
       "      <th>Mendoza Province</th>\n",
       "      <td>86.108182</td>\n",
       "      <td>3.128598</td>\n",
       "      <td>20.858266</td>\n",
       "      <td>19.819035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>85.398200</td>\n",
       "      <td>2.838966</td>\n",
       "      <td>20.456300</td>\n",
       "      <td>22.055162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">Australia</th>\n",
       "      <th>Australia Other</th>\n",
       "      <td>84.813743</td>\n",
       "      <td>2.132315</td>\n",
       "      <td>11.693285</td>\n",
       "      <td>6.056877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New South Wales</th>\n",
       "      <td>87.048780</td>\n",
       "      <td>2.433956</td>\n",
       "      <td>22.049180</td>\n",
       "      <td>16.192186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Queensland</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Australia</th>\n",
       "      <td>88.544607</td>\n",
       "      <td>2.815980</td>\n",
       "      <td>35.489679</td>\n",
       "      <td>44.617021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tasmania</th>\n",
       "      <td>87.659574</td>\n",
       "      <td>1.936790</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>13.508583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Victoria</th>\n",
       "      <td>88.045677</td>\n",
       "      <td>3.136002</td>\n",
       "      <td>37.098522</td>\n",
       "      <td>40.595528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western Australia</th>\n",
       "      <td>87.641548</td>\n",
       "      <td>2.560657</td>\n",
       "      <td>25.519507</td>\n",
       "      <td>17.454678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"28\" valign=\"top\">Austria</th>\n",
       "      <th>Austria</th>\n",
       "      <td>86.736842</td>\n",
       "      <td>2.353298</td>\n",
       "      <td>27.176471</td>\n",
       "      <td>15.561311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burgenland</th>\n",
       "      <td>88.985602</td>\n",
       "      <td>2.648188</td>\n",
       "      <td>31.202160</td>\n",
       "      <td>20.814947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carnuntum</th>\n",
       "      <td>89.342857</td>\n",
       "      <td>2.139252</td>\n",
       "      <td>26.872727</td>\n",
       "      <td>14.193184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donauland</th>\n",
       "      <td>88.409091</td>\n",
       "      <td>1.918806</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>10.627906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eisenberg</th>\n",
       "      <td>91.333333</td>\n",
       "      <td>1.154701</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>5.033223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kamptal</th>\n",
       "      <td>90.406728</td>\n",
       "      <td>2.427416</td>\n",
       "      <td>36.468504</td>\n",
       "      <td>18.531167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kremstal</th>\n",
       "      <td>89.644654</td>\n",
       "      <td>2.038158</td>\n",
       "      <td>26.777778</td>\n",
       "      <td>12.180801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Langenlois</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leithaberg</th>\n",
       "      <td>90.833333</td>\n",
       "      <td>1.471960</td>\n",
       "      <td>32.600000</td>\n",
       "      <td>10.549882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mittelburgenland</th>\n",
       "      <td>89.375000</td>\n",
       "      <td>2.514850</td>\n",
       "      <td>30.650000</td>\n",
       "      <td>12.069351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neusiedlersee</th>\n",
       "      <td>88.111111</td>\n",
       "      <td>3.068529</td>\n",
       "      <td>34.575758</td>\n",
       "      <td>22.231777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neusiedlersee-Hügelland</th>\n",
       "      <td>88.511628</td>\n",
       "      <td>3.224697</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>19.138592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Niederösterreich</th>\n",
       "      <td>88.301426</td>\n",
       "      <td>2.352328</td>\n",
       "      <td>21.942211</td>\n",
       "      <td>9.722040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Styria</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.333333</td>\n",
       "      <td>7.505553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steiermark</th>\n",
       "      <td>88.571429</td>\n",
       "      <td>1.272418</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.915780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Styria</th>\n",
       "      <td>86.533333</td>\n",
       "      <td>1.187234</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>8.937881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Südoststeiermark</th>\n",
       "      <td>89.298246</td>\n",
       "      <td>2.104119</td>\n",
       "      <td>27.309524</td>\n",
       "      <td>9.369093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Südsteiermark</th>\n",
       "      <td>88.781250</td>\n",
       "      <td>2.578721</td>\n",
       "      <td>32.787879</td>\n",
       "      <td>13.147618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thermenregion</th>\n",
       "      <td>88.950820</td>\n",
       "      <td>2.060460</td>\n",
       "      <td>34.622449</td>\n",
       "      <td>20.474029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traisental</th>\n",
       "      <td>90.791667</td>\n",
       "      <td>1.641292</td>\n",
       "      <td>31.888889</td>\n",
       "      <td>13.037904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vienna</th>\n",
       "      <td>89.074074</td>\n",
       "      <td>1.871856</td>\n",
       "      <td>21.844444</td>\n",
       "      <td>5.923588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wachau</th>\n",
       "      <td>90.765013</td>\n",
       "      <td>2.562747</td>\n",
       "      <td>47.132308</td>\n",
       "      <td>63.547914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wagram</th>\n",
       "      <td>89.500000</td>\n",
       "      <td>2.607681</td>\n",
       "      <td>19.533333</td>\n",
       "      <td>9.171903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wagram-Donauland</th>\n",
       "      <td>88.973333</td>\n",
       "      <td>1.724022</td>\n",
       "      <td>27.238095</td>\n",
       "      <td>11.290467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weinland Österreich</th>\n",
       "      <td>87.900000</td>\n",
       "      <td>2.078995</td>\n",
       "      <td>13.285714</td>\n",
       "      <td>3.450328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weinviertel</th>\n",
       "      <td>88.351852</td>\n",
       "      <td>1.650128</td>\n",
       "      <td>21.325581</td>\n",
       "      <td>12.443627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wiener Gemischter Satz</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>0.836660</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>9.814955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Österreichischer Sekt</th>\n",
       "      <td>86.450000</td>\n",
       "      <td>1.932411</td>\n",
       "      <td>28.307692</td>\n",
       "      <td>11.175752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosnia and Herzegovina</th>\n",
       "      <th>Mostar</th>\n",
       "      <td>84.750000</td>\n",
       "      <td>2.362908</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <th>Brazil</th>\n",
       "      <td>83.333333</td>\n",
       "      <td>1.032796</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>7.960318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   points            \\\n",
       "                                                     mean       std   \n",
       "country                province                                       \n",
       "Albania                Mirditë                  88.000000  0.000000   \n",
       "Argentina              Mendoza Province         86.108182  3.128598   \n",
       "                       Other                    85.398200  2.838966   \n",
       "Australia              Australia Other          84.813743  2.132315   \n",
       "                       New South Wales          87.048780  2.433956   \n",
       "                       Queensland               85.000000  0.000000   \n",
       "                       South Australia          88.544607  2.815980   \n",
       "                       Tasmania                 87.659574  1.936790   \n",
       "                       Victoria                 88.045677  3.136002   \n",
       "                       Western Australia        87.641548  2.560657   \n",
       "Austria                Austria                  86.736842  2.353298   \n",
       "                       Burgenland               88.985602  2.648188   \n",
       "                       Carnuntum                89.342857  2.139252   \n",
       "                       Donauland                88.409091  1.918806   \n",
       "                       Eisenberg                91.333333  1.154701   \n",
       "                       Kamptal                  90.406728  2.427416   \n",
       "                       Kremstal                 89.644654  2.038158   \n",
       "                       Langenlois               84.000000       NaN   \n",
       "                       Leithaberg               90.833333  1.471960   \n",
       "                       Mittelburgenland         89.375000  2.514850   \n",
       "                       Neusiedlersee            88.111111  3.068529   \n",
       "                       Neusiedlersee-Hügelland  88.511628  3.224697   \n",
       "                       Niederösterreich         88.301426  2.352328   \n",
       "                       South Styria             87.000000  1.000000   \n",
       "                       Steiermark               88.571429  1.272418   \n",
       "                       Styria                   86.533333  1.187234   \n",
       "                       Südoststeiermark         89.298246  2.104119   \n",
       "                       Südsteiermark            88.781250  2.578721   \n",
       "                       Thermenregion            88.950820  2.060460   \n",
       "                       Traisental               90.791667  1.641292   \n",
       "                       Vienna                   89.074074  1.871856   \n",
       "                       Wachau                   90.765013  2.562747   \n",
       "                       Wagram                   89.500000  2.607681   \n",
       "                       Wagram-Donauland         88.973333  1.724022   \n",
       "                       Weinland Österreich      87.900000  2.078995   \n",
       "                       Weinviertel              88.351852  1.650128   \n",
       "                       Wiener Gemischter Satz   90.200000  0.836660   \n",
       "                       Österreichischer Sekt    86.450000  1.932411   \n",
       "Bosnia and Herzegovina Mostar                   84.750000  2.362908   \n",
       "Brazil                 Brazil                   83.333333  1.032796   \n",
       "\n",
       "                                                    price             \n",
       "                                                     mean        std  \n",
       "country                province                                       \n",
       "Albania                Mirditë                  20.000000   0.000000  \n",
       "Argentina              Mendoza Province         20.858266  19.819035  \n",
       "                       Other                    20.456300  22.055162  \n",
       "Australia              Australia Other          11.693285   6.056877  \n",
       "                       New South Wales          22.049180  16.192186  \n",
       "                       Queensland               13.000000   0.000000  \n",
       "                       South Australia          35.489679  44.617021  \n",
       "                       Tasmania                 27.200000  13.508583  \n",
       "                       Victoria                 37.098522  40.595528  \n",
       "                       Western Australia        25.519507  17.454678  \n",
       "Austria                Austria                  27.176471  15.561311  \n",
       "                       Burgenland               31.202160  20.814947  \n",
       "                       Carnuntum                26.872727  14.193184  \n",
       "                       Donauland                26.000000  10.627906  \n",
       "                       Eisenberg                24.666667   5.033223  \n",
       "                       Kamptal                  36.468504  18.531167  \n",
       "                       Kremstal                 26.777778  12.180801  \n",
       "                       Langenlois               17.000000        NaN  \n",
       "                       Leithaberg               32.600000  10.549882  \n",
       "                       Mittelburgenland         30.650000  12.069351  \n",
       "                       Neusiedlersee            34.575758  22.231777  \n",
       "                       Neusiedlersee-Hügelland  30.000000  19.138592  \n",
       "                       Niederösterreich         21.942211   9.722040  \n",
       "                       South Styria             27.333333   7.505553  \n",
       "                       Steiermark               20.000000   3.915780  \n",
       "                       Styria                   24.200000   8.937881  \n",
       "                       Südoststeiermark         27.309524   9.369093  \n",
       "                       Südsteiermark            32.787879  13.147618  \n",
       "                       Thermenregion            34.622449  20.474029  \n",
       "                       Traisental               31.888889  13.037904  \n",
       "                       Vienna                   21.844444   5.923588  \n",
       "                       Wachau                   47.132308  63.547914  \n",
       "                       Wagram                   19.533333   9.171903  \n",
       "                       Wagram-Donauland         27.238095  11.290467  \n",
       "                       Weinland Österreich      13.285714   3.450328  \n",
       "                       Weinviertel              21.325581  12.443627  \n",
       "                       Wiener Gemischter Satz   26.500000   9.814955  \n",
       "                       Österreichischer Sekt    28.307692  11.175752  \n",
       "Bosnia and Herzegovina Mostar                   12.750000   0.500000  \n",
       "Brazil                 Brazil                   20.833333   7.960318  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['country', 'province'])[['points', 'price']].agg(['mean', 'std']).head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a239b30",
   "metadata": {},
   "source": [
    "# Exercise: Olympic data\n",
    "\n",
    "1. Create a data frame from `olympic_athlete_events.csv`, in the zipfile.  We only care about Sex, Age, Height, Weight, Team, Year.\n",
    "2. In which year were the athletes, on average, the tallest?\n",
    "3. Which country has the oldest athletes? The youngest?\n",
    "4. Find the average height and weight for each team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9e2f8c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Team</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>China</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denmark/Sweden</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex   Age  Height  Weight            Team  Year\n",
       "0   M  24.0   180.0    80.0           China  1992\n",
       "1   M  23.0   170.0    60.0           China  2012\n",
       "2   M  24.0     NaN     NaN         Denmark  1920\n",
       "3   M  34.0     NaN     NaN  Denmark/Sweden  1900\n",
       "4   F  21.0   185.0    82.0     Netherlands  1988"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/reuven/Courses/Current/data/olympic_athlete_events.csv'\n",
    "\n",
    "df = pd.read_csv(filename,\n",
    "                usecols=['Sex', 'Age', 'Height', 'Weight', 'Team', 'Year'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "59dd7065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year\n",
       "1896    172.739130\n",
       "1960    173.141286\n",
       "1964    173.448574\n",
       "1956    173.900968\n",
       "1968    173.945865\n",
       "1952    174.138940\n",
       "1932    174.220115\n",
       "1972    174.565363\n",
       "1998    174.581369\n",
       "2006    174.623172\n",
       "2002    174.702451\n",
       "2014    174.816670\n",
       "2010    174.918182\n",
       "1976    174.920528\n",
       "1924    174.963039\n",
       "1928    175.162051\n",
       "1994    175.169862\n",
       "1980    175.527488\n",
       "1984    175.540855\n",
       "1936    175.723993\n",
       "1988    175.745252\n",
       "1920    175.752282\n",
       "1904    175.788732\n",
       "1996    175.895121\n",
       "2004    175.972850\n",
       "2016    176.034266\n",
       "2000    176.089721\n",
       "1948    176.172797\n",
       "1992    176.174649\n",
       "2008    176.211062\n",
       "2012    176.262469\n",
       "1900    176.637931\n",
       "1912    177.447989\n",
       "1908    177.543158\n",
       "1906    178.206226\n",
       "Name: Height, dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in which year were the athletes, on average, tallest?\n",
    "\n",
    "df.groupby('Year')['Height'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "295de9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Team\n",
       "Ethnikos Gymnastikos Syllogos        10.000000\n",
       "Olympion                             17.500000\n",
       "Pupilles de Neptune de Lille #2-1    18.000000\n",
       "Italy-3                              18.000000\n",
       "Christian Brothers' College-1        18.181818\n",
       "Pupilles de Neptune de Lille-1       18.333333\n",
       "Ubu                                  18.500000\n",
       "East Germany-3                       18.666667\n",
       "North Korea-2                        18.833333\n",
       "Pistoja/Firenze                      19.000000\n",
       "Scaup                                19.000000\n",
       "Berliner Ruderclub                   19.000000\n",
       "Tritons Lillois-2                    19.000000\n",
       "Bremen                               19.000000\n",
       "Univ. of Brussels                    19.000000\n",
       "Angerburg                            19.000000\n",
       "Western Golf Association-1           19.100000\n",
       "USFSA                                19.142857\n",
       "Deutscher Schwimm Verband Berlin     19.500000\n",
       "Sirene                               19.500000\n",
       "Greece-4                             20.000000\n",
       "West Germany-3                       20.000000\n",
       "Boreas-2                             20.000000\n",
       "Pupilles de Neptune de Lille #1-3    20.000000\n",
       "Club Nautique de Dieppe-5            20.000000\n",
       "Tuvalu                               20.142857\n",
       "Marshall Islands                     20.285714\n",
       "Germania Ruder Club, Hamburg-2       20.400000\n",
       "New York Athletic Club               20.400000\n",
       "Lucky                                20.500000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which country has the oldest athletes? The youngest?\n",
    "\n",
    "df.groupby('Team')['Age'].mean().sort_values().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3f7e6831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Team\n",
       "Pirouette-31    71.0\n",
       "Pirouette-5     71.0\n",
       "Whisper         67.0\n",
       "Ariette-8       62.0\n",
       "Ariette-10      62.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Team')['Age'].mean().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b44c8950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Team</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30. Februar</th>\n",
       "      <td>171.500000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A North American Team</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acipactli</th>\n",
       "      <td>174.666667</td>\n",
       "      <td>75.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acturus</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>170.592593</td>\n",
       "      <td>65.901639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Akatonbo</th>\n",
       "      <td>182.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alain IV</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>89.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>173.000000</td>\n",
       "      <td>71.491803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcaid</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcyon-6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcyon-7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aldebaran</th>\n",
       "      <td>174.500000</td>\n",
       "      <td>78.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aldebaran II</th>\n",
       "      <td>177.500000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aletta</th>\n",
       "      <td>176.333333</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>174.702869</td>\n",
       "      <td>68.693252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ali-Baba II</th>\n",
       "      <td>162.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ali-Baba IV</th>\n",
       "      <td>162.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ali-Baba IX</th>\n",
       "      <td>175.000000</td>\n",
       "      <td>82.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ali-Baba VI</th>\n",
       "      <td>175.000000</td>\n",
       "      <td>82.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allegro</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Almaz</th>\n",
       "      <td>175.500000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aloha II</th>\n",
       "      <td>156.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amateur Athletic Association</th>\n",
       "      <td>176.500000</td>\n",
       "      <td>70.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Samoa</th>\n",
       "      <td>175.666667</td>\n",
       "      <td>87.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amolgavar</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amstel Amsterdam</th>\n",
       "      <td>NaN</td>\n",
       "      <td>82.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amulet-3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amulet-7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ancora</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andorinha</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Height     Weight\n",
       "Team                                               \n",
       "30. Februar                   171.500000  70.000000\n",
       "A North American Team                NaN        NaN\n",
       "Acipactli                     174.666667  75.333333\n",
       "Acturus                              NaN        NaN\n",
       "Afghanistan                   170.592593  65.901639\n",
       "Akatonbo                      182.000000  80.000000\n",
       "Alain IV                      176.000000  89.333333\n",
       "Albania                       173.000000  71.491803\n",
       "Alcaid                               NaN        NaN\n",
       "Alcyon-6                             NaN        NaN\n",
       "Alcyon-7                             NaN        NaN\n",
       "Aldebaran                     174.500000  78.500000\n",
       "Aldebaran II                  177.500000  80.000000\n",
       "Aletta                        176.333333  71.000000\n",
       "Algeria                       174.702869  68.693252\n",
       "Ali-Baba II                   162.000000  67.000000\n",
       "Ali-Baba IV                   162.000000  67.000000\n",
       "Ali-Baba IX                   175.000000  82.500000\n",
       "Ali-Baba VI                   175.000000  82.500000\n",
       "Allegro                              NaN        NaN\n",
       "Almaz                         175.500000  73.000000\n",
       "Aloha II                      156.000000  56.000000\n",
       "Amateur Athletic Association  176.500000  70.500000\n",
       "American Samoa                175.666667  87.958333\n",
       "Amolgavar                            NaN        NaN\n",
       "Amstel Amsterdam                     NaN  82.500000\n",
       "Amulet-3                             NaN        NaN\n",
       "Amulet-7                             NaN        NaN\n",
       "Ancora                               NaN        NaN\n",
       "Andorinha                            NaN        NaN"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the average height and weight for each team.\n",
    "\n",
    "df.groupby('Team')[['Height', 'Weight']].mean().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656831cf",
   "metadata": {},
   "source": [
    "# Pivot tables\n",
    "\n",
    "We've now seen that we can group by one column, or by many columns.  When we do that, we're running an aggregation method on the data that fits that column (or columns).\n",
    "\n",
    "What if I have two categorical columns that aren't hierarchical (like with countries + provinces)? What if I want to group by two different axes, and see the intersections of those categories?\n",
    "\n",
    "That's a pivot table:\n",
    "\n",
    "- We run a groupby on one category, and put the unique values of that category in the rows index.\n",
    "- We run a groupby on a separate category, and put the unique values of that category in the column names.\n",
    "- At the intersection of each of the rows + columns, we run an aggregation method.\n",
    "\n",
    "This allows us to see the average values for two different categories at the same time.\n",
    "\n",
    "For example:\n",
    "- See sales totals per country and per product. \n",
    "- See network usage per device and per country.\n",
    "- See e-commerce sales per hour and per country.\n",
    "\n",
    "How do we do this?\n",
    "- Choose one categorical column whose values will be on the index (rows).\n",
    "- Choose one categorical column whose values will be the columns.\n",
    "- Choose one numeric column to perform the calculation\n",
    "- Choose an aggregation method (by default, it's \"mean\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "aa63df6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>country</th>\n",
       "      <th>Albania</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Australia</th>\n",
       "      <th>Austria</th>\n",
       "      <th>Bosnia and Herzegovina</th>\n",
       "      <th>Brazil</th>\n",
       "      <th>Bulgaria</th>\n",
       "      <th>Canada</th>\n",
       "      <th>Chile</th>\n",
       "      <th>China</th>\n",
       "      <th>...</th>\n",
       "      <th>Slovenia</th>\n",
       "      <th>South Africa</th>\n",
       "      <th>South Korea</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Switzerland</th>\n",
       "      <th>Turkey</th>\n",
       "      <th>US</th>\n",
       "      <th>US-France</th>\n",
       "      <th>Ukraine</th>\n",
       "      <th>Uruguay</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variety</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bordeaux-style Red Blend</th>\n",
       "      <td>NaN</td>\n",
       "      <td>45.382353</td>\n",
       "      <td>51.703704</td>\n",
       "      <td>36.875000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>46.471698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>36.479675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>57.089666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabernet Sauvignon</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16.299763</td>\n",
       "      <td>30.015576</td>\n",
       "      <td>34.875000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.00</td>\n",
       "      <td>12.312500</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>19.966527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>24.920188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.770270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>49.179720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabernet Sauvignon-Merlot</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20.045455</td>\n",
       "      <td>24.523810</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>33.854167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chardonnay</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13.812636</td>\n",
       "      <td>20.409295</td>\n",
       "      <td>38.585366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>23.961538</td>\n",
       "      <td>14.592742</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>19.131387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.626866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>27.676953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Merlot</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13.427083</td>\n",
       "      <td>17.388235</td>\n",
       "      <td>47.428571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.80</td>\n",
       "      <td>9.545455</td>\n",
       "      <td>77.625000</td>\n",
       "      <td>12.841986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.666667</td>\n",
       "      <td>17.920635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.166667</td>\n",
       "      <td>28.5</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>26.199061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pinot Noir</th>\n",
       "      <td>NaN</td>\n",
       "      <td>27.025210</td>\n",
       "      <td>28.460317</td>\n",
       "      <td>39.115044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>18.403077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>39.133333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.483871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.868193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red Blend</th>\n",
       "      <td>NaN</td>\n",
       "      <td>34.993994</td>\n",
       "      <td>28.696296</td>\n",
       "      <td>33.268293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.00</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>37.147500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>25.243902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.355915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.700000</td>\n",
       "      <td>32.411747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Riesling</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>19.473118</td>\n",
       "      <td>37.149533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>28.650000</td>\n",
       "      <td>17.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.614779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rosé</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12.740741</td>\n",
       "      <td>16.137931</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>12.308824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>13.542857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.808642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>18.056196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sauvignon Blanc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13.261745</td>\n",
       "      <td>16.671756</td>\n",
       "      <td>31.010989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>13.411126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>14.991124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.620000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.850116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shiraz</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>41.343904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>13.960784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.016129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.313043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sparkling Blend</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15.227273</td>\n",
       "      <td>16.345455</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.571429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.281022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.459752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Syrah</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15.885714</td>\n",
       "      <td>104.071429</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>23.440541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.419355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.666667</td>\n",
       "      <td>33.389998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viognier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11.214286</td>\n",
       "      <td>19.657534</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.335430</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White Blend</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.163265</td>\n",
       "      <td>14.565217</td>\n",
       "      <td>35.970149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>15.977273</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>18.477612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.063187</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.352941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "country                    Albania  Argentina   Australia    Austria  \\\n",
       "variety                                                                \n",
       "Bordeaux-style Red Blend       NaN  45.382353   51.703704  36.875000   \n",
       "Cabernet Sauvignon             NaN  16.299763   30.015576  34.875000   \n",
       "Cabernet Sauvignon-Merlot      NaN  20.045455   24.523810  30.000000   \n",
       "Chardonnay                     NaN  13.812636   20.409295  38.585366   \n",
       "Merlot                         NaN  13.427083   17.388235  47.428571   \n",
       "Pinot Noir                     NaN  27.025210   28.460317  39.115044   \n",
       "Red Blend                      NaN  34.993994   28.696296  33.268293   \n",
       "Riesling                       NaN  18.000000   19.473118  37.149533   \n",
       "Rosé                           NaN  12.740741   16.137931  14.250000   \n",
       "Sauvignon Blanc                NaN  13.261745   16.671756  31.010989   \n",
       "Shiraz                         NaN   8.666667   41.343904        NaN   \n",
       "Sparkling Blend                NaN  15.227273   16.345455  33.000000   \n",
       "Syrah                          NaN  15.885714  104.071429  38.000000   \n",
       "Viognier                       NaN  11.214286   19.657534  54.000000   \n",
       "White Blend                    NaN  17.163265   14.565217  35.970149   \n",
       "\n",
       "country                    Bosnia and Herzegovina  Brazil   Bulgaria  \\\n",
       "variety                                                                \n",
       "Bordeaux-style Red Blend                      NaN   35.00        NaN   \n",
       "Cabernet Sauvignon                            NaN   13.00  12.312500   \n",
       "Cabernet Sauvignon-Merlot                     NaN   23.00        NaN   \n",
       "Chardonnay                                    NaN     NaN   9.750000   \n",
       "Merlot                                        NaN   13.80   9.545455   \n",
       "Pinot Noir                                    NaN     NaN  14.200000   \n",
       "Red Blend                                     NaN   29.00  18.333333   \n",
       "Riesling                                      NaN     NaN   8.500000   \n",
       "Rosé                                          NaN     NaN   9.000000   \n",
       "Sauvignon Blanc                               NaN     NaN   8.400000   \n",
       "Shiraz                                        NaN     NaN        NaN   \n",
       "Sparkling Blend                               NaN   20.75        NaN   \n",
       "Syrah                                         NaN     NaN  28.000000   \n",
       "Viognier                                      NaN     NaN        NaN   \n",
       "White Blend                                   NaN     NaN   8.000000   \n",
       "\n",
       "country                       Canada      Chile  China  ...   Slovenia  \\\n",
       "variety                                                 ...              \n",
       "Bordeaux-style Red Blend   47.500000  46.471698    NaN  ...  44.000000   \n",
       "Cabernet Sauvignon         66.000000  19.966527    NaN  ...  32.500000   \n",
       "Cabernet Sauvignon-Merlot        NaN  17.666667    NaN  ...        NaN   \n",
       "Chardonnay                 23.961538  14.592742   27.0  ...  24.500000   \n",
       "Merlot                     77.625000  12.841986    NaN  ...  35.666667   \n",
       "Pinot Noir                 33.333333  18.403077    NaN  ...  28.250000   \n",
       "Red Blend                  30.500000  37.147500    NaN  ...  28.666667   \n",
       "Riesling                   28.650000  17.700000    NaN  ...  30.666667   \n",
       "Rosé                       20.000000  12.308824    NaN  ...  23.666667   \n",
       "Sauvignon Blanc            20.250000  13.411126    NaN  ...  23.250000   \n",
       "Shiraz                     20.000000  13.960784    NaN  ...        NaN   \n",
       "Sparkling Blend                  NaN  27.500000    NaN  ...        NaN   \n",
       "Syrah                      36.000000  23.440541    NaN  ...        NaN   \n",
       "Viognier                   24.000000  13.000000    NaN  ...        NaN   \n",
       "White Blend                21.333333  15.977273    7.0  ...  43.000000   \n",
       "\n",
       "country                    South Africa  South Korea      Spain  Switzerland  \\\n",
       "variety                                                                        \n",
       "Bordeaux-style Red Blend      36.479675          NaN  74.333333          NaN   \n",
       "Cabernet Sauvignon            24.920188          NaN  29.770270          NaN   \n",
       "Cabernet Sauvignon-Merlot     22.555556          NaN  16.150000          NaN   \n",
       "Chardonnay                    19.131387          NaN  15.626866          NaN   \n",
       "Merlot                        17.920635          NaN  15.166667         28.5   \n",
       "Pinot Noir                    39.133333          NaN  18.483871          NaN   \n",
       "Red Blend                     25.243902          NaN  34.355915          NaN   \n",
       "Riesling                      17.200000          NaN  20.000000          NaN   \n",
       "Rosé                          13.542857          NaN  10.808642          NaN   \n",
       "Sauvignon Blanc               14.991124          NaN  14.620000          NaN   \n",
       "Shiraz                        21.016129          NaN   9.500000          NaN   \n",
       "Sparkling Blend               19.571429          NaN  17.281022          NaN   \n",
       "Syrah                         29.600000          NaN  37.419355          NaN   \n",
       "Viognier                      19.800000          NaN  13.000000          NaN   \n",
       "White Blend                   18.477612          NaN  18.063187         21.0   \n",
       "\n",
       "country                       Turkey         US  US-France  Ukraine    Uruguay  \n",
       "variety                                                                         \n",
       "Bordeaux-style Red Blend   25.000000  57.089666        NaN      NaN        NaN  \n",
       "Cabernet Sauvignon         79.000000  49.179720        NaN      NaN  11.500000  \n",
       "Cabernet Sauvignon-Merlot  16.000000  33.854167        NaN      NaN        NaN  \n",
       "Chardonnay                 17.000000  27.676953        NaN      NaN  40.000000  \n",
       "Merlot                     68.500000  26.199061        NaN      NaN   8.000000  \n",
       "Pinot Noir                       NaN  41.868193        NaN      NaN  20.000000  \n",
       "Red Blend                  29.700000  32.411747        NaN      NaN  35.142857  \n",
       "Riesling                         NaN  17.614779        NaN      NaN        NaN  \n",
       "Rosé                       15.666667  18.056196        NaN      NaN  15.000000  \n",
       "Sauvignon Blanc            18.000000  18.850116        NaN      NaN        NaN  \n",
       "Shiraz                           NaN  15.313043        NaN      NaN        NaN  \n",
       "Sparkling Blend                  NaN  32.459752        NaN     13.0        NaN  \n",
       "Syrah                      33.666667  33.389998        NaN      NaN        NaN  \n",
       "Viognier                         NaN  22.335430       50.0      NaN  14.000000  \n",
       "White Blend                      NaN  20.352941        NaN      NaN        NaN  \n",
       "\n",
       "[15 rows x 46 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I want to create a pivot table from the wine data:\n",
    "# - country is the columns\n",
    "# - variety is the index\n",
    "# - price is our numeric column\n",
    "# - mean is the aggregation method\n",
    "\n",
    "filename = '/Users/reuven/Courses/Current/data/winemag-150k-reviews.csv'\n",
    "\n",
    "df = pd.read_csv(filename, usecols=['country', 'price', 'variety'])\n",
    "\n",
    "df.pivot_table(index='variety', \n",
    "               columns='country', \n",
    "               values='price').dropna(thresh=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b969bf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>price</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>235.0</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Pinot Noir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence red blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150925</th>\n",
       "      <td>Italy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>White Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150926</th>\n",
       "      <td>France</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Champagne Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150927</th>\n",
       "      <td>Italy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>White Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150928</th>\n",
       "      <td>France</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Champagne Blend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150929</th>\n",
       "      <td>Italy</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Pinot Grigio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150930 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  price             variety\n",
       "0           US  235.0  Cabernet Sauvignon\n",
       "1        Spain  110.0       Tinta de Toro\n",
       "2           US   90.0     Sauvignon Blanc\n",
       "3           US   65.0          Pinot Noir\n",
       "4       France   66.0  Provence red blend\n",
       "...        ...    ...                 ...\n",
       "150925   Italy   20.0         White Blend\n",
       "150926  France   27.0     Champagne Blend\n",
       "150927   Italy   20.0         White Blend\n",
       "150928  France   52.0     Champagne Blend\n",
       "150929   Italy   15.0        Pinot Grigio\n",
       "\n",
       "[150930 rows x 3 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "af024bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>country</th>\n",
       "      <th>Albania</th>\n",
       "      <th>Argentina</th>\n",
       "      <th>Australia</th>\n",
       "      <th>Austria</th>\n",
       "      <th>Bosnia and Herzegovina</th>\n",
       "      <th>Brazil</th>\n",
       "      <th>Bulgaria</th>\n",
       "      <th>Canada</th>\n",
       "      <th>Chile</th>\n",
       "      <th>China</th>\n",
       "      <th>...</th>\n",
       "      <th>Slovenia</th>\n",
       "      <th>South Africa</th>\n",
       "      <th>South Korea</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Switzerland</th>\n",
       "      <th>Turkey</th>\n",
       "      <th>US</th>\n",
       "      <th>US-France</th>\n",
       "      <th>Ukraine</th>\n",
       "      <th>Uruguay</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variety</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bordeaux-style Red Blend</th>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabernet Sauvignon</th>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabernet Sauvignon-Merlot</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chardonnay</th>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Merlot</th>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pinot Noir</th>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red Blend</th>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Riesling</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rosé</th>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sauvignon Blanc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shiraz</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sparkling Blend</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Syrah</th>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viognier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White Blend</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "country                    Albania  Argentina  Australia  Austria  \\\n",
       "variety                                                             \n",
       "Bordeaux-style Red Blend       NaN      150.0      145.0     43.0   \n",
       "Cabernet Sauvignon             NaN       76.0      500.0     50.0   \n",
       "Cabernet Sauvignon-Merlot      NaN       50.0       75.0     63.0   \n",
       "Chardonnay                     NaN      115.0       90.0    111.0   \n",
       "Merlot                         NaN       40.0       86.0     52.0   \n",
       "Pinot Noir                     NaN      250.0      125.0     89.0   \n",
       "Red Blend                      NaN      120.0      200.0     90.0   \n",
       "Riesling                       NaN       18.0       57.0    126.0   \n",
       "Rosé                           NaN       25.0       25.0     25.0   \n",
       "Sauvignon Blanc                NaN       72.0       30.0     65.0   \n",
       "Shiraz                         NaN       13.0      850.0      NaN   \n",
       "Sparkling Blend                NaN       23.0       40.0     44.0   \n",
       "Syrah                          NaN       80.0      350.0     38.0   \n",
       "Viognier                       NaN       20.0       45.0     54.0   \n",
       "White Blend                    NaN       50.0       38.0    120.0   \n",
       "\n",
       "country                    Bosnia and Herzegovina  Brazil  Bulgaria  Canada  \\\n",
       "variety                                                                       \n",
       "Bordeaux-style Red Blend                      NaN    35.0       NaN    70.0   \n",
       "Cabernet Sauvignon                            NaN    13.0      19.0    70.0   \n",
       "Cabernet Sauvignon-Merlot                     NaN    35.0       NaN     NaN   \n",
       "Chardonnay                                    NaN     NaN      14.0    34.0   \n",
       "Merlot                                        NaN    15.0      15.0   145.0   \n",
       "Pinot Noir                                    NaN     NaN      28.0    50.0   \n",
       "Red Blend                                     NaN    29.0      20.0    31.0   \n",
       "Riesling                                      NaN     NaN       9.0    85.0   \n",
       "Rosé                                          NaN     NaN       9.0    24.0   \n",
       "Sauvignon Blanc                               NaN     NaN       9.0    25.0   \n",
       "Shiraz                                        NaN     NaN       NaN    20.0   \n",
       "Sparkling Blend                               NaN    31.0       NaN     NaN   \n",
       "Syrah                                         NaN     NaN      28.0    38.0   \n",
       "Viognier                                      NaN     NaN       NaN    25.0   \n",
       "White Blend                                   NaN     NaN       8.0    22.0   \n",
       "\n",
       "country                    Chile  China  ...  Slovenia  South Africa  \\\n",
       "variety                                  ...                           \n",
       "Bordeaux-style Red Blend   100.0    NaN  ...      75.0         125.0   \n",
       "Cabernet Sauvignon         400.0    NaN  ...      38.0          65.0   \n",
       "Cabernet Sauvignon-Merlot   40.0    NaN  ...       NaN          67.0   \n",
       "Chardonnay                  95.0   27.0  ...      45.0          53.0   \n",
       "Merlot                      35.0    NaN  ...      37.0          75.0   \n",
       "Pinot Noir                  55.0    NaN  ...      40.0          75.0   \n",
       "Red Blend                  400.0    NaN  ...      50.0         100.0   \n",
       "Riesling                    30.0    NaN  ...      36.0          24.0   \n",
       "Rosé                        20.0    NaN  ...      24.0          23.0   \n",
       "Sauvignon Blanc             37.0    NaN  ...      31.0          50.0   \n",
       "Shiraz                      29.0    NaN  ...       NaN         139.0   \n",
       "Sparkling Blend             40.0    NaN  ...       NaN          55.0   \n",
       "Syrah                      150.0    NaN  ...       NaN          70.0   \n",
       "Viognier                    22.0    NaN  ...       NaN          30.0   \n",
       "White Blend                 40.0    7.0  ...      90.0          42.0   \n",
       "\n",
       "country                    South Korea  Spain  Switzerland  Turkey      US  \\\n",
       "variety                                                                      \n",
       "Bordeaux-style Red Blend           NaN  150.0          NaN    25.0   500.0   \n",
       "Cabernet Sauvignon                 NaN  135.0          NaN    79.0   625.0   \n",
       "Cabernet Sauvignon-Merlot          NaN   23.0          NaN    16.0    85.0   \n",
       "Chardonnay                         NaN   90.0          NaN    17.0  2013.0   \n",
       "Merlot                             NaN   30.0         38.0   120.0   140.0   \n",
       "Pinot Noir                         NaN   46.0          NaN     NaN   185.0   \n",
       "Red Blend                          NaN  440.0          NaN    60.0   290.0   \n",
       "Riesling                           NaN   20.0          NaN     NaN   100.0   \n",
       "Rosé                               NaN   25.0          NaN    17.0    75.0   \n",
       "Sauvignon Blanc                    NaN   30.0          NaN    18.0    90.0   \n",
       "Shiraz                             NaN   10.0          NaN     NaN    74.0   \n",
       "Sparkling Blend                    NaN  150.0          NaN     NaN   189.0   \n",
       "Syrah                              NaN  110.0          NaN    45.0   175.0   \n",
       "Viognier                           NaN   13.0          NaN     NaN    60.0   \n",
       "White Blend                        NaN   95.0         21.0     NaN    85.0   \n",
       "\n",
       "country                    US-France  Ukraine  Uruguay  \n",
       "variety                                                 \n",
       "Bordeaux-style Red Blend         NaN      NaN      NaN  \n",
       "Cabernet Sauvignon               NaN      NaN     15.0  \n",
       "Cabernet Sauvignon-Merlot        NaN      NaN      NaN  \n",
       "Chardonnay                       NaN      NaN     40.0  \n",
       "Merlot                           NaN      NaN      9.0  \n",
       "Pinot Noir                       NaN      NaN     20.0  \n",
       "Red Blend                        NaN      NaN     60.0  \n",
       "Riesling                         NaN      NaN      NaN  \n",
       "Rosé                             NaN      NaN     15.0  \n",
       "Sauvignon Blanc                  NaN      NaN      NaN  \n",
       "Shiraz                           NaN      NaN      NaN  \n",
       "Sparkling Blend                  NaN     13.0      NaN  \n",
       "Syrah                            NaN      NaN      NaN  \n",
       "Viognier                        50.0      NaN     15.0  \n",
       "White Blend                      NaN      NaN      NaN  \n",
       "\n",
       "[15 rows x 46 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(index='variety', \n",
    "               columns='country', \n",
    "               values='price', aggfunc='max').dropna(thresh=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de777fc",
   "metadata": {},
   "source": [
    "# Exercise: Pivot tables and olympic data\n",
    "\n",
    "1. Create a data frame from `olympic_athlete_events.csv`, in the zipfile. We only care about Sex, Age, Height, Weight, Team, Year.\n",
    "2. Create a pivot table in which the columns are years, and the index is teams, and we'll see the mean height.\n",
    "3. Create a pivot table in which the columns are years, and the index is Sex, and we'll see the mean age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "72fb57f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Team</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>China</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denmark/Sweden</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex   Age  Height  Weight            Team  Year\n",
       "0   M  24.0   180.0    80.0           China  1992\n",
       "1   M  23.0   170.0    60.0           China  2012\n",
       "2   M  24.0     NaN     NaN         Denmark  1920\n",
       "3   M  34.0     NaN     NaN  Denmark/Sweden  1900\n",
       "4   F  21.0   185.0    82.0     Netherlands  1988"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/reuven/Courses/Current/data/olympic_athlete_events.csv'\n",
    "\n",
    "df = pd.read_csv(filename,\n",
    "                usecols=['Sex', 'Age', 'Height', 'Weight', 'Team', 'Year'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "32ab669a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Year</th>\n",
       "      <th>1896</th>\n",
       "      <th>1900</th>\n",
       "      <th>1904</th>\n",
       "      <th>1906</th>\n",
       "      <th>1908</th>\n",
       "      <th>1912</th>\n",
       "      <th>1920</th>\n",
       "      <th>1924</th>\n",
       "      <th>1928</th>\n",
       "      <th>1932</th>\n",
       "      <th>...</th>\n",
       "      <th>1998</th>\n",
       "      <th>2000</th>\n",
       "      <th>2002</th>\n",
       "      <th>2004</th>\n",
       "      <th>2006</th>\n",
       "      <th>2008</th>\n",
       "      <th>2010</th>\n",
       "      <th>2012</th>\n",
       "      <th>2014</th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Team</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>NaN</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.733333</td>\n",
       "      <td>177.318182</td>\n",
       "      <td>176.375000</td>\n",
       "      <td>175.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>173.676471</td>\n",
       "      <td>177.050000</td>\n",
       "      <td>171.024390</td>\n",
       "      <td>177.430769</td>\n",
       "      <td>173.933333</td>\n",
       "      <td>176.969589</td>\n",
       "      <td>172.272727</td>\n",
       "      <td>178.363636</td>\n",
       "      <td>173.714286</td>\n",
       "      <td>178.614931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria</th>\n",
       "      <td>NaN</td>\n",
       "      <td>176.500000</td>\n",
       "      <td>169.500000</td>\n",
       "      <td>179.857143</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>181.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>173.181818</td>\n",
       "      <td>173.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>177.506849</td>\n",
       "      <td>179.464912</td>\n",
       "      <td>178.736111</td>\n",
       "      <td>178.920455</td>\n",
       "      <td>178.008065</td>\n",
       "      <td>177.258427</td>\n",
       "      <td>176.604839</td>\n",
       "      <td>176.677778</td>\n",
       "      <td>177.172249</td>\n",
       "      <td>176.308642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>176.388889</td>\n",
       "      <td>178.470588</td>\n",
       "      <td>178.363636</td>\n",
       "      <td>179.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>175.095745</td>\n",
       "      <td>176.923077</td>\n",
       "      <td>175.685714</td>\n",
       "      <td>178.750000</td>\n",
       "      <td>178.517857</td>\n",
       "      <td>177.100000</td>\n",
       "      <td>177.401408</td>\n",
       "      <td>173.818182</td>\n",
       "      <td>176.224638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <td>NaN</td>\n",
       "      <td>169.250000</td>\n",
       "      <td>176.750000</td>\n",
       "      <td>176.666667</td>\n",
       "      <td>177.238095</td>\n",
       "      <td>177.440000</td>\n",
       "      <td>172.621622</td>\n",
       "      <td>174.700000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>173.409091</td>\n",
       "      <td>...</td>\n",
       "      <td>174.258065</td>\n",
       "      <td>175.638142</td>\n",
       "      <td>175.208122</td>\n",
       "      <td>174.156658</td>\n",
       "      <td>175.047101</td>\n",
       "      <td>175.733184</td>\n",
       "      <td>175.688172</td>\n",
       "      <td>174.573446</td>\n",
       "      <td>175.080495</td>\n",
       "      <td>174.251889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Denmark</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168.333333</td>\n",
       "      <td>171.400000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>172.153846</td>\n",
       "      <td>169.636364</td>\n",
       "      <td>168.613636</td>\n",
       "      <td>...</td>\n",
       "      <td>175.750000</td>\n",
       "      <td>180.035714</td>\n",
       "      <td>173.181818</td>\n",
       "      <td>178.805825</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>182.970297</td>\n",
       "      <td>175.739130</td>\n",
       "      <td>180.462069</td>\n",
       "      <td>183.642857</td>\n",
       "      <td>180.944056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finland</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.857143</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>176.280702</td>\n",
       "      <td>176.129032</td>\n",
       "      <td>175.160714</td>\n",
       "      <td>172.733333</td>\n",
       "      <td>173.523077</td>\n",
       "      <td>...</td>\n",
       "      <td>174.234848</td>\n",
       "      <td>176.647727</td>\n",
       "      <td>175.345455</td>\n",
       "      <td>179.417910</td>\n",
       "      <td>175.607143</td>\n",
       "      <td>177.657143</td>\n",
       "      <td>175.431507</td>\n",
       "      <td>175.043478</td>\n",
       "      <td>175.551020</td>\n",
       "      <td>176.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>NaN</td>\n",
       "      <td>169.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.280000</td>\n",
       "      <td>174.777778</td>\n",
       "      <td>174.420000</td>\n",
       "      <td>171.720930</td>\n",
       "      <td>171.960000</td>\n",
       "      <td>172.841270</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>174.827586</td>\n",
       "      <td>176.231760</td>\n",
       "      <td>175.774390</td>\n",
       "      <td>176.114790</td>\n",
       "      <td>174.038710</td>\n",
       "      <td>176.963636</td>\n",
       "      <td>174.765625</td>\n",
       "      <td>177.335714</td>\n",
       "      <td>173.772487</td>\n",
       "      <td>177.748016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Great Britain</th>\n",
       "      <td>188.000000</td>\n",
       "      <td>182.125000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>178.629630</td>\n",
       "      <td>173.142857</td>\n",
       "      <td>174.787234</td>\n",
       "      <td>176.584906</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>176.634146</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>173.764706</td>\n",
       "      <td>176.482587</td>\n",
       "      <td>173.055556</td>\n",
       "      <td>176.661932</td>\n",
       "      <td>176.111111</td>\n",
       "      <td>176.886199</td>\n",
       "      <td>176.338235</td>\n",
       "      <td>177.763040</td>\n",
       "      <td>173.428571</td>\n",
       "      <td>176.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greece</th>\n",
       "      <td>175.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>182.444444</td>\n",
       "      <td>179.600000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>180.750000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>176.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>179.642857</td>\n",
       "      <td>175.542857</td>\n",
       "      <td>174.733333</td>\n",
       "      <td>176.564777</td>\n",
       "      <td>175.500000</td>\n",
       "      <td>178.790698</td>\n",
       "      <td>173.833333</td>\n",
       "      <td>178.852174</td>\n",
       "      <td>175.923077</td>\n",
       "      <td>180.634615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hungary</th>\n",
       "      <td>NaN</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>180.833333</td>\n",
       "      <td>182.750000</td>\n",
       "      <td>177.066667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.857143</td>\n",
       "      <td>178.928571</td>\n",
       "      <td>180.520000</td>\n",
       "      <td>...</td>\n",
       "      <td>175.875000</td>\n",
       "      <td>179.054852</td>\n",
       "      <td>176.391304</td>\n",
       "      <td>179.771654</td>\n",
       "      <td>178.062500</td>\n",
       "      <td>178.912037</td>\n",
       "      <td>174.218750</td>\n",
       "      <td>180.900000</td>\n",
       "      <td>173.540541</td>\n",
       "      <td>179.426471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>178.250000</td>\n",
       "      <td>179.888889</td>\n",
       "      <td>179.650000</td>\n",
       "      <td>170.103448</td>\n",
       "      <td>171.571429</td>\n",
       "      <td>169.903226</td>\n",
       "      <td>...</td>\n",
       "      <td>174.238994</td>\n",
       "      <td>177.502222</td>\n",
       "      <td>172.107527</td>\n",
       "      <td>177.740426</td>\n",
       "      <td>173.300752</td>\n",
       "      <td>176.444934</td>\n",
       "      <td>173.408163</td>\n",
       "      <td>176.275401</td>\n",
       "      <td>172.511628</td>\n",
       "      <td>176.440506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>173.692308</td>\n",
       "      <td>177.391304</td>\n",
       "      <td>175.322581</td>\n",
       "      <td>...</td>\n",
       "      <td>177.458333</td>\n",
       "      <td>181.996491</td>\n",
       "      <td>179.681818</td>\n",
       "      <td>181.185606</td>\n",
       "      <td>179.542373</td>\n",
       "      <td>180.771739</td>\n",
       "      <td>177.430769</td>\n",
       "      <td>179.779817</td>\n",
       "      <td>177.524390</td>\n",
       "      <td>177.411215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norway</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>172.500000</td>\n",
       "      <td>172.666667</td>\n",
       "      <td>174.138889</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>176.526316</td>\n",
       "      <td>178.176471</td>\n",
       "      <td>175.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>177.496644</td>\n",
       "      <td>176.927928</td>\n",
       "      <td>177.584337</td>\n",
       "      <td>179.346154</td>\n",
       "      <td>177.776398</td>\n",
       "      <td>176.510204</td>\n",
       "      <td>178.552632</td>\n",
       "      <td>179.782609</td>\n",
       "      <td>177.410959</td>\n",
       "      <td>178.701299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweden</th>\n",
       "      <td>NaN</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179.238095</td>\n",
       "      <td>178.254902</td>\n",
       "      <td>177.517986</td>\n",
       "      <td>176.909091</td>\n",
       "      <td>175.300000</td>\n",
       "      <td>180.416667</td>\n",
       "      <td>178.517241</td>\n",
       "      <td>...</td>\n",
       "      <td>175.924658</td>\n",
       "      <td>179.958763</td>\n",
       "      <td>176.283019</td>\n",
       "      <td>178.180645</td>\n",
       "      <td>176.833333</td>\n",
       "      <td>177.833333</td>\n",
       "      <td>177.029070</td>\n",
       "      <td>178.327381</td>\n",
       "      <td>176.628378</td>\n",
       "      <td>178.102151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Switzerland</th>\n",
       "      <td>NaN</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>172.666667</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>174.714286</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>174.283019</td>\n",
       "      <td>176.492754</td>\n",
       "      <td>176.193548</td>\n",
       "      <td>176.305970</td>\n",
       "      <td>176.012121</td>\n",
       "      <td>176.053571</td>\n",
       "      <td>176.618280</td>\n",
       "      <td>177.098361</td>\n",
       "      <td>174.046512</td>\n",
       "      <td>173.858108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>179.875000</td>\n",
       "      <td>179.025000</td>\n",
       "      <td>176.178082</td>\n",
       "      <td>180.271186</td>\n",
       "      <td>179.476190</td>\n",
       "      <td>179.160550</td>\n",
       "      <td>176.754098</td>\n",
       "      <td>175.689655</td>\n",
       "      <td>178.918750</td>\n",
       "      <td>178.357616</td>\n",
       "      <td>...</td>\n",
       "      <td>173.467181</td>\n",
       "      <td>177.325269</td>\n",
       "      <td>173.768421</td>\n",
       "      <td>176.936080</td>\n",
       "      <td>173.867797</td>\n",
       "      <td>177.471774</td>\n",
       "      <td>174.488449</td>\n",
       "      <td>178.091181</td>\n",
       "      <td>174.714715</td>\n",
       "      <td>177.789398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Year                 1896        1900        1904        1906        1908  \\\n",
       "Team                                                                        \n",
       "Australia             NaN  178.000000         NaN  172.200000         NaN   \n",
       "Austria               NaN  176.500000  169.500000  179.857143  180.000000   \n",
       "Belgium               NaN         NaN         NaN         NaN  179.000000   \n",
       "Canada                NaN  169.250000  176.750000  176.666667  177.238095   \n",
       "Denmark               NaN         NaN         NaN         NaN  168.333333   \n",
       "Finland               NaN         NaN         NaN  180.857143  180.000000   \n",
       "France                NaN  169.555556         NaN  172.280000  174.777778   \n",
       "Great Britain  188.000000  182.125000  187.000000  178.629630  173.142857   \n",
       "Greece         175.666667         NaN  182.000000  182.444444  179.600000   \n",
       "Hungary               NaN  187.000000  187.000000  180.833333  182.750000   \n",
       "Italy                 NaN         NaN  172.000000  171.000000  178.250000   \n",
       "Netherlands           NaN         NaN         NaN         NaN  188.200000   \n",
       "Norway                NaN         NaN  173.000000  172.500000  172.666667   \n",
       "Sweden                NaN  190.000000         NaN  179.238095  178.254902   \n",
       "Switzerland           NaN  168.000000  180.000000  172.666667  185.000000   \n",
       "United States  179.875000  179.025000  176.178082  180.271186  179.476190   \n",
       "\n",
       "Year                 1912        1920        1924        1928        1932  \\\n",
       "Team                                                                        \n",
       "Australia             NaN  175.733333  177.318182  176.375000  175.285714   \n",
       "Austria        181.142857         NaN  178.000000  173.181818  173.666667   \n",
       "Belgium        180.000000  176.388889  178.470588  178.363636  179.333333   \n",
       "Canada         177.440000  172.621622  174.700000  173.000000  173.409091   \n",
       "Denmark        171.400000  170.000000  172.153846  169.636364  168.613636   \n",
       "Finland        176.280702  176.129032  175.160714  172.733333  173.523077   \n",
       "France         174.420000  171.720930  171.960000  172.841270  173.000000   \n",
       "Great Britain  174.787234  176.584906  177.000000  176.634146  173.000000   \n",
       "Greece         183.000000  178.000000  180.750000  177.000000  176.500000   \n",
       "Hungary        177.066667         NaN  175.857143  178.928571  180.520000   \n",
       "Italy          179.888889  179.650000  170.103448  171.571429  169.903226   \n",
       "Netherlands           NaN  184.000000  173.692308  177.391304  175.322581   \n",
       "Norway         174.138889  177.000000  176.526316  178.176471  175.600000   \n",
       "Sweden         177.517986  176.909091  175.300000  180.416667  178.517241   \n",
       "Switzerland    185.000000  175.000000  171.000000  174.714286  175.000000   \n",
       "United States  179.160550  176.754098  175.689655  178.918750  178.357616   \n",
       "\n",
       "Year           ...        1998        2000        2002        2004  \\\n",
       "Team           ...                                                   \n",
       "Australia      ...  173.676471  177.050000  171.024390  177.430769   \n",
       "Austria        ...  177.506849  179.464912  178.736111  178.920455   \n",
       "Belgium        ...  181.000000  175.095745  176.923077  175.685714   \n",
       "Canada         ...  174.258065  175.638142  175.208122  174.156658   \n",
       "Denmark        ...  175.750000  180.035714  173.181818  178.805825   \n",
       "Finland        ...  174.234848  176.647727  175.345455  179.417910   \n",
       "France         ...  174.827586  176.231760  175.774390  176.114790   \n",
       "Great Britain  ...  173.764706  176.482587  173.055556  176.661932   \n",
       "Greece         ...  179.642857  175.542857  174.733333  176.564777   \n",
       "Hungary        ...  175.875000  179.054852  176.391304  179.771654   \n",
       "Italy          ...  174.238994  177.502222  172.107527  177.740426   \n",
       "Netherlands    ...  177.458333  181.996491  179.681818  181.185606   \n",
       "Norway         ...  177.496644  176.927928  177.584337  179.346154   \n",
       "Sweden         ...  175.924658  179.958763  176.283019  178.180645   \n",
       "Switzerland    ...  174.283019  176.492754  176.193548  176.305970   \n",
       "United States  ...  173.467181  177.325269  173.768421  176.936080   \n",
       "\n",
       "Year                 2006        2008        2010        2012        2014  \\\n",
       "Team                                                                        \n",
       "Australia      173.933333  176.969589  172.272727  178.363636  173.714286   \n",
       "Austria        178.008065  177.258427  176.604839  176.677778  177.172249   \n",
       "Belgium        178.750000  178.517857  177.100000  177.401408  173.818182   \n",
       "Canada         175.047101  175.733184  175.688172  174.573446  175.080495   \n",
       "Denmark        170.000000  182.970297  175.739130  180.462069  183.642857   \n",
       "Finland        175.607143  177.657143  175.431507  175.043478  175.551020   \n",
       "France         174.038710  176.963636  174.765625  177.335714  173.772487   \n",
       "Great Britain  176.111111  176.886199  176.338235  177.763040  173.428571   \n",
       "Greece         175.500000  178.790698  173.833333  178.852174  175.923077   \n",
       "Hungary        178.062500  178.912037  174.218750  180.900000  173.540541   \n",
       "Italy          173.300752  176.444934  173.408163  176.275401  172.511628   \n",
       "Netherlands    179.542373  180.771739  177.430769  179.779817  177.524390   \n",
       "Norway         177.776398  176.510204  178.552632  179.782609  177.410959   \n",
       "Sweden         176.833333  177.833333  177.029070  178.327381  176.628378   \n",
       "Switzerland    176.012121  176.053571  176.618280  177.098361  174.046512   \n",
       "United States  173.867797  177.471774  174.488449  178.091181  174.714715   \n",
       "\n",
       "Year                 2016  \n",
       "Team                       \n",
       "Australia      178.614931  \n",
       "Austria        176.308642  \n",
       "Belgium        176.224638  \n",
       "Canada         174.251889  \n",
       "Denmark        180.944056  \n",
       "Finland        176.090909  \n",
       "France         177.748016  \n",
       "Great Britain  176.400000  \n",
       "Greece         180.634615  \n",
       "Hungary        179.426471  \n",
       "Italy          176.440506  \n",
       "Netherlands    177.411215  \n",
       "Norway         178.701299  \n",
       "Sweden         178.102151  \n",
       "Switzerland    173.858108  \n",
       "United States  177.789398  \n",
       "\n",
       "[16 rows x 35 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pivot table in which the columns are years, and the index is teams, and we'll see the mean height.\n",
    "\n",
    "df.pivot_table(columns='Year', index='Team', values='Height').dropna(thresh=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b8876add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Year</th>\n",
       "      <th>1896</th>\n",
       "      <th>1900</th>\n",
       "      <th>1904</th>\n",
       "      <th>1906</th>\n",
       "      <th>1908</th>\n",
       "      <th>1912</th>\n",
       "      <th>1920</th>\n",
       "      <th>1924</th>\n",
       "      <th>1928</th>\n",
       "      <th>1932</th>\n",
       "      <th>...</th>\n",
       "      <th>1998</th>\n",
       "      <th>2000</th>\n",
       "      <th>2002</th>\n",
       "      <th>2004</th>\n",
       "      <th>2006</th>\n",
       "      <th>2008</th>\n",
       "      <th>2010</th>\n",
       "      <th>2012</th>\n",
       "      <th>2014</th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29.791667</td>\n",
       "      <td>50.230769</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>33.897436</td>\n",
       "      <td>22.379310</td>\n",
       "      <td>24.409836</td>\n",
       "      <td>26.359223</td>\n",
       "      <td>23.712737</td>\n",
       "      <td>29.222552</td>\n",
       "      <td>...</td>\n",
       "      <td>24.353324</td>\n",
       "      <td>24.483057</td>\n",
       "      <td>25.128951</td>\n",
       "      <td>24.780923</td>\n",
       "      <td>25.190666</td>\n",
       "      <td>24.875645</td>\n",
       "      <td>25.300487</td>\n",
       "      <td>25.161651</td>\n",
       "      <td>25.334652</td>\n",
       "      <td>25.572875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>23.580645</td>\n",
       "      <td>29.017825</td>\n",
       "      <td>26.396450</td>\n",
       "      <td>27.139959</td>\n",
       "      <td>26.858268</td>\n",
       "      <td>27.656834</td>\n",
       "      <td>29.470075</td>\n",
       "      <td>28.468815</td>\n",
       "      <td>29.582273</td>\n",
       "      <td>33.008666</td>\n",
       "      <td>...</td>\n",
       "      <td>25.668319</td>\n",
       "      <td>26.030513</td>\n",
       "      <td>26.409181</td>\n",
       "      <td>26.242497</td>\n",
       "      <td>26.473524</td>\n",
       "      <td>26.375161</td>\n",
       "      <td>26.719765</td>\n",
       "      <td>26.615904</td>\n",
       "      <td>26.447699</td>\n",
       "      <td>26.737307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Year       1896       1900       1904       1906       1908       1912  \\\n",
       "Sex                                                                      \n",
       "F           NaN  29.791667  50.230769  23.500000  33.897436  22.379310   \n",
       "M     23.580645  29.017825  26.396450  27.139959  26.858268  27.656834   \n",
       "\n",
       "Year       1920       1924       1928       1932  ...       1998       2000  \\\n",
       "Sex                                               ...                         \n",
       "F     24.409836  26.359223  23.712737  29.222552  ...  24.353324  24.483057   \n",
       "M     29.470075  28.468815  29.582273  33.008666  ...  25.668319  26.030513   \n",
       "\n",
       "Year       2002       2004       2006       2008       2010       2012  \\\n",
       "Sex                                                                      \n",
       "F     25.128951  24.780923  25.190666  24.875645  25.300487  25.161651   \n",
       "M     26.409181  26.242497  26.473524  26.375161  26.719765  26.615904   \n",
       "\n",
       "Year       2014       2016  \n",
       "Sex                         \n",
       "F     25.334652  25.572875  \n",
       "M     26.447699  26.737307  \n",
       "\n",
       "[2 rows x 35 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pivot table in which the columns are years, and the index is Sex, and we'll see the mean age.\n",
    "\n",
    "df.pivot_table(columns='Year', index='Sex', values='Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "04913c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Height</th>\n",
       "      <th>127.0</th>\n",
       "      <th>128.0</th>\n",
       "      <th>130.0</th>\n",
       "      <th>131.0</th>\n",
       "      <th>132.0</th>\n",
       "      <th>133.0</th>\n",
       "      <th>135.0</th>\n",
       "      <th>136.0</th>\n",
       "      <th>137.0</th>\n",
       "      <th>138.0</th>\n",
       "      <th>...</th>\n",
       "      <th>214.0</th>\n",
       "      <th>215.0</th>\n",
       "      <th>216.0</th>\n",
       "      <th>217.0</th>\n",
       "      <th>218.0</th>\n",
       "      <th>219.0</th>\n",
       "      <th>220.0</th>\n",
       "      <th>221.0</th>\n",
       "      <th>223.0</th>\n",
       "      <th>226.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Team</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uzbekistan</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venezuela</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Germany</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yugoslavia</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zimbabwe</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Height        127.0  128.0  130.0  131.0  132.0  133.0  135.0  136.0  137.0  \\\n",
       "Team                                                                          \n",
       "Algeria         NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "Angola          NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "Argentina       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "Australia       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "Austria         NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "...             ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "Uzbekistan      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "Venezuela       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "West Germany    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "Yugoslavia      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "Zimbabwe        NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "Height        138.0  ...  214.0  215.0  216.0  217.0  218.0  219.0  220.0  \\\n",
       "Team                 ...                                                    \n",
       "Algeria         NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "Angola          NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "Argentina       NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "Australia      33.0  ...    NaN    NaN    NaN    NaN   93.0    NaN  135.0   \n",
       "Austria         NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "...             ...  ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "Uzbekistan      NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "Venezuela       NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "West Germany    NaN  ...    NaN    NaN    NaN    NaN  110.0    NaN    NaN   \n",
       "Yugoslavia      NaN  ...    NaN    NaN    NaN  115.0    NaN    NaN    NaN   \n",
       "Zimbabwe       66.0  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "Height        221.0  223.0  226.0  \n",
       "Team                               \n",
       "Algeria         NaN    NaN    NaN  \n",
       "Angola          NaN    NaN    NaN  \n",
       "Argentina       NaN    NaN    NaN  \n",
       "Australia       NaN    NaN    NaN  \n",
       "Austria         NaN    NaN    NaN  \n",
       "...             ...    ...    ...  \n",
       "Uzbekistan      NaN    NaN    NaN  \n",
       "Venezuela       NaN    NaN    NaN  \n",
       "West Germany    NaN    NaN    NaN  \n",
       "Yugoslavia      NaN    NaN    NaN  \n",
       "Zimbabwe        NaN    NaN    NaN  \n",
       "\n",
       "[83 rows x 95 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a terrible idea, but you *could* do a pivot table with numeric (non-categorical) data\n",
    "\n",
    "df.pivot_table(columns='Height', index='Team', values='Weight').dropna(thresh=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "65ec9bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    210945.000000\n",
       "mean        175.338970\n",
       "std          10.518462\n",
       "min         127.000000\n",
       "25%         168.000000\n",
       "50%         175.000000\n",
       "75%         183.000000\n",
       "max         226.000000\n",
       "Name: Height, dtype: float64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can we group by ranges? (using .groupby)\n",
    "# the answer is: no, but we can create a new column based on ranges, and then group there\n",
    "\n",
    "df['Height'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3b57c8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         medium\n",
       "1         medium\n",
       "2            NaN\n",
       "3            NaN\n",
       "4         medium\n",
       "           ...  \n",
       "271111    medium\n",
       "271112    medium\n",
       "271113    medium\n",
       "271114    medium\n",
       "271115    medium\n",
       "Name: Height, Length: 271116, dtype: category\n",
       "Categories (3, object): ['short' < 'medium' < 'tall']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'll divide the heights into short, medium, and tall (very very very non-scientific, non-medical)\n",
    "\n",
    "# short: up to 150 cm\n",
    "# medium is 150 to 185\n",
    "# tall: above 185 cm\n",
    "\n",
    "# pd.cut takes a numeric column and produces a categorical column based on it\n",
    "pd.cut(df['Height'],\n",
    "       [126, 150, 185, 227],    # boundaries\n",
    "        labels=['short', 'medium', 'tall']   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "658e7296",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cut in module pandas.core.reshape.tile:\n",
      "\n",
      "cut(x, bins, right: 'bool' = True, labels=None, retbins: 'bool' = False, precision: 'int' = 3, include_lowest: 'bool' = False, duplicates: 'str' = 'raise', ordered: 'bool' = True)\n",
      "    Bin values into discrete intervals.\n",
      "    \n",
      "    Use `cut` when you need to segment and sort data values into bins. This\n",
      "    function is also useful for going from a continuous variable to a\n",
      "    categorical variable. For example, `cut` could convert ages to groups of\n",
      "    age ranges. Supports binning into an equal number of bins, or a\n",
      "    pre-specified array of bins.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array-like\n",
      "        The input array to be binned. Must be 1-dimensional.\n",
      "    bins : int, sequence of scalars, or IntervalIndex\n",
      "        The criteria to bin by.\n",
      "    \n",
      "        * int : Defines the number of equal-width bins in the range of `x`. The\n",
      "          range of `x` is extended by .1% on each side to include the minimum\n",
      "          and maximum values of `x`.\n",
      "        * sequence of scalars : Defines the bin edges allowing for non-uniform\n",
      "          width. No extension of the range of `x` is done.\n",
      "        * IntervalIndex : Defines the exact bins to be used. Note that\n",
      "          IntervalIndex for `bins` must be non-overlapping.\n",
      "    \n",
      "    right : bool, default True\n",
      "        Indicates whether `bins` includes the rightmost edge or not. If\n",
      "        ``right == True`` (the default), then the `bins` ``[1, 2, 3, 4]``\n",
      "        indicate (1,2], (2,3], (3,4]. This argument is ignored when\n",
      "        `bins` is an IntervalIndex.\n",
      "    labels : array or False, default None\n",
      "        Specifies the labels for the returned bins. Must be the same length as\n",
      "        the resulting bins. If False, returns only integer indicators of the\n",
      "        bins. This affects the type of the output container (see below).\n",
      "        This argument is ignored when `bins` is an IntervalIndex. If True,\n",
      "        raises an error. When `ordered=False`, labels must be provided.\n",
      "    retbins : bool, default False\n",
      "        Whether to return the bins or not. Useful when bins is provided\n",
      "        as a scalar.\n",
      "    precision : int, default 3\n",
      "        The precision at which to store and display the bins labels.\n",
      "    include_lowest : bool, default False\n",
      "        Whether the first interval should be left-inclusive or not.\n",
      "    duplicates : {default 'raise', 'drop'}, optional\n",
      "        If bin edges are not unique, raise ValueError or drop non-uniques.\n",
      "    ordered : bool, default True\n",
      "        Whether the labels are ordered or not. Applies to returned types\n",
      "        Categorical and Series (with Categorical dtype). If True,\n",
      "        the resulting categorical will be ordered. If False, the resulting\n",
      "        categorical will be unordered (labels must be provided).\n",
      "    \n",
      "        .. versionadded:: 1.1.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : Categorical, Series, or ndarray\n",
      "        An array-like object representing the respective bin for each value\n",
      "        of `x`. The type depends on the value of `labels`.\n",
      "    \n",
      "        * None (default) : returns a Series for Series `x` or a\n",
      "          Categorical for all other inputs. The values stored within\n",
      "          are Interval dtype.\n",
      "    \n",
      "        * sequence of scalars : returns a Series for Series `x` or a\n",
      "          Categorical for all other inputs. The values stored within\n",
      "          are whatever the type in the sequence is.\n",
      "    \n",
      "        * False : returns an ndarray of integers.\n",
      "    \n",
      "    bins : numpy.ndarray or IntervalIndex.\n",
      "        The computed or specified bins. Only returned when `retbins=True`.\n",
      "        For scalar or sequence `bins`, this is an ndarray with the computed\n",
      "        bins. If set `duplicates=drop`, `bins` will drop non-unique bin. For\n",
      "        an IntervalIndex `bins`, this is equal to `bins`.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    qcut : Discretize variable into equal-sized buckets based on rank\n",
      "        or based on sample quantiles.\n",
      "    Categorical : Array type for storing data that come from a\n",
      "        fixed set of values.\n",
      "    Series : One-dimensional array with axis labels (including time series).\n",
      "    IntervalIndex : Immutable Index implementing an ordered, sliceable set.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Any NA values will be NA in the result. Out of bounds values will be NA in\n",
      "    the resulting Series or Categorical object.\n",
      "    \n",
      "    Reference :ref:`the user guide <reshaping.tile.cut>` for more examples.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Discretize into three equal-sized bins.\n",
      "    \n",
      "    >>> pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3)\n",
      "    ... # doctest: +ELLIPSIS\n",
      "    [(0.994, 3.0], (5.0, 7.0], (3.0, 5.0], (3.0, 5.0], (5.0, 7.0], ...\n",
      "    Categories (3, interval[float64, right]): [(0.994, 3.0] < (3.0, 5.0] ...\n",
      "    \n",
      "    >>> pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3, retbins=True)\n",
      "    ... # doctest: +ELLIPSIS\n",
      "    ([(0.994, 3.0], (5.0, 7.0], (3.0, 5.0], (3.0, 5.0], (5.0, 7.0], ...\n",
      "    Categories (3, interval[float64, right]): [(0.994, 3.0] < (3.0, 5.0] ...\n",
      "    array([0.994, 3.   , 5.   , 7.   ]))\n",
      "    \n",
      "    Discovers the same bins, but assign them specific labels. Notice that\n",
      "    the returned Categorical's categories are `labels` and is ordered.\n",
      "    \n",
      "    >>> pd.cut(np.array([1, 7, 5, 4, 6, 3]),\n",
      "    ...        3, labels=[\"bad\", \"medium\", \"good\"])\n",
      "    ['bad', 'good', 'medium', 'medium', 'good', 'bad']\n",
      "    Categories (3, object): ['bad' < 'medium' < 'good']\n",
      "    \n",
      "    ``ordered=False`` will result in unordered categories when labels are passed.\n",
      "    This parameter can be used to allow non-unique labels:\n",
      "    \n",
      "    >>> pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,\n",
      "    ...        labels=[\"B\", \"A\", \"B\"], ordered=False)\n",
      "    ['B', 'B', 'A', 'A', 'B', 'B']\n",
      "    Categories (2, object): ['A', 'B']\n",
      "    \n",
      "    ``labels=False`` implies you just want the bins back.\n",
      "    \n",
      "    >>> pd.cut([0, 1, 1, 2], bins=4, labels=False)\n",
      "    array([0, 1, 1, 3])\n",
      "    \n",
      "    Passing a Series as an input returns a Series with categorical dtype:\n",
      "    \n",
      "    >>> s = pd.Series(np.array([2, 4, 6, 8, 10]),\n",
      "    ...               index=['a', 'b', 'c', 'd', 'e'])\n",
      "    >>> pd.cut(s, 3)\n",
      "    ... # doctest: +ELLIPSIS\n",
      "    a    (1.992, 4.667]\n",
      "    b    (1.992, 4.667]\n",
      "    c    (4.667, 7.333]\n",
      "    d     (7.333, 10.0]\n",
      "    e     (7.333, 10.0]\n",
      "    dtype: category\n",
      "    Categories (3, interval[float64, right]): [(1.992, 4.667] < (4.667, ...\n",
      "    \n",
      "    Passing a Series as an input returns a Series with mapping value.\n",
      "    It is used to map numerically to intervals based on bins.\n",
      "    \n",
      "    >>> s = pd.Series(np.array([2, 4, 6, 8, 10]),\n",
      "    ...               index=['a', 'b', 'c', 'd', 'e'])\n",
      "    >>> pd.cut(s, [0, 2, 4, 6, 8, 10], labels=False, retbins=True, right=False)\n",
      "    ... # doctest: +ELLIPSIS\n",
      "    (a    1.0\n",
      "     b    2.0\n",
      "     c    3.0\n",
      "     d    4.0\n",
      "     e    NaN\n",
      "     dtype: float64,\n",
      "     array([ 0,  2,  4,  6,  8, 10]))\n",
      "    \n",
      "    Use `drop` optional when bins is not unique\n",
      "    \n",
      "    >>> pd.cut(s, [0, 2, 4, 6, 10, 10], labels=False, retbins=True,\n",
      "    ...        right=False, duplicates='drop')\n",
      "    ... # doctest: +ELLIPSIS\n",
      "    (a    1.0\n",
      "     b    2.0\n",
      "     c    3.0\n",
      "     d    3.0\n",
      "     e    NaN\n",
      "     dtype: float64,\n",
      "     array([ 0,  2,  4,  6, 10]))\n",
      "    \n",
      "    Passing an IntervalIndex for `bins` results in those categories exactly.\n",
      "    Notice that values not covered by the IntervalIndex are set to NaN. 0\n",
      "    is to the left of the first bin (which is closed on the right), and 1.5\n",
      "    falls between two bins.\n",
      "    \n",
      "    >>> bins = pd.IntervalIndex.from_tuples([(0, 1), (2, 3), (4, 5)])\n",
      "    >>> pd.cut([0, 0.5, 1.5, 2.5, 4.5], bins)\n",
      "    [NaN, (0.0, 1.0], NaN, (2.0, 3.0], (4.0, 5.0]]\n",
      "    Categories (3, interval[int64, right]): [(0, 1] < (2, 3] < (4, 5]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361fb81f",
   "metadata": {},
   "source": [
    "# Next up\n",
    "\n",
    "1. Joining\n",
    "2. Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5565a8b0",
   "metadata": {},
   "source": [
    "# Joining\n",
    "\n",
    "Sometimes, I'll have data spread across more than one data frame. Joining allows me to combine the data frames, temporarily, into a single one, and thus ask questions of the data.\n",
    "\n",
    "If there's a 1-to-1 correspondence between the index on the first DF and the the index on the second DF, then it's pretty obvious how they'll fit together.  But if there are repeates in either DF (or both), then Pandas will match all appropriate rows together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "53105195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banana</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cucumber</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dill</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  price\n",
       "0     apple   1.00\n",
       "1    banana   1.50\n",
       "2  cucumber   0.75\n",
       "3      dill   3.00"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I'll create two data frames -- one for products, and one for sales\n",
    "\n",
    "products_df = DataFrame([{'name':'apple', 'price':1},\n",
    "                         {'name':'banana', 'price':1.5},\n",
    "                         {'name':'cucumber', 'price':0.75},\n",
    "                         {'name':'dill', 'price':3}\n",
    "                         ])\n",
    "\n",
    "products_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bb442544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my next data frame has to do with sales\n",
    "\n",
    "sales_df = DataFrame([{'name':'apple', 'quantity':5},\n",
    "                     {'name':'apple', 'quantity':50},\n",
    "                     {'name':'banana', 'quantity':3},\n",
    "                     {'name':'banana', 'quantity':10},\n",
    "                     {'name':'cucumber', 'quantity':2},\n",
    "                     {'name':'cucumber', 'quantity':6},\n",
    "                     {'name':'dill', 'quantity':10},\n",
    "                     {'name':'dill', 'quantity':1}\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5136c144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banana</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>banana</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cucumber</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cucumber</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dill</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dill</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  quantity\n",
       "0     apple         5\n",
       "1     apple        50\n",
       "2    banana         3\n",
       "3    banana        10\n",
       "4  cucumber         2\n",
       "5  cucumber         6\n",
       "6      dill        10\n",
       "7      dill         1"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2ac5d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to combine (temporarily) these two data frames together\n",
    "# the \"name\" column appears to be common to both\n",
    "\n",
    "# we should make \"name\" the index on both\n",
    "\n",
    "products_df = products_df.set_index('name')\n",
    "sales_df = sales_df.set_index('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f1df0401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banana</th>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cucumber</th>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dill</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          price\n",
       "name           \n",
       "apple      1.00\n",
       "banana     1.50\n",
       "cucumber   0.75\n",
       "dill       3.00"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1be2d6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banana</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banana</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cucumber</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cucumber</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dill</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dill</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          quantity\n",
       "name              \n",
       "apple            5\n",
       "apple           50\n",
       "banana           3\n",
       "banana          10\n",
       "cucumber         2\n",
       "cucumber         6\n",
       "dill            10\n",
       "dill             1"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "66a23c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>1.00</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banana</th>\n",
       "      <td>1.50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banana</th>\n",
       "      <td>1.50</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cucumber</th>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cucumber</th>\n",
       "      <td>0.75</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dill</th>\n",
       "      <td>3.00</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dill</th>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          price  quantity\n",
       "name                     \n",
       "apple      1.00         5\n",
       "apple      1.00        50\n",
       "banana     1.50         3\n",
       "banana     1.50        10\n",
       "cucumber   0.75         2\n",
       "cucumber   0.75         6\n",
       "dill       3.00        10\n",
       "dill       3.00         1"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I get a data frame back \n",
    "products_df.join(sales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3766a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = products_df.join(sales_df)\n",
    "df['revenue'] = df['price'] * df['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a4462d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>1.00</td>\n",
       "      <td>50</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banana</th>\n",
       "      <td>1.50</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banana</th>\n",
       "      <td>1.50</td>\n",
       "      <td>10</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cucumber</th>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cucumber</th>\n",
       "      <td>0.75</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dill</th>\n",
       "      <td>3.00</td>\n",
       "      <td>10</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dill</th>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          price  quantity  revenue\n",
       "name                              \n",
       "apple      1.00         5      5.0\n",
       "apple      1.00        50     50.0\n",
       "banana     1.50         3      4.5\n",
       "banana     1.50        10     15.0\n",
       "cucumber   0.75         2      1.5\n",
       "cucumber   0.75         6      4.5\n",
       "dill       3.00        10     30.0\n",
       "dill       3.00         1      3.0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "eab2c322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113.5"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['revenue'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2833f4e",
   "metadata": {},
   "source": [
    "# How do we join?\n",
    "\n",
    "1. Have two data frames\n",
    "2. Set the indexes on the two data frames to contain the same (or overlapping) values. It's OK if values repeat. It's also OK if values don't appear in both. (In such cases, by default, they won't appear)\n",
    "3. Use `df.join` to join one data frame with another; this returns a new data frame.\n",
    "4. Query the resulting data frame, as you would any other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091649c4",
   "metadata": {},
   "source": [
    "# Exercise: OECD tourist spending\n",
    "\n",
    "The OECD collects lots of economic data about its member countries. We have some such data for a subset of the OECD. We have two files:\n",
    "\n",
    "- `oecd_locations.csv`, with a subset of OECD countries, and\n",
    "- `oecd_tourism.csv`, showing how much was spent (and received) on tourism by people in each OECD country, over several years.\n",
    "\n",
    "1. Create data frames for both of these CSV files.\n",
    "2. Join them together, so that we get the full names of the countries, and not just their abbrevations, when looking at the tourism data.\n",
    "3. Display how much money was spent (INT_EXP) on tourism from each OECD country, on average, across all years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "368bf89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbreviation</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUT</th>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEL</th>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAN</th>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNK</th>\n",
       "      <td>Denmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIN</th>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRA</th>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEU</th>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUN</th>\n",
       "      <td>Hungary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITA</th>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPN</th>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KOR</th>\n",
       "      <td>Korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBR</th>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRA</th>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISR</th>\n",
       "      <td>Israel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name\n",
       "abbreviation                \n",
       "AUS                Australia\n",
       "AUT                  Austria\n",
       "BEL                  Belgium\n",
       "CAN                   Canada\n",
       "DNK                  Denmark\n",
       "FIN                  Finland\n",
       "FRA                   France\n",
       "DEU                  Germany\n",
       "HUN                  Hungary\n",
       "ITA                    Italy\n",
       "JPN                    Japan\n",
       "KOR                    Korea\n",
       "GBR           United Kingdom\n",
       "USA            United States\n",
       "BRA                   Brazil\n",
       "ISR                   Israel"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oecd_locations = pd.read_csv('/Users/reuven/Courses/Current/data/oecd_locations.csv',\n",
    "                            header=None,\n",
    "                            names=['abbreviation', 'name'],\n",
    "                            index_col='abbreviation')\n",
    "oecd_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3c1467c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT</th>\n",
       "      <th>TIME</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOCATION</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>INT_REC</td>\n",
       "      <td>2008</td>\n",
       "      <td>31159.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>INT_REC</td>\n",
       "      <td>2009</td>\n",
       "      <td>29980.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>INT_REC</td>\n",
       "      <td>2010</td>\n",
       "      <td>35165.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>INT_REC</td>\n",
       "      <td>2011</td>\n",
       "      <td>38710.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>INT_REC</td>\n",
       "      <td>2012</td>\n",
       "      <td>38003.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRB</th>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2015</td>\n",
       "      <td>1253.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRB</th>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2016</td>\n",
       "      <td>1351.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRB</th>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2017</td>\n",
       "      <td>1549.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRB</th>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2018</td>\n",
       "      <td>1837.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRB</th>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2019</td>\n",
       "      <td>1999.313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1234 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SUBJECT  TIME      Value\n",
       "LOCATION                          \n",
       "AUS       INT_REC  2008  31159.800\n",
       "AUS       INT_REC  2009  29980.700\n",
       "AUS       INT_REC  2010  35165.500\n",
       "AUS       INT_REC  2011  38710.100\n",
       "AUS       INT_REC  2012  38003.700\n",
       "...           ...   ...        ...\n",
       "SRB       INT-EXP  2015   1253.644\n",
       "SRB       INT-EXP  2016   1351.098\n",
       "SRB       INT-EXP  2017   1549.183\n",
       "SRB       INT-EXP  2018   1837.317\n",
       "SRB       INT-EXP  2019   1999.313\n",
       "\n",
       "[1234 rows x 3 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oecd_tourism = pd.read_csv('/Users/reuven/Courses/Current/data/oecd_tourism.csv',\n",
    "                          usecols=['LOCATION', 'SUBJECT', 'TIME', 'Value'],\n",
    "                          index_col='LOCATION')\n",
    "\n",
    "oecd_tourism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "37fb21f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>SUBJECT</th>\n",
       "      <th>TIME</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>Australia</td>\n",
       "      <td>INT_REC</td>\n",
       "      <td>2008</td>\n",
       "      <td>31159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>Australia</td>\n",
       "      <td>INT_REC</td>\n",
       "      <td>2009</td>\n",
       "      <td>29980.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>Australia</td>\n",
       "      <td>INT_REC</td>\n",
       "      <td>2010</td>\n",
       "      <td>35165.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>Australia</td>\n",
       "      <td>INT_REC</td>\n",
       "      <td>2011</td>\n",
       "      <td>38710.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>Australia</td>\n",
       "      <td>INT_REC</td>\n",
       "      <td>2012</td>\n",
       "      <td>38003.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>United States</td>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2015</td>\n",
       "      <td>144667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>United States</td>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2016</td>\n",
       "      <td>147639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>United States</td>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2017</td>\n",
       "      <td>158331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>United States</td>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2018</td>\n",
       "      <td>172548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>United States</td>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2019</td>\n",
       "      <td>182365.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  SUBJECT  TIME     Value\n",
       "AUS      Australia  INT_REC  2008   31159.8\n",
       "AUS      Australia  INT_REC  2009   29980.7\n",
       "AUS      Australia  INT_REC  2010   35165.5\n",
       "AUS      Australia  INT_REC  2011   38710.1\n",
       "AUS      Australia  INT_REC  2012   38003.7\n",
       "..             ...      ...   ...       ...\n",
       "USA  United States  INT-EXP  2015  144667.0\n",
       "USA  United States  INT-EXP  2016  147639.0\n",
       "USA  United States  INT-EXP  2017  158331.0\n",
       "USA  United States  INT-EXP  2018  172548.0\n",
       "USA  United States  INT-EXP  2019  182365.0\n",
       "\n",
       "[364 rows x 4 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = oecd_locations.join(oecd_tourism)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4d182167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the income, keep only expenses\n",
    "df = df.loc[df['SUBJECT'] == 'INT-EXP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "79a9a31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>SUBJECT</th>\n",
       "      <th>TIME</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>Australia</td>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2008</td>\n",
       "      <td>27620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>Australia</td>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2009</td>\n",
       "      <td>25629.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>Australia</td>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2010</td>\n",
       "      <td>31916.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>Australia</td>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2011</td>\n",
       "      <td>39381.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>Australia</td>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2012</td>\n",
       "      <td>41632.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>United States</td>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2015</td>\n",
       "      <td>144667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>United States</td>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2016</td>\n",
       "      <td>147639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>United States</td>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2017</td>\n",
       "      <td>158331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>United States</td>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2018</td>\n",
       "      <td>172548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>United States</td>\n",
       "      <td>INT-EXP</td>\n",
       "      <td>2019</td>\n",
       "      <td>182365.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  SUBJECT  TIME     Value\n",
       "AUS      Australia  INT-EXP  2008   27620.0\n",
       "AUS      Australia  INT-EXP  2009   25629.6\n",
       "AUS      Australia  INT-EXP  2010   31916.5\n",
       "AUS      Australia  INT-EXP  2011   39381.5\n",
       "AUS      Australia  INT-EXP  2012   41632.8\n",
       "..             ...      ...   ...       ...\n",
       "USA  United States  INT-EXP  2015  144667.0\n",
       "USA  United States  INT-EXP  2016  147639.0\n",
       "USA  United States  INT-EXP  2017  158331.0\n",
       "USA  United States  INT-EXP  2018  172548.0\n",
       "USA  United States  INT-EXP  2019  182365.0\n",
       "\n",
       "[182 rows x 4 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "51de65d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Australia          36727.966667\n",
       "Austria            11934.563636\n",
       "Belgium            20859.883455\n",
       "Brazil             21564.351833\n",
       "Canada             40984.633333\n",
       "Denmark            11326.169636\n",
       "Finland             5877.080909\n",
       "France             51394.272273\n",
       "Germany            96615.075545\n",
       "Hungary             2918.390182\n",
       "Israel              6726.524833\n",
       "Italy              34148.908455\n",
       "Japan              32197.925000\n",
       "Korea              25573.509091\n",
       "United Kingdom     75262.227273\n",
       "United States     142080.666667\n",
       "Name: Value, dtype: float64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('name')['Value'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b958b7c7",
   "metadata": {},
   "source": [
    "# Cleaning data\n",
    "\n",
    "Real-world data is messy!\n",
    "\n",
    "- Bad values\n",
    "- Missing values\n",
    "- States things in multiple ways\n",
    "\n",
    "I've heard several data scientists say that they spend 70-80 percent of their time cleaning data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6cdb0faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summons Number,Plate ID,Registration State,Plate Type,Issue Date,Violation Code,Vehicle Body Type,Vehicle Make,Issuing Agency,Street Code1,Street Code2,Street Code3,Vehicle Expiration Date,Violation Location,Violation Precinct,Issuer Precinct,Issuer Code,Issuer Command,Issuer Squad,Violation Time,Time First Observed,Violation County,Violation In Front Of Or Opposite,House Number,Street Name,Intersecting Street,Date First Observed,Law Section,Sub Division,Violation Legal Code,Days Parking In Effect,From Hours In Effect,To Hours In Effect,Vehicle Color,Unregistered Vehicle?,Vehicle Year,Meter Number,Feet From Curb,Violation Post Code,Violation Description,No Standing or Stopping Violation,Hydrant Violation,Double Parking Violation\r\n",
      "1477633194,J58JKX,NJ,PAS,05/08/1972 12:00:00 AM,16,SDN,HONDA,P,8730,5130,5280,0,72,72,504,342924,T504,0000,0523P,,K,F,270,43 ST,,0,408,E2,,YYYYYBB,0800A,0400P,BK,0,0,-,0,,,,,\r\n",
      "1449715424,KRE6058,PA,PAS,08/29/1977 12:00:00 AM,98,SUBN,ME/BE,P,86530,71800,73110,0,77,77,77,961115,0077,0000,0428P,,K,F,1953,UNION ST,,0,408,F1,,BBBBBBB,ALL,ALL,BLK,0,0,-,0,,,,,\r\n",
      "1455779155,444326R,NJ,PAS,10/03/1988 12:00:00 AM,20,SDN,LEXUS,P,27030,41330,69230,0,88,88,730,535422,T730,0000,0625A,,K,O,45,CLERMONT AVENUE,,0,408,D,,BBBBBBB,ALL,ALL,BLACK,0,0,-,0,,,,,\r\n",
      "1458800908,F728330,OH,PAS,01/03/1990 12:00:00 AM,21,SDN,CHEVR,P,33030,93630,58730,0,90,90,301,355074,T301,0000,1106A,,K,F,218,DIVISION AVE,,0,408,C,,BYBBYBB,1100A,1230P,,0,0,-,0,,,,,\r\n",
      "1466038676,FMY9090,NY,PAS,02/14/1990 12:00:00 AM,21,SUBN,JEEP,S,45130,23930,68130,20210915,90,90,0,668676,KNBO,0000,1253A,,K,F,850,GRAND ST,,0,408,D1,,BYBBYBB,1200A,0300A,GREY,0,2015,-,0,,,,,\r\n",
      "1440657920,KDG0693,PA,PAS,07/21/1990 12:00:00 AM,14,SUBN,HYUN,P,33440,62200,0,20191231,100,100,100,963999,0100,0000,0525P,,Q,,,B 99 ST,SHORE FRONT PKWY,0,408,C,,BBBBBBB,ALL,ALL,GY,0,0,-,0,,,,,\r\n",
      "1460987810,79928MG,NY,COM,09/19/1990 12:00:00 AM,48,DELV,INTER,P,0,0,0,20200531,1,1,401,958976,0401,0000,1120A,,NY,,,W/S/O WASHINGTON ST,S/O SPRING ST,0,408,E9,,BBBBBBB,ALL,ALL,WH,0,2015,-,0,,,,,\r\n",
      "1449130203,JJJ8186,NY,PAS,10/14/1990 12:00:00 AM,14,SUBN,BMW,P,10020,27480,27540,20210710,52,52,52,964971,0052,0000,0320A,,BX,F,2734,BAINBRIDGE AVE,,0,408,F2,,BBBBBBB,ALL,ALL,BLK,0,2010,-,0,,,,,\r\n",
      "1451300189,DKD6024,NC,PAS,07/25/1991 12:00:00 AM,98,SDN,FORD,P,11280,54137,5430,20190930,68,68,68,945183,0068,0000,0843P,,K,F,372,94 ST,,0,408,C3,,BBBBBBB,ALL,ALL,GREY,0,0,-,0,,,,,\r\n"
     ]
    }
   ],
   "source": [
    "!head /Users/reuven/Courses/Current/data/nyc-parking-violations-2020.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca4dc54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d619d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/reuven/Courses/Current/data/nyc-parking-violations-2020.csv'\n",
    "\n",
    "df = pd.read_csv(filename,\n",
    "                usecols=['Plate ID', 'Issue Date', 'Vehicle Make', 'Vehicle Color', 'Street Code1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5f91a23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plate ID</th>\n",
       "      <th>Issue Date</th>\n",
       "      <th>Vehicle Make</th>\n",
       "      <th>Street Code1</th>\n",
       "      <th>Vehicle Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J58JKX</td>\n",
       "      <td>05/08/1972 12:00:00 AM</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>8730</td>\n",
       "      <td>BK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KRE6058</td>\n",
       "      <td>08/29/1977 12:00:00 AM</td>\n",
       "      <td>ME/BE</td>\n",
       "      <td>86530</td>\n",
       "      <td>BLK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>444326R</td>\n",
       "      <td>10/03/1988 12:00:00 AM</td>\n",
       "      <td>LEXUS</td>\n",
       "      <td>27030</td>\n",
       "      <td>BLACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F728330</td>\n",
       "      <td>01/03/1990 12:00:00 AM</td>\n",
       "      <td>CHEVR</td>\n",
       "      <td>33030</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FMY9090</td>\n",
       "      <td>02/14/1990 12:00:00 AM</td>\n",
       "      <td>JEEP</td>\n",
       "      <td>45130</td>\n",
       "      <td>GREY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Plate ID              Issue Date Vehicle Make  Street Code1 Vehicle Color\n",
       "0   J58JKX  05/08/1972 12:00:00 AM        HONDA          8730            BK\n",
       "1  KRE6058  08/29/1977 12:00:00 AM        ME/BE         86530           BLK\n",
       "2  444326R  10/03/1988 12:00:00 AM        LEXUS         27030         BLACK\n",
       "3  F728330  01/03/1990 12:00:00 AM        CHEVR         33030           NaN\n",
       "4  FMY9090  02/14/1990 12:00:00 AM         JEEP         45130          GREY"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "16a189eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Street Code1', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "952048d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plate ID</th>\n",
       "      <th>Issue Date</th>\n",
       "      <th>Vehicle Make</th>\n",
       "      <th>Vehicle Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J58JKX</td>\n",
       "      <td>05/08/1972 12:00:00 AM</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>BK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KRE6058</td>\n",
       "      <td>08/29/1977 12:00:00 AM</td>\n",
       "      <td>ME/BE</td>\n",
       "      <td>BLK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>444326R</td>\n",
       "      <td>10/03/1988 12:00:00 AM</td>\n",
       "      <td>LEXUS</td>\n",
       "      <td>BLACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F728330</td>\n",
       "      <td>01/03/1990 12:00:00 AM</td>\n",
       "      <td>CHEVR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FMY9090</td>\n",
       "      <td>02/14/1990 12:00:00 AM</td>\n",
       "      <td>JEEP</td>\n",
       "      <td>GREY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Plate ID              Issue Date Vehicle Make Vehicle Color\n",
       "0   J58JKX  05/08/1972 12:00:00 AM        HONDA            BK\n",
       "1  KRE6058  08/29/1977 12:00:00 AM        ME/BE           BLK\n",
       "2  444326R  10/03/1988 12:00:00 AM        LEXUS         BLACK\n",
       "3  F728330  01/03/1990 12:00:00 AM        CHEVR           NaN\n",
       "4  FMY9090  02/14/1990 12:00:00 AM         JEEP          GREY"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5d4c68ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WH       2344858\n",
       "GY       2307704\n",
       "BK       2066374\n",
       "WHITE    1061234\n",
       "BL        775124\n",
       "RD        483298\n",
       "BLACK     465110\n",
       "GREY      306787\n",
       "BROWN     292348\n",
       "SILVE     191477\n",
       "GR        182929\n",
       "BLUE      178298\n",
       "RED       161693\n",
       "TN        120576\n",
       "BR        102204\n",
       "YW         98700\n",
       "BLK        91539\n",
       "OTHER      60245\n",
       "GREEN      58765\n",
       "GL         54851\n",
       "Name: Vehicle Color, dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what was the most common color of tickets vehicles?\n",
    "\n",
    "df['Vehicle Color'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb39788c",
   "metadata": {},
   "source": [
    "# Exercise: Unify color names\n",
    "\n",
    "1. Load the parking violations file into a data frame (if you can). We only need the following columns: plate ID, issue date, make, and color.\n",
    "2. Find some color names that are duplicated, and unify those names -- so instead of both `BLACK` and `BK`, turn one into the other.\n",
    "3. Which colors are most likely to be cited? \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "40aaad2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming WH -> WHITE\n",
      "Transforming GY -> GRAY\n",
      "Transforming BK -> BLACK\n",
      "Transforming BL -> BLUE\n",
      "Transforming RD -> RED\n",
      "Transforming GR -> GRAY\n",
      "Transforming TN -> TAN\n"
     ]
    }
   ],
   "source": [
    "# WH -> WHITE\n",
    "# GY -> GRAY\n",
    "# BK -> BLACK\n",
    "# BL -> BLUE\n",
    "# RD -> RED\n",
    "# GR -> GRAY\n",
    "# TN -> TAN\n",
    "\n",
    "color_map = {'WH':'WHITE',\n",
    "             'GY':'GRAY',\n",
    "             'BK':'BLACK',\n",
    "             'BL':'BLUE',\n",
    "             'RD':'RED',\n",
    "             'GR':'GREEN',\n",
    "             'TN':'TAN'}\n",
    "\n",
    "for key, value in color_map.items():\n",
    "    print(f'Transforming {key} -> {value}')\n",
    "    df.loc[df['Vehicle Color'] == key, 'Vehicle Color'] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "454cb1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHITE    3406092\n",
       "GRAY     2531487\n",
       "BLACK    2531484\n",
       "BLUE      953422\n",
       "RED       644991\n",
       "GREY      306787\n",
       "BROWN     292348\n",
       "SILVE     191477\n",
       "TAN       141667\n",
       "BR        102204\n",
       "YW         98700\n",
       "BLK        91539\n",
       "OTHER      60245\n",
       "GREEN      58765\n",
       "GL         54851\n",
       "GRY        46527\n",
       "MR         42812\n",
       "WHT        35433\n",
       "YELLO      32792\n",
       "WHI        29760\n",
       "Name: Vehicle Color, dtype: int64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Vehicle Color'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8e0c9746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12495734, 4)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning task #2 dealing with NaN\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7fd821fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plate ID</th>\n",
       "      <th>Issue Date</th>\n",
       "      <th>Vehicle Make</th>\n",
       "      <th>Vehicle Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J58JKX</td>\n",
       "      <td>05/08/1972 12:00:00 AM</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>BLACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KRE6058</td>\n",
       "      <td>08/29/1977 12:00:00 AM</td>\n",
       "      <td>ME/BE</td>\n",
       "      <td>BLK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>444326R</td>\n",
       "      <td>10/03/1988 12:00:00 AM</td>\n",
       "      <td>LEXUS</td>\n",
       "      <td>BLACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FMY9090</td>\n",
       "      <td>02/14/1990 12:00:00 AM</td>\n",
       "      <td>JEEP</td>\n",
       "      <td>GREY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KDG0693</td>\n",
       "      <td>07/21/1990 12:00:00 AM</td>\n",
       "      <td>HYUN</td>\n",
       "      <td>GRAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495729</th>\n",
       "      <td>62161MM</td>\n",
       "      <td>01/03/2040 12:00:00 AM</td>\n",
       "      <td>FORD</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495730</th>\n",
       "      <td>GYE7330</td>\n",
       "      <td>04/19/2045 12:00:00 AM</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>BLK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495731</th>\n",
       "      <td>HNY4802</td>\n",
       "      <td>01/17/2049 12:00:00 AM</td>\n",
       "      <td>FORD</td>\n",
       "      <td>GRAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495732</th>\n",
       "      <td>T687081C</td>\n",
       "      <td>12/19/2063 12:00:00 AM</td>\n",
       "      <td>TOYOT</td>\n",
       "      <td>BLK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495733</th>\n",
       "      <td>3497ZN</td>\n",
       "      <td>06/04/2064 12:00:00 AM</td>\n",
       "      <td>UTILI</td>\n",
       "      <td>WHITE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12049645 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Plate ID              Issue Date Vehicle Make Vehicle Color\n",
       "0           J58JKX  05/08/1972 12:00:00 AM        HONDA         BLACK\n",
       "1          KRE6058  08/29/1977 12:00:00 AM        ME/BE           BLK\n",
       "2          444326R  10/03/1988 12:00:00 AM        LEXUS         BLACK\n",
       "4          FMY9090  02/14/1990 12:00:00 AM         JEEP          GREY\n",
       "5          KDG0693  07/21/1990 12:00:00 AM         HYUN          GRAY\n",
       "...            ...                     ...          ...           ...\n",
       "12495729   62161MM  01/03/2040 12:00:00 AM         FORD            BR\n",
       "12495730   GYE7330  04/19/2045 12:00:00 AM        HONDA           BLK\n",
       "12495731   HNY4802  01/17/2049 12:00:00 AM         FORD          GRAY\n",
       "12495732  T687081C  12/19/2063 12:00:00 AM        TOYOT           BLK\n",
       "12495733    3497ZN  06/04/2064 12:00:00 AM        UTILI         WHITE\n",
       "\n",
       "[12049645 rows x 4 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()  # don't want any NaN values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8e9ed71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446089"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12495734 - 12049645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d7b03d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plate ID            202\n",
       "Issue Date            0\n",
       "Vehicle Make      62420\n",
       "Vehicle Color    391982\n",
       "dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out -- where are the NaNs?\n",
    "\n",
    "df.isna().sum()   # True == 1 and False == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f68bb48",
   "metadata": {},
   "source": [
    "# Next week:\n",
    "\n",
    "1. Working with text in Pandas\n",
    "2. Working with dates in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95818b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
